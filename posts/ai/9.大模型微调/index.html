<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>9.大模型微调 | 王小红的笔记</title><meta name=keywords content="大模型应用开发"><meta name=description content="大语言中的大型主要体现在参数规模和训练数据量，一般参数规模达到1B(10亿)量级才叫大模型，只有达到这个量级才会有机遇Scaling law的涌现现象，涌现现象是大模型的魅力，有点像初中物理学的液态变固态。
模型的参数数量跟显存占比的计算，以OPT-6.7B举例：OPT-6.7B就是6.7Billion个参数，假设参数的类型是Float16，即每个参数占用16位（2字节）的显存。总显存占用=参数总量×每个参数的显存占用。总内存 = 67亿 * 2 = 134亿字节。转换成GB就是134亿 / 1024 / 1024 / 1024 = 12.5GB的显存。
使用大显存的GPU加载整个模型可以加快训练速度，部署时也可以提高响应速度，但是可以只使用CPU+内存的方式训练或者部署，只不过这种方式的训练很慢，因为训练时需要大量的矩阵相乘操作。但是使用部署后的模型只是一个前向传播操作，CPU+内存的方式不会比GPU慢很多，除非是有并发量的批量推理，GPU的优势会很明显。
现在是一个信息过载的时代，搜什么都会出现一堆，大模型工具的使用可以帮助我们筛选出有用的信息
模型分类：自回归(CAUSAL_LM，文本生成任务，比如GPT)、序列分类(SEQ_CLS，情感分析、文本分类)、token级分类(TOKEN_CLS，命名实体识别NER)、问答任务(QUESTION_ANS)
大模型应用4个阶段
1提示词工程
面向的是终端用户，大模型时代的沟通手段，通过提示词从大模型挖掘知识。就是如何通过对话框跟大模型更好交流。大模型都是概率模型，很多能力他都没有，比如数学运算，但是我们可做到通过描述让他理解。这也是为什么基于注意力机制的模型很容易回答错误一个描述很复杂的小学数学应用题。
2AI智能体（AI Agent）
基于ReAct范式，就是大模型自主判断应该使用哪些工具，比如chatGPT+联网搜索。分为3类：

行动代理（Action agents）：自主决定使用工具，比如OpenAI的Function Call；
模拟代理（Simulation agents）：通常设计用于模拟角色扮演，在模拟的环境中运行，比如生成式智能体，CAMEL。以后可能会应用在游戏领域，类似于美剧西部世界；
自主智能体（Autonomous agents）：独立执行实现长期目标，比如Auto-GPT，manus（国产的，好像是Claude套壳）。

基于大模型开发应用的开发人员，比如自动客服，虚拟助手。
3大模型微调（Fine-tuning）
在预训练模型的基础上，使用较小的数据集进一步训练来调整模型参数。当有和目标相关的较小的数据集，并且希望模型在这个任务上表现更好的时候使用。
未来是面向基础模型编程。
4预训练技术（Pre-training）
使用大量的未标记数据（比如维基百科内容）来训练一个初步的模型，为后续的微调提供基础模型。适合有资源的大厂，有大量的数据集，数据清洗做的好，然后大力出奇迹。
能自己预训练模型的都是顶级大厂，因为需要的资源实在是太大了，比如LLaMA-65B就需要780G显存。
RAG
把我们从外部拿到的数据通过处理之后变成向量数据库中的知识。
微调技术路线
20年之前大家都不知道怎么去做微调，OpenAI发表了一篇论文提出调整prompt，让模型能更好的理解输入也能有很好的效果，再加上几年之后的文生图让prompt被大家熟知。
但是prompt有个缺点就是相同的prompt换一个模型或者换一个语言描述效果就会差很多，不管是在LangChain里或者在应用的对话框中都有这个问题。

全量微调（FFT）：所有系数都进行调整，原来的VC相关的模型用的多一点，训练成本高，容易造成灾难性遗忘。
高效微调（PEFT）：分为有监督微调（SFT）、基于人类反馈的强化学习（RLHF）、基于AI反馈的强化学习（RLAIF）。

PEFT
高效微调技术：Adapter Tuning(2019 Google) -> Prefix Tuning(2021 Stanford) -> Prompt Tuning(2021 Google) -> P-Tuning V1(2021 TsingHua, MIT) -> P-Tuning V2(2022 TsingHua, BAAI )
传统的模型微调是很容易的，比如分类的卷积网络中可以直接选择冻结卷积层，训练softmax层直接增加类别，2018年google的bert出来之后模型就已经不是CNN那种神经网络了，都是在叠加transformer的层数，整个模型看起来又宽又高，包括到今天的大语言模型中，哪部分参数干了哪些事也是未知的。"><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/posts/ai/9.%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/posts/ai/9.%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://wangxiaohong123.github.io/posts/ai/9.%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="9.大模型微调"><meta property="og:description" content="大语言中的大型主要体现在参数规模和训练数据量，一般参数规模达到1B(10亿)量级才叫大模型，只有达到这个量级才会有机遇Scaling law的涌现现象，涌现现象是大模型的魅力，有点像初中物理学的液态变固态。
模型的参数数量跟显存占比的计算，以OPT-6.7B举例：OPT-6.7B就是6.7Billion个参数，假设参数的类型是Float16，即每个参数占用16位（2字节）的显存。总显存占用=参数总量×每个参数的显存占用。总内存 = 67亿 * 2 = 134亿字节。转换成GB就是134亿 / 1024 / 1024 / 1024 = 12.5GB的显存。
使用大显存的GPU加载整个模型可以加快训练速度，部署时也可以提高响应速度，但是可以只使用CPU+内存的方式训练或者部署，只不过这种方式的训练很慢，因为训练时需要大量的矩阵相乘操作。但是使用部署后的模型只是一个前向传播操作，CPU+内存的方式不会比GPU慢很多，除非是有并发量的批量推理，GPU的优势会很明显。
现在是一个信息过载的时代，搜什么都会出现一堆，大模型工具的使用可以帮助我们筛选出有用的信息
模型分类：自回归(CAUSAL_LM，文本生成任务，比如GPT)、序列分类(SEQ_CLS，情感分析、文本分类)、token级分类(TOKEN_CLS，命名实体识别NER)、问答任务(QUESTION_ANS)
大模型应用4个阶段 1提示词工程 面向的是终端用户，大模型时代的沟通手段，通过提示词从大模型挖掘知识。就是如何通过对话框跟大模型更好交流。大模型都是概率模型，很多能力他都没有，比如数学运算，但是我们可做到通过描述让他理解。这也是为什么基于注意力机制的模型很容易回答错误一个描述很复杂的小学数学应用题。
2AI智能体（AI Agent） 基于ReAct范式，就是大模型自主判断应该使用哪些工具，比如chatGPT+联网搜索。分为3类：
行动代理（Action agents）：自主决定使用工具，比如OpenAI的Function Call； 模拟代理（Simulation agents）：通常设计用于模拟角色扮演，在模拟的环境中运行，比如生成式智能体，CAMEL。以后可能会应用在游戏领域，类似于美剧西部世界； 自主智能体（Autonomous agents）：独立执行实现长期目标，比如Auto-GPT，manus（国产的，好像是Claude套壳）。 基于大模型开发应用的开发人员，比如自动客服，虚拟助手。
3大模型微调（Fine-tuning） 在预训练模型的基础上，使用较小的数据集进一步训练来调整模型参数。当有和目标相关的较小的数据集，并且希望模型在这个任务上表现更好的时候使用。
未来是面向基础模型编程。
4预训练技术（Pre-training） 使用大量的未标记数据（比如维基百科内容）来训练一个初步的模型，为后续的微调提供基础模型。适合有资源的大厂，有大量的数据集，数据清洗做的好，然后大力出奇迹。
能自己预训练模型的都是顶级大厂，因为需要的资源实在是太大了，比如LLaMA-65B就需要780G显存。
RAG 把我们从外部拿到的数据通过处理之后变成向量数据库中的知识。
微调技术路线 20年之前大家都不知道怎么去做微调，OpenAI发表了一篇论文提出调整prompt，让模型能更好的理解输入也能有很好的效果，再加上几年之后的文生图让prompt被大家熟知。
但是prompt有个缺点就是相同的prompt换一个模型或者换一个语言描述效果就会差很多，不管是在LangChain里或者在应用的对话框中都有这个问题。
全量微调（FFT）：所有系数都进行调整，原来的VC相关的模型用的多一点，训练成本高，容易造成灾难性遗忘。 高效微调（PEFT）：分为有监督微调（SFT）、基于人类反馈的强化学习（RLHF）、基于AI反馈的强化学习（RLAIF）。 PEFT 高效微调技术：Adapter Tuning(2019 Google) -> Prefix Tuning(2021 Stanford) -> Prompt Tuning(2021 Google) -> P-Tuning V1(2021 TsingHua, MIT) -> P-Tuning V2(2022 TsingHua, BAAI )
传统的模型微调是很容易的，比如分类的卷积网络中可以直接选择冻结卷积层，训练softmax层直接增加类别，2018年google的bert出来之后模型就已经不是CNN那种神经网络了，都是在叠加transformer的层数，整个模型看起来又宽又高，包括到今天的大语言模型中，哪部分参数干了哪些事也是未知的。"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:tag" content="大模型应用开发"><meta name=twitter:card content="summary"><meta name=twitter:title content="9.大模型微调"><meta name=twitter:description content="大语言中的大型主要体现在参数规模和训练数据量，一般参数规模达到1B(10亿)量级才叫大模型，只有达到这个量级才会有机遇Scaling law的涌现现象，涌现现象是大模型的魅力，有点像初中物理学的液态变固态。
模型的参数数量跟显存占比的计算，以OPT-6.7B举例：OPT-6.7B就是6.7Billion个参数，假设参数的类型是Float16，即每个参数占用16位（2字节）的显存。总显存占用=参数总量×每个参数的显存占用。总内存 = 67亿 * 2 = 134亿字节。转换成GB就是134亿 / 1024 / 1024 / 1024 = 12.5GB的显存。
使用大显存的GPU加载整个模型可以加快训练速度，部署时也可以提高响应速度，但是可以只使用CPU+内存的方式训练或者部署，只不过这种方式的训练很慢，因为训练时需要大量的矩阵相乘操作。但是使用部署后的模型只是一个前向传播操作，CPU+内存的方式不会比GPU慢很多，除非是有并发量的批量推理，GPU的优势会很明显。
现在是一个信息过载的时代，搜什么都会出现一堆，大模型工具的使用可以帮助我们筛选出有用的信息
模型分类：自回归(CAUSAL_LM，文本生成任务，比如GPT)、序列分类(SEQ_CLS，情感分析、文本分类)、token级分类(TOKEN_CLS，命名实体识别NER)、问答任务(QUESTION_ANS)
大模型应用4个阶段
1提示词工程
面向的是终端用户，大模型时代的沟通手段，通过提示词从大模型挖掘知识。就是如何通过对话框跟大模型更好交流。大模型都是概率模型，很多能力他都没有，比如数学运算，但是我们可做到通过描述让他理解。这也是为什么基于注意力机制的模型很容易回答错误一个描述很复杂的小学数学应用题。
2AI智能体（AI Agent）
基于ReAct范式，就是大模型自主判断应该使用哪些工具，比如chatGPT+联网搜索。分为3类：

行动代理（Action agents）：自主决定使用工具，比如OpenAI的Function Call；
模拟代理（Simulation agents）：通常设计用于模拟角色扮演，在模拟的环境中运行，比如生成式智能体，CAMEL。以后可能会应用在游戏领域，类似于美剧西部世界；
自主智能体（Autonomous agents）：独立执行实现长期目标，比如Auto-GPT，manus（国产的，好像是Claude套壳）。

基于大模型开发应用的开发人员，比如自动客服，虚拟助手。
3大模型微调（Fine-tuning）
在预训练模型的基础上，使用较小的数据集进一步训练来调整模型参数。当有和目标相关的较小的数据集，并且希望模型在这个任务上表现更好的时候使用。
未来是面向基础模型编程。
4预训练技术（Pre-training）
使用大量的未标记数据（比如维基百科内容）来训练一个初步的模型，为后续的微调提供基础模型。适合有资源的大厂，有大量的数据集，数据清洗做的好，然后大力出奇迹。
能自己预训练模型的都是顶级大厂，因为需要的资源实在是太大了，比如LLaMA-65B就需要780G显存。
RAG
把我们从外部拿到的数据通过处理之后变成向量数据库中的知识。
微调技术路线
20年之前大家都不知道怎么去做微调，OpenAI发表了一篇论文提出调整prompt，让模型能更好的理解输入也能有很好的效果，再加上几年之后的文生图让prompt被大家熟知。
但是prompt有个缺点就是相同的prompt换一个模型或者换一个语言描述效果就会差很多，不管是在LangChain里或者在应用的对话框中都有这个问题。

全量微调（FFT）：所有系数都进行调整，原来的VC相关的模型用的多一点，训练成本高，容易造成灾难性遗忘。
高效微调（PEFT）：分为有监督微调（SFT）、基于人类反馈的强化学习（RLHF）、基于AI反馈的强化学习（RLAIF）。

PEFT
高效微调技术：Adapter Tuning(2019 Google) -> Prefix Tuning(2021 Stanford) -> Prompt Tuning(2021 Google) -> P-Tuning V1(2021 TsingHua, MIT) -> P-Tuning V2(2022 TsingHua, BAAI )
传统的模型微调是很容易的，比如分类的卷积网络中可以直接选择冻结卷积层，训练softmax层直接增加类别，2018年google的bert出来之后模型就已经不是CNN那种神经网络了，都是在叠加transformer的层数，整个模型看起来又宽又高，包括到今天的大语言模型中，哪部分参数干了哪些事也是未知的。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://wangxiaohong123.github.io/posts/"},{"@type":"ListItem","position":2,"name":"9.大模型微调","item":"https://wangxiaohong123.github.io/posts/ai/9.%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"9.大模型微调","name":"9.大模型微调","description":"大语言中的大型主要体现在参数规模和训练数据量，一般参数规模达到1B(10亿)量级才叫大模型，只有达到这个量级才会有机遇Scaling law的涌现现象，涌现现象是大模型的魅力，有点像初中物理学的液态变固态。\n模型的参数数量跟显存占比的计算，以OPT-6.7B举例：OPT-6.7B就是6.7Billion个参数，假设参数的类型是Float16，即每个参数占用16位（2字节）的显存。总显存占用=参数总量×每个参数的显存占用。总内存 = 67亿 * 2 = 134亿字节。转换成GB就是134亿 / 1024 / 1024 / 1024 = 12.5GB的显存。\n使用大显存的GPU加载整个模型可以加快训练速度，部署时也可以提高响应速度，但是可以只使用CPU+内存的方式训练或者部署，只不过这种方式的训练很慢，因为训练时需要大量的矩阵相乘操作。但是使用部署后的模型只是一个前向传播操作，CPU+内存的方式不会比GPU慢很多，除非是有并发量的批量推理，GPU的优势会很明显。\n现在是一个信息过载的时代，搜什么都会出现一堆，大模型工具的使用可以帮助我们筛选出有用的信息\n模型分类：自回归(CAUSAL_LM，文本生成任务，比如GPT)、序列分类(SEQ_CLS，情感分析、文本分类)、token级分类(TOKEN_CLS，命名实体识别NER)、问答任务(QUESTION_ANS)\n大模型应用4个阶段 1提示词工程 面向的是终端用户，大模型时代的沟通手段，通过提示词从大模型挖掘知识。就是如何通过对话框跟大模型更好交流。大模型都是概率模型，很多能力他都没有，比如数学运算，但是我们可做到通过描述让他理解。这也是为什么基于注意力机制的模型很容易回答错误一个描述很复杂的小学数学应用题。\n2AI智能体（AI Agent） 基于ReAct范式，就是大模型自主判断应该使用哪些工具，比如chatGPT+联网搜索。分为3类：\n行动代理（Action agents）：自主决定使用工具，比如OpenAI的Function Call； 模拟代理（Simulation agents）：通常设计用于模拟角色扮演，在模拟的环境中运行，比如生成式智能体，CAMEL。以后可能会应用在游戏领域，类似于美剧西部世界； 自主智能体（Autonomous agents）：独立执行实现长期目标，比如Auto-GPT，manus（国产的，好像是Claude套壳）。 基于大模型开发应用的开发人员，比如自动客服，虚拟助手。\n3大模型微调（Fine-tuning） 在预训练模型的基础上，使用较小的数据集进一步训练来调整模型参数。当有和目标相关的较小的数据集，并且希望模型在这个任务上表现更好的时候使用。\n未来是面向基础模型编程。\n4预训练技术（Pre-training） 使用大量的未标记数据（比如维基百科内容）来训练一个初步的模型，为后续的微调提供基础模型。适合有资源的大厂，有大量的数据集，数据清洗做的好，然后大力出奇迹。\n能自己预训练模型的都是顶级大厂，因为需要的资源实在是太大了，比如LLaMA-65B就需要780G显存。\nRAG 把我们从外部拿到的数据通过处理之后变成向量数据库中的知识。\n微调技术路线 20年之前大家都不知道怎么去做微调，OpenAI发表了一篇论文提出调整prompt，让模型能更好的理解输入也能有很好的效果，再加上几年之后的文生图让prompt被大家熟知。\n但是prompt有个缺点就是相同的prompt换一个模型或者换一个语言描述效果就会差很多，不管是在LangChain里或者在应用的对话框中都有这个问题。\n全量微调（FFT）：所有系数都进行调整，原来的VC相关的模型用的多一点，训练成本高，容易造成灾难性遗忘。 高效微调（PEFT）：分为有监督微调（SFT）、基于人类反馈的强化学习（RLHF）、基于AI反馈的强化学习（RLAIF）。 PEFT 高效微调技术：Adapter Tuning(2019 Google) -\u0026gt; Prefix Tuning(2021 Stanford) -\u0026gt; Prompt Tuning(2021 Google) -\u0026gt; P-Tuning V1(2021 TsingHua, MIT) -\u0026gt; P-Tuning V2(2022 TsingHua, BAAI )\n传统的模型微调是很容易的，比如分类的卷积网络中可以直接选择冻结卷积层，训练softmax层直接增加类别，2018年google的bert出来之后模型就已经不是CNN那种神经网络了，都是在叠加transformer的层数，整个模型看起来又宽又高，包括到今天的大语言模型中，哪部分参数干了哪些事也是未知的。\n","keywords":["大模型应用开发"],"articleBody":"大语言中的大型主要体现在参数规模和训练数据量，一般参数规模达到1B(10亿)量级才叫大模型，只有达到这个量级才会有机遇Scaling law的涌现现象，涌现现象是大模型的魅力，有点像初中物理学的液态变固态。\n模型的参数数量跟显存占比的计算，以OPT-6.7B举例：OPT-6.7B就是6.7Billion个参数，假设参数的类型是Float16，即每个参数占用16位（2字节）的显存。总显存占用=参数总量×每个参数的显存占用。总内存 = 67亿 * 2 = 134亿字节。转换成GB就是134亿 / 1024 / 1024 / 1024 = 12.5GB的显存。\n使用大显存的GPU加载整个模型可以加快训练速度，部署时也可以提高响应速度，但是可以只使用CPU+内存的方式训练或者部署，只不过这种方式的训练很慢，因为训练时需要大量的矩阵相乘操作。但是使用部署后的模型只是一个前向传播操作，CPU+内存的方式不会比GPU慢很多，除非是有并发量的批量推理，GPU的优势会很明显。\n现在是一个信息过载的时代，搜什么都会出现一堆，大模型工具的使用可以帮助我们筛选出有用的信息\n模型分类：自回归(CAUSAL_LM，文本生成任务，比如GPT)、序列分类(SEQ_CLS，情感分析、文本分类)、token级分类(TOKEN_CLS，命名实体识别NER)、问答任务(QUESTION_ANS)\n大模型应用4个阶段 1提示词工程 面向的是终端用户，大模型时代的沟通手段，通过提示词从大模型挖掘知识。就是如何通过对话框跟大模型更好交流。大模型都是概率模型，很多能力他都没有，比如数学运算，但是我们可做到通过描述让他理解。这也是为什么基于注意力机制的模型很容易回答错误一个描述很复杂的小学数学应用题。\n2AI智能体（AI Agent） 基于ReAct范式，就是大模型自主判断应该使用哪些工具，比如chatGPT+联网搜索。分为3类：\n行动代理（Action agents）：自主决定使用工具，比如OpenAI的Function Call； 模拟代理（Simulation agents）：通常设计用于模拟角色扮演，在模拟的环境中运行，比如生成式智能体，CAMEL。以后可能会应用在游戏领域，类似于美剧西部世界； 自主智能体（Autonomous agents）：独立执行实现长期目标，比如Auto-GPT，manus（国产的，好像是Claude套壳）。 基于大模型开发应用的开发人员，比如自动客服，虚拟助手。\n3大模型微调（Fine-tuning） 在预训练模型的基础上，使用较小的数据集进一步训练来调整模型参数。当有和目标相关的较小的数据集，并且希望模型在这个任务上表现更好的时候使用。\n未来是面向基础模型编程。\n4预训练技术（Pre-training） 使用大量的未标记数据（比如维基百科内容）来训练一个初步的模型，为后续的微调提供基础模型。适合有资源的大厂，有大量的数据集，数据清洗做的好，然后大力出奇迹。\n能自己预训练模型的都是顶级大厂，因为需要的资源实在是太大了，比如LLaMA-65B就需要780G显存。\nRAG 把我们从外部拿到的数据通过处理之后变成向量数据库中的知识。\n微调技术路线 20年之前大家都不知道怎么去做微调，OpenAI发表了一篇论文提出调整prompt，让模型能更好的理解输入也能有很好的效果，再加上几年之后的文生图让prompt被大家熟知。\n但是prompt有个缺点就是相同的prompt换一个模型或者换一个语言描述效果就会差很多，不管是在LangChain里或者在应用的对话框中都有这个问题。\n全量微调（FFT）：所有系数都进行调整，原来的VC相关的模型用的多一点，训练成本高，容易造成灾难性遗忘。 高效微调（PEFT）：分为有监督微调（SFT）、基于人类反馈的强化学习（RLHF）、基于AI反馈的强化学习（RLAIF）。 PEFT 高效微调技术：Adapter Tuning(2019 Google) -\u003e Prefix Tuning(2021 Stanford) -\u003e Prompt Tuning(2021 Google) -\u003e P-Tuning V1(2021 TsingHua, MIT) -\u003e P-Tuning V2(2022 TsingHua, BAAI )\n传统的模型微调是很容易的，比如分类的卷积网络中可以直接选择冻结卷积层，训练softmax层直接增加类别，2018年google的bert出来之后模型就已经不是CNN那种神经网络了，都是在叠加transformer的层数，整个模型看起来又宽又高，包括到今天的大语言模型中，哪部分参数干了哪些事也是未知的。\nAdapter Tuning bert是先做了一个语义理解能力很强的模型，然后在下游的具体任务上逐个的去微调模型，这中做法的成本相当高，做微调时需要把整个bert都加载到显存中。19年的时候google提出在transformer的Feed-forward layer层后增加一个adapter层，adapter层负责将高维向量转成低维，计算后在转回高维，只训练降维后的特征提升效率。\nPrefix Tuning 21年的时候斯坦福大学发表了一篇论文，Prefix Tuning，这个是在整个transformer前增加一个Prefix模块，仅训练Prefix，冻结Transformer全部参数，这样可以不将整个模型都加载到显存中，可以降低算力和训练时间。\n上面的微调都是有几类任务就需要微调几次，很麻烦。\nPrompt Tuning 相当于是Prefix Tuning的简化版，只在输入层增加一些token，让模型能够更好的理解用户的输入。解决了Prefix Tuning实现困难的问题，更容易训练，而且效果很接近Prefix Tuning。相当于在模型之前增加一个新的模型，并且不需要区分任务种类，只需要增加一个通用的就可以。\nP-Tuning V1 清华唐杰团队、杨志林和MIT一起发表的论文，优化了冻结模型的数据可能会导致模型过拟合的问题，他和Prefix Tuning的区别是P-Tuning更灵活，只在Input embedding层增加一些参数，且使用长短记忆网络加MLP进行初始化。\nP-Tuning V2 Prompt Tuning和P-Tuning V1在模型参数较小的情况下表显不好，V2改善了一下。\n上面的方法都没法兼顾高效和高质量，比如Adapter会增加模型深度，训练成本高，其他的会生成额外的token，会减少我们输入的token长度。\nLoRA 低秩适配技术：LoRA(2021 微软) -\u003e QLoRA(2023 华盛顿大学) -\u003e AdaLoRA(2023 微软)\n通过低秩分解将权重更新表示为两个较小的矩阵（更新矩阵），这些新矩阵可以在适应新数据的同时保持整体变化数量较少进行训练，原始矩阵保持冻结状态，并且不接受任何调整。最终结果通过原始权重和适应后的权重组合得到。\n实际上是在原始的预训练模型旁增加一个附加的网络通路，可以看成外挂了矩阵A和矩阵B相乘来模拟征秩。\n假设模型某一层的矩阵大小是d_in × d_out，那么lora外挂的2个矩阵就是d_in × r和r × d_out，这个r就是秩。\n适配时会将模型的原始权重+lora的适配矩阵，$ W_{final}=W_{pretrained}+\\frac{α}{r}⋅(A×B) $，α是一个缩放因子，通过α和r控制低秩矩阵对原始权重的影响，α越大影响越大(微调越激进)。\n相比PEFT的优势\n更少的可训练参数：LoRA通常只需要训练非常少的额外参数，相较于全参数微调或者某些PEFT方法，可以极大地减少需要更新的参数数量。 更高的训练效率：由于减少了需要更新的参数，LoRA能够更快地收敛，并且对计算资源的需求更低。 无推理延迟：LoRA不会增加推理时的延迟，因为低秩矩阵可以在运行时动态地与原模型权重相加或相乘，无需改变模型结构或重新存储整个模型。 灵活的模块化适应：LoRA允许创建轻量级、特定任务的适配器，这些适配器可以在不修改基础模型架构的情况下进行互换，便于多任务学习和任务切换。 稳健的知识保留：通过冻结预训练权重，LoRA有助于减轻灾难性遗忘的问题，即在学习新任务时丢失之前学到的知识。 AdaLoRA 使用SVD提升矩阵低秩分解性能，动态调整不同权重矩阵的本征秩r。\nSVD（奇异值分解）是一种矩阵分解技术，可以将任意一个矩阵分解为：左奇异向量矩阵、奇异值矩阵和右奇异向量矩阵。可以实现降维、数据压缩、噪声过滤、提取文本数据的潜在语义结构等。\nQLoRA 在LoRA的基础上增加了量化，引入了 NormalFloat（NF4），这是一种基于统计分布设计的非对称、4-bit 数据类型。NF4 能更好地适应权重的分布特性，在精度损失最小的前提下实现更高的压缩率。\nHugging Face Transformers使用 开发环境：miniconda，python3.11\nTransformers库提供了几千个预训练模型，并且对Jax、PyTorch、TensorFlow等支持很友好，活跃度非常高。\npipelines库 通过pipelines可以让我们很方便的调用现成的模型。他是先将输入变成模型能理解的向量，向量可以解决不同的语言的词表达相同意思的问题。转成向量之后交给模型，在经过一个后处理输出结果，不同的模型后处理不同。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from transformers import AutoTokenizer, AutoModel from transformers import pipeline # 手动拉取tokenizer和模型 tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\") model = AutoModel.from_pretrained(\"bert-base-chinese\") # 保存修改的tokenizer和模型 tokenizer.save_pretrained(\"路径\") model.save_pretrained(\"路径\") # 使用pipeline调用gpt2模型 prompt = \"吧啦吧啦一段话\" generator = pipeline(task=\"text-generator\", model=\"gpt2\") # 生成2句回应，每个句子最大长度为16 print(generator(prompt, num_return_sequences=2, max_length=16)) datasets库 用于快速加载、处理的公共数据集。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 from datasets import load_dataset import torch from torch.utils.data import DataLoader # 加载GLUE中的SST-2情感分析任务数据集 dataset = load_dataset(\"glue\", \"sst2\") # 加载本地 CSV 文件 dataset = load_dataset(\"csv\", data_files={\"train\": \"data/train.csv\", \"test\": \"data/test.csv\"}) # 查看训练集 print(dataset[\"train\"][:5]) # 转换为 PyTorch Dataset train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8) Trainer库 封装了完整训练循环的高级类，可以简化模型训练、评估、预测等流程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from transformers import TrainingArguments, Trainer # 训练 trainer = Trainer( model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset, compute_metrics=compute_metrics, ) trainer.train() # 保存模型，后续可以通过 from_pretrained() 方法重新加载 trainer.save_model(model_dir) # 保存训练状态，一般和try-except结合，防止训练中断 trainer.save_state() evaluate库 提供一系列标准评估指标，如准确率、F1、BLEU、ROUGE 等。\n1 2 3 4 5 6 7 8 9 10 11 import evaluate import numpy as np # 加载评估指标-准确率 accuracy = evaluate.load(\"accuracy\") # 计算准确率 labels = small_eval_dataset[:][\"label\"] preds = np.argmax(predictions.predictions, axis=-1) acc = accuracy.compute(predictions=preds, references=labels) print(f\"Accuracy: {acc['accuracy']}\") PEFT库 提供微调支持。\n1 2 3 4 5 6 7 8 9 10 11 12 from peft import LoraConfig, PeftModel, PeftConfig, TaskType, get_peft_model peft_config = LoraConfig( task_type=TaskType.SEQ_CLS, # 任务类型：序列分类 inference_mode=False, # 训练模式 r=8, # LoRA秩 lora_alpha=16, # 缩放因子 lora_dropout=0.1 # dropout率 ) # 将 PEFT 层添加到原始模型中 model = get_peft_model(model, peft_config) Transformers微调demo 文本分类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 from transformers import AutoTokenizer from datasets import load_dataset import random import pandas as pd import datasets from transformers import AutoModelForSequenceClassification import numpy as np import evaluate from transformers import TrainingArguments, Trainer def show_random_elements(dataset, num_examples=10): \"\"\" 查看数据集 :param dataset: 目标数据集 :param num_examples: 输出条数 :return: \"\"\" assert num_examples \u003c= len(dataset), f\"数据集长度 {len(dataset)} 小于 num_examples {num_examples}\" picks = [] for _ in range(num_examples): pick = random.randint(0, len(dataset) - 1) while pick in picks: pick = random.randint(0, len(dataset) - 1) picks.append(pick) df = pd.DataFrame(dataset[picks]) for column, typ in dataset.featrues.items(): if isinstance(typ, datasets.ClassLabel): df[column] = df[column].transform(lambda i: typ.names[i]) print(df) # 下载数据集 dataset = load_dataset(\"yelp_review_full\") # 查看下载的数据集格式 show_random_elements(dataset[\"train\"]) # 数据预处理 tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\") def tokenize_function(examples): \"\"\" 对超过长度的文本进行截断,长度不够的进行填充 \"\"\" return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True) # datasets的map方法支持在整个数据集上应用预处理函数 tokenized_datasets = dataset.map(tokenize_function, batched=True) # 删除原始文本，节省内存 tokenized_datasets = tokenized_datasets.remove_columns([\"text\"]) # 查看预处理后的数据集 show_random_elements(tokenized_datasets[\"train\"], num_examples=1) # 数据抽样，全量跑的时间太长，测试的时候就取一点 small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000)) small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000)) # 加载模型,数据集是5分类，所以这里指定num_labels也是5 # AutoModelForSequenceClassification 是专门为序列分类任务设计的,相对于AutoModel，AutoModelForSequenceClassification多了一些处理，比如分类操作，将概率转化为标签 model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5) model_dir = \"models/bert-base-cased-finetune-yelp\" # evaluation_strategy是评估策略，每完成1个epoch（遍历一次整个训练集）进行一次评估 # batch size是16，如果是单核GPU的话就是每次向模型输入16条数据；epoch是3，整个数据集会被训练3次 # logging_steps 默认值为500，根据我们的训练数据和步长，将其设置为每30步记录一次日志，比如只有1核GPU，就是每训练30 * 16条数据后记录一次日志 # 完整的参数：https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.TrainingArguments # 配置在源码中的定义：https://github.com/huggingface/transformers/blob/v4.36.1/src/transformers/training_args.py#L161 training_args = TrainingArguments(output_dir=model_dir, eval_strategy=\"epoch\", per_device_train_batch_size=16, num_train_epochs=3, logging_steps=30) # 简单的加载一个准确率指标 metric = evaluate.load(\"accuracy\") def compute_metrics(eval_pred): \"\"\" 统计模型能力，这里只根据准确率评估 :param eval_pred: 模型输出 :return: 概率最高的标签 \"\"\" # labels是实际的标签 # logits是2维数组，行数是batch size，列数是分类大小，就是说每行都是对一个样本的所有标签的分数预测 logits, labels = eval_pred # 获取样本得分最高的标签，就是模型预测的标签 predictions = np.argmax(logits, axis=-1) # 使用模型预测的标签和真实标签比较，得到准确率 return metric.compute(predictions=predictions, references=labels) # 开始训练 trainer = Trainer( model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset, compute_metrics=compute_metrics, ) trainer.train() # 保存模型，后续可以通过 from_pretrained() 方法重新加载 # 训练完就要保存，要不后面抛异常就白训练了 trainer.save_model(model_dir) # 保存训练状态，一般和try-except结合，防止训练中断 # trainer.save_state() small_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=64).select(range(100)) test_results = trainer.evaluate(small_test_dataset) print(f\"Test Accuracy: {test_results['eval_accuracy']:.4f}\") 量化 量化就是对模型中系数（权重、激活值等）的压缩，用较少的信息表示数据，同时尽量不降低太多准确性。量化主要分2种：\n后训练量化（PTQ）：在模型训练后降低系数的精度，就好比打印东西，本来是10页，为了省纸改小字体变成5页了。没有降低训练成本，可以节省部署资源。GPTQ、AWQ、BitsAndBytes(BNB)等。 量化感知训练（QAT）：训练时就考虑量化，效果更好，并且微调时训练成本更低，PyTorch Quantization Toolkit、NVIDIA TensorRT等。 当权重很大时，训练过程中矩阵相乘后产生的小数位会不断加长，这个时候量化后的精度过低就会导致精度丢失，也是梯度消失，所以模型的系数越大，参数的数据类型也越大。\n如果需要加载量化后的模型(比如bitsandbytes)必须要在Intel CPU上。\nLoRA微调demo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 import torch from transformers import GPT2Tokenizer, AutoConfig, AutoModelForCausalLM, TrainingArguments, Trainer from peft import LoraConfig, get_peft_model from datasets import load_dataset, ClassLabel, Sequence model_id = \"facebook/opt-125m\" # 加载模型 # 如果要加载量化后的模型可以使用model = AutoModelForCausalLM.from_pretrained(model_id, load_8bit=True) # 这种写法会使用bitsandbytes，但是必须要在Intel GPU基础上，下面的代码使用torch_dtype=torch.float16也可以减少内存的占用 # 目前bitsandbytes要比quanto或者pytorch自带的量化工具效率高 model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"cpu\") tokenizer = GPT2Tokenizer.from_pretrained(model_id) # 配置 LoRA peft_config = LoraConfig( r=8, # LoRA的秩 lora_alpha=16, # 适应的比例因子 target_modules=[\"q_proj\", \"v_proj\"], # 对哪些模块加 LoRA，可选的还有k_proj、out_proj lora_dropout=0.1, # 随机失效的神经元概率，防止过拟合，仅作用于lora的适配矩阵 bias=\"none\", # 不使用偏置，可选\"all\"、\"lora_only\" task_type=\"CAUSAL_LM\" # 表示这是因果(自回归)语言模型任务 ) # 自动包装模型，适配 LoRA（无需 prepare_model_for_int8_training） model = get_peft_model(model, peft_config) # 看一下模型大小 print(f\"{model.get_memory_footprint() / (1024 ** 3):.2f}GB\") # 数据集处理 dataset = load_dataset(\"Abirate/english_quotes\") tokenized_dataset = dataset.map(lambda samples: tokenizer(samples[\"quote\"]), batched=True) from transformers import DataCollatorForLanguageModeling # 数据集收集器，处理语言模型数据，mlm设置为不使用掩码语言模型 data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False) # 微调 model_dir = \"models\" training_args = TrainingArguments(output_dir=f\"{model_dir}/{model_id}-lora\", learning_rate=2e-4, # 学习率，定义梯度下降更新参数时的步长 per_device_train_batch_size=16, fp16=True, # 使用混合精度模型，上面设置了存的时候使用int8精度，但是计算的时候还是使用f16 max_steps=2, # 最大训练步长 logging_steps=30, save_safetensors=False) # 有些模型会出现多个模块复用权重，训练时重复保存相同的权重会报错，需要把save_safetensors关掉 trainer = Trainer( model=model, args=training_args, train_dataset=tokenized_dataset[\"train\"], data_collator=data_collator ) trainer.train() # 保存和使用 model.save_pretrained(f\"{model_dir}/{model_id}-lora-int8\") lora_model = trainer.model text = \"two things are infinite:\" inputs = tokenizer(text, return_tensors=\"pt\") out = lora_model.generate(**inputs, max_new_tokens=48) print(tokenizer.decode(out[0], skip_special_tokens=True)) ","wordCount":"965","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://wangxiaohong123.github.io/posts/ai/9.%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/"},"publisher":{"@type":"Organization","name":"王小红的笔记","logo":{"@type":"ImageObject","url":"https://wangxiaohong123.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">9.大模型微调</h1><div class=post-meta>5 min</div></header><div class=post-content><p>大语言中的大型主要体现在参数规模和训练数据量，一般参数规模达到1B(10亿)量级才叫大模型，只有达到这个量级才会有机遇Scaling law的涌现现象，涌现现象是大模型的魅力，有点像初中物理学的液态变固态。</p><p>模型的参数数量跟显存占比的计算，以OPT-6.7B举例：OPT-6.7B就是6.7Billion个参数，假设参数的类型是Float16，即每个参数占用16位（2字节）的显存。总显存占用=参数总量×每个参数的显存占用。总内存 = 67亿 * 2 = 134亿字节。转换成GB就是134亿 / 1024 / 1024 / 1024 = 12.5GB的显存。</p><p>使用大显存的GPU加载整个模型可以加快训练速度，部署时也可以提高响应速度，但是可以只使用CPU+内存的方式训练或者部署，只不过这种方式的训练很慢，因为训练时需要大量的矩阵相乘操作。但是使用部署后的模型只是一个前向传播操作，CPU+内存的方式不会比GPU慢很多，除非是有并发量的批量推理，GPU的优势会很明显。</p><p><strong>现在是一个信息过载的时代，搜什么都会出现一堆，大模型工具的使用可以帮助我们筛选出有用的信息</strong></p><p>模型分类：自回归(<code>CAUSAL_LM</code>，文本生成任务，比如GPT)、序列分类(<code>SEQ_CLS</code>，情感分析、文本分类)、token级分类(<code>TOKEN_CLS</code>，命名实体识别NER)、问答任务(<code>QUESTION_ANS</code>)</p><h4 id=大模型应用4个阶段>大模型应用4个阶段<a hidden class=anchor aria-hidden=true href=#大模型应用4个阶段>#</a></h4><h5 id=1提示词工程>1提示词工程<a hidden class=anchor aria-hidden=true href=#1提示词工程>#</a></h5><p>面向的是终端用户，大模型时代的沟通手段，通过提示词从大模型挖掘知识。就是如何通过对话框跟大模型更好交流。大模型都是概率模型，很多能力他都没有，比如数学运算，但是我们可做到通过描述让他理解。这也是为什么基于注意力机制的模型很容易回答错误一个描述很复杂的小学数学应用题。</p><h5 id=2ai智能体ai-agent>2AI智能体（AI Agent）<a hidden class=anchor aria-hidden=true href=#2ai智能体ai-agent>#</a></h5><p>基于ReAct范式，就是大模型自主判断应该使用哪些工具，比如chatGPT+联网搜索。分为3类：</p><ol><li>行动代理（Action agents）：自主决定使用工具，比如OpenAI的Function Call；</li><li>模拟代理（Simulation agents）：通常设计用于模拟角色扮演，在模拟的环境中运行，比如生成式智能体，CAMEL。以后可能会应用在游戏领域，类似于美剧西部世界；</li><li>自主智能体（Autonomous agents）：独立执行实现长期目标，比如Auto-GPT，manus（国产的，好像是Claude套壳）。</li></ol><p>基于大模型开发应用的开发人员，比如自动客服，虚拟助手。</p><h5 id=3大模型微调fine-tuning>3大模型微调（Fine-tuning）<a hidden class=anchor aria-hidden=true href=#3大模型微调fine-tuning>#</a></h5><p>在预训练模型的基础上，使用较小的数据集进一步训练来调整模型参数。当有和目标相关的较小的数据集，并且希望模型在这个任务上表现更好的时候使用。</p><p>未来是面向基础模型编程。</p><h5 id=4预训练技术pre-training>4预训练技术（Pre-training）<a hidden class=anchor aria-hidden=true href=#4预训练技术pre-training>#</a></h5><p>使用大量的未标记数据（比如维基百科内容）来训练一个初步的模型，为后续的微调提供基础模型。适合有资源的大厂，有大量的数据集，数据清洗做的好，然后大力出奇迹。</p><p>能自己预训练模型的都是顶级大厂，因为需要的资源实在是太大了，比如LLaMA-65B就需要780G显存。</p><h4 id=rag>RAG<a hidden class=anchor aria-hidden=true href=#rag>#</a></h4><p>把我们从外部拿到的数据通过处理之后变成向量数据库中的知识。</p><h3 id=微调技术路线>微调技术路线<a hidden class=anchor aria-hidden=true href=#微调技术路线>#</a></h3><p>20年之前大家都不知道怎么去做微调，OpenAI发表了一篇论文提出调整prompt，让模型能更好的理解输入也能有很好的效果，再加上几年之后的文生图让prompt被大家熟知。</p><p>但是prompt有个缺点就是相同的prompt换一个模型或者换一个语言描述效果就会差很多，不管是在LangChain里或者在应用的对话框中都有这个问题。</p><ol><li>全量微调（FFT）：所有系数都进行调整，原来的VC相关的模型用的多一点，训练成本高，容易造成灾难性遗忘。</li><li>高效微调（PEFT）：分为有监督微调（SFT）、基于人类反馈的强化学习（RLHF）、基于AI反馈的强化学习（RLAIF）。</li></ol><h4 id=peft>PEFT<a hidden class=anchor aria-hidden=true href=#peft>#</a></h4><p>高效微调技术：Adapter Tuning(2019 Google) -> Prefix Tuning(2021 Stanford) -> Prompt Tuning(2021 Google) -> P-Tuning V1(2021 TsingHua, MIT) -> P-Tuning V2(2022 TsingHua, BAAI )</p><p>传统的模型微调是很容易的，比如分类的卷积网络中可以直接选择冻结卷积层，训练softmax层直接增加类别，2018年google的bert出来之后模型就已经不是CNN那种神经网络了，都是在叠加transformer的层数，整个模型看起来又宽又高，包括到今天的大语言模型中，哪部分参数干了哪些事也是未知的。</p><h5 id=adapter-tuning>Adapter Tuning<a hidden class=anchor aria-hidden=true href=#adapter-tuning>#</a></h5><p>bert是先做了一个语义理解能力很强的模型，然后在下游的具体任务上逐个的去微调模型，这中做法的成本相当高，做微调时需要把整个bert都加载到显存中。19年的时候google提出在transformer的Feed-forward layer层后增加一个adapter层，adapter层负责将高维向量转成低维，计算后在转回高维，只训练降维后的特征提升效率。</p><h5 id=prefix-tuning>Prefix Tuning<a hidden class=anchor aria-hidden=true href=#prefix-tuning>#</a></h5><p>21年的时候斯坦福大学发表了一篇论文，Prefix Tuning，这个是在整个transformer前增加一个Prefix模块，仅训练Prefix，冻结Transformer全部参数，这样可以不将整个模型都加载到显存中，可以降低算力和训练时间。</p><p>上面的微调都是有几类任务就需要微调几次，很麻烦。</p><h5 id=prompt-tuning>Prompt Tuning<a hidden class=anchor aria-hidden=true href=#prompt-tuning>#</a></h5><p>相当于是Prefix Tuning的简化版，只在输入层增加一些token，让模型能够更好的理解用户的输入。解决了Prefix Tuning实现困难的问题，更容易训练，而且效果很接近Prefix Tuning。相当于在模型之前增加一个新的模型，并且不需要区分任务种类，只需要增加一个通用的就可以。</p><h5 id=p-tuning-v1>P-Tuning V1<a hidden class=anchor aria-hidden=true href=#p-tuning-v1>#</a></h5><p>清华唐杰团队、杨志林和MIT一起发表的论文，优化了冻结模型的数据可能会导致模型过拟合的问题，他和Prefix Tuning的区别是P-Tuning更灵活，只在Input embedding层增加一些参数，且使用长短记忆网络加MLP进行初始化。</p><h5 id=p-tuning-v2>P-Tuning V2<a hidden class=anchor aria-hidden=true href=#p-tuning-v2>#</a></h5><p>Prompt Tuning和P-Tuning V1在模型参数较小的情况下表显不好，V2改善了一下。</p><p>上面的方法都没法兼顾高效和高质量，比如Adapter会增加模型深度，训练成本高，其他的会生成额外的token，会减少我们输入的token长度。</p><h4 id=lora>LoRA<a hidden class=anchor aria-hidden=true href=#lora>#</a></h4><p>低秩适配技术：LoRA(2021 微软) -> QLoRA(2023 华盛顿大学) -> AdaLoRA(2023 微软)</p><p>通过低秩分解将权重更新表示为两个较小的矩阵（更新矩阵），这些新矩阵可以在适应新数据的同时保持整体变化数量较少进行训练，原始矩阵保持冻结状态，并且不接受任何调整。最终结果通过原始权重和适应后的权重组合得到。</p><p>实际上是在原始的预训练模型旁增加一个附加的网络通路，可以看成外挂了矩阵A和矩阵B相乘来模拟征秩。</p><p>假设模型某一层的矩阵大小是d_in × d_out，那么lora外挂的2个矩阵就是d_in × r和r × d_out，这个r就是秩。</p><p>适配时会将模型的原始权重+lora的适配矩阵，$ W_{final}=W_{pretrained}+\frac{α}{r}⋅(A×B) $，α是一个缩放因子，通过α和r控制低秩矩阵对原始权重的影响，α越大影响越大(微调越激进)。</p><p>相比PEFT的优势</p><ol><li>更少的可训练参数：LoRA通常只需要训练非常少的额外参数，相较于全参数微调或者某些PEFT方法，可以极大地减少需要更新的参数数量。</li><li>更高的训练效率：由于减少了需要更新的参数，LoRA能够更快地收敛，并且对计算资源的需求更低。</li><li>无推理延迟：LoRA不会增加推理时的延迟，因为低秩矩阵可以在运行时动态地与原模型权重相加或相乘，无需改变模型结构或重新存储整个模型。</li><li>灵活的模块化适应：LoRA允许创建轻量级、特定任务的适配器，这些适配器可以在不修改基础模型架构的情况下进行互换，便于多任务学习和任务切换。</li><li>稳健的知识保留：通过冻结预训练权重，LoRA有助于减轻灾难性遗忘的问题，即在学习新任务时丢失之前学到的知识。</li></ol><h5 id=adalora>AdaLoRA<a hidden class=anchor aria-hidden=true href=#adalora>#</a></h5><p>使用SVD提升矩阵低秩分解性能，动态调整不同权重矩阵的本征秩r。</p><p>SVD（奇异值分解）是一种矩阵分解技术，可以将任意一个矩阵分解为：左奇异向量矩阵、奇异值矩阵和右奇异向量矩阵。可以实现降维、数据压缩、噪声过滤、提取文本数据的潜在语义结构等。</p><h5 id=qlora>QLoRA<a hidden class=anchor aria-hidden=true href=#qlora>#</a></h5><p>在LoRA的基础上增加了量化，引入了 <strong>NormalFloat（NF4）</strong>，这是一种基于统计分布设计的非对称、4-bit 数据类型。NF4 能更好地适应权重的分布特性，在精度损失最小的前提下实现更高的压缩率。</p><h3 id=hugging-face-transformers使用>Hugging Face Transformers使用<a hidden class=anchor aria-hidden=true href=#hugging-face-transformers使用>#</a></h3><p>开发环境：miniconda，python3.11</p><p>Transformers库提供了几千个预训练模型，并且对Jax、PyTorch、TensorFlow等支持很友好，活跃度非常高。</p><h4 id=pipelines库>pipelines库<a hidden class=anchor aria-hidden=true href=#pipelines库>#</a></h4><p>通过pipelines可以让我们很方便的调用现成的模型。他是先将输入变成模型能理解的向量，向量可以解决不同的语言的词表达相同意思的问题。转成向量之后交给模型，在经过一个后处理输出结果，不同的模型后处理不同。</p><p><img alt=transformers-pipeline loading=lazy src=https://raw.githubusercontent.com/wangxiaohong123/p-bed/main/uPic/transformers-pipeline.jpg></p><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>from</span> transformers <span style=color:#ff79c6>import</span> AutoTokenizer, AutoModel
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> transformers <span style=color:#ff79c6>import</span> pipeline
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 手动拉取tokenizer和模型</span>
</span></span><span style=display:flex><span>tokenizer <span style=color:#ff79c6>=</span> AutoTokenizer<span style=color:#ff79c6>.</span>from_pretrained(<span style=color:#f1fa8c>&#34;bert-base-chinese&#34;</span>)
</span></span><span style=display:flex><span>model <span style=color:#ff79c6>=</span> AutoModel<span style=color:#ff79c6>.</span>from_pretrained(<span style=color:#f1fa8c>&#34;bert-base-chinese&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 保存修改的tokenizer和模型</span>
</span></span><span style=display:flex><span>tokenizer<span style=color:#ff79c6>.</span>save_pretrained(<span style=color:#f1fa8c>&#34;路径&#34;</span>)
</span></span><span style=display:flex><span>model<span style=color:#ff79c6>.</span>save_pretrained(<span style=color:#f1fa8c>&#34;路径&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 使用pipeline调用gpt2模型</span>
</span></span><span style=display:flex><span>prompt <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#34;吧啦吧啦一段话&#34;</span>
</span></span><span style=display:flex><span>generator <span style=color:#ff79c6>=</span> pipeline(task<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;text-generator&#34;</span>, model<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;gpt2&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#6272a4># 生成2句回应，每个句子最大长度为16</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(generator(prompt, num_return_sequences<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, max_length<span style=color:#ff79c6>=</span><span style=color:#bd93f9>16</span>))
</span></span></code></pre></td></tr></table></div></div><h4 id=datasets库>datasets库<a hidden class=anchor aria-hidden=true href=#datasets库>#</a></h4><p>用于快速加载、处理的公共数据集。</p><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>from</span> datasets <span style=color:#ff79c6>import</span> load_dataset
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> torch
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> torch.utils.data <span style=color:#ff79c6>import</span> DataLoader
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 加载GLUE中的SST-2情感分析任务数据集</span>
</span></span><span style=display:flex><span>dataset <span style=color:#ff79c6>=</span> load_dataset(<span style=color:#f1fa8c>&#34;glue&#34;</span>, <span style=color:#f1fa8c>&#34;sst2&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#6272a4># 加载本地 CSV 文件</span>
</span></span><span style=display:flex><span>dataset <span style=color:#ff79c6>=</span> load_dataset(<span style=color:#f1fa8c>&#34;csv&#34;</span>, data_files<span style=color:#ff79c6>=</span>{<span style=color:#f1fa8c>&#34;train&#34;</span>: <span style=color:#f1fa8c>&#34;data/train.csv&#34;</span>, <span style=color:#f1fa8c>&#34;test&#34;</span>: <span style=color:#f1fa8c>&#34;data/test.csv&#34;</span>})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 查看训练集</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(dataset[<span style=color:#f1fa8c>&#34;train&#34;</span>][:<span style=color:#bd93f9>5</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 转换为 PyTorch Dataset</span>
</span></span><span style=display:flex><span>train_dataloader <span style=color:#ff79c6>=</span> DataLoader(small_train_dataset, shuffle<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>, batch_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>8</span>)
</span></span></code></pre></td></tr></table></div></div><h4 id=trainer库>Trainer库<a hidden class=anchor aria-hidden=true href=#trainer库>#</a></h4><p>封装了完整训练循环的高级类，可以简化模型训练、评估、预测等流程。</p><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>from</span> transformers <span style=color:#ff79c6>import</span> TrainingArguments, Trainer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 训练</span>
</span></span><span style=display:flex><span>trainer <span style=color:#ff79c6>=</span> Trainer(
</span></span><span style=display:flex><span>    model<span style=color:#ff79c6>=</span>model,
</span></span><span style=display:flex><span>    args<span style=color:#ff79c6>=</span>training_args,
</span></span><span style=display:flex><span>    train_dataset<span style=color:#ff79c6>=</span>small_train_dataset,
</span></span><span style=display:flex><span>    eval_dataset<span style=color:#ff79c6>=</span>small_eval_dataset,
</span></span><span style=display:flex><span>    compute_metrics<span style=color:#ff79c6>=</span>compute_metrics,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>trainer<span style=color:#ff79c6>.</span>train()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 保存模型，后续可以通过 from_pretrained() 方法重新加载</span>
</span></span><span style=display:flex><span>trainer<span style=color:#ff79c6>.</span>save_model(model_dir)
</span></span><span style=display:flex><span><span style=color:#6272a4># 保存训练状态，一般和try-except结合，防止训练中断</span>
</span></span><span style=display:flex><span>trainer<span style=color:#ff79c6>.</span>save_state()
</span></span></code></pre></td></tr></table></div></div><h4 id=evaluate库>evaluate库<a hidden class=anchor aria-hidden=true href=#evaluate库>#</a></h4><p>提供一系列标准评估指标，如准确率、F1、BLEU、ROUGE 等。</p><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> evaluate
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> numpy <span style=color:#ff79c6>as</span> np
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 加载评估指标-准确率</span>
</span></span><span style=display:flex><span>accuracy <span style=color:#ff79c6>=</span> evaluate<span style=color:#ff79c6>.</span>load(<span style=color:#f1fa8c>&#34;accuracy&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 计算准确率</span>
</span></span><span style=display:flex><span>labels <span style=color:#ff79c6>=</span> small_eval_dataset[:][<span style=color:#f1fa8c>&#34;label&#34;</span>]
</span></span><span style=display:flex><span>preds <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>argmax(predictions<span style=color:#ff79c6>.</span>predictions, axis<span style=color:#ff79c6>=-</span><span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>acc <span style=color:#ff79c6>=</span> accuracy<span style=color:#ff79c6>.</span>compute(predictions<span style=color:#ff79c6>=</span>preds, references<span style=color:#ff79c6>=</span>labels)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#f1fa8c>f</span><span style=color:#f1fa8c>&#34;Accuracy: </span><span style=color:#f1fa8c>{</span>acc[<span style=color:#f1fa8c>&#39;accuracy&#39;</span>]<span style=color:#f1fa8c>}</span><span style=color:#f1fa8c>&#34;</span>)
</span></span></code></pre></td></tr></table></div></div><h4 id=peft库>PEFT库<a hidden class=anchor aria-hidden=true href=#peft库>#</a></h4><p>提供微调支持。</p><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>from</span> peft <span style=color:#ff79c6>import</span> LoraConfig, PeftModel, PeftConfig, TaskType, get_peft_model
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>peft_config <span style=color:#ff79c6>=</span> LoraConfig(
</span></span><span style=display:flex><span>    task_type<span style=color:#ff79c6>=</span>TaskType<span style=color:#ff79c6>.</span>SEQ_CLS,   <span style=color:#6272a4># 任务类型：序列分类</span>
</span></span><span style=display:flex><span>    inference_mode<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>,         <span style=color:#6272a4># 训练模式</span>
</span></span><span style=display:flex><span>    r<span style=color:#ff79c6>=</span><span style=color:#bd93f9>8</span>,                          <span style=color:#6272a4># LoRA秩</span>
</span></span><span style=display:flex><span>    lora_alpha<span style=color:#ff79c6>=</span><span style=color:#bd93f9>16</span>,                <span style=color:#6272a4># 缩放因子</span>
</span></span><span style=display:flex><span>    lora_dropout<span style=color:#ff79c6>=</span><span style=color:#bd93f9>0.1</span>              <span style=color:#6272a4># dropout率</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 将 PEFT 层添加到原始模型中</span>
</span></span><span style=display:flex><span>model <span style=color:#ff79c6>=</span> get_peft_model(model, peft_config)
</span></span></code></pre></td></tr></table></div></div><h4 id=transformers微调demo>Transformers微调demo<a hidden class=anchor aria-hidden=true href=#transformers微调demo>#</a></h4><h5 id=文本分类>文本分类<a hidden class=anchor aria-hidden=true href=#文本分类>#</a></h5><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 64
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 65
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 66
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 67
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 68
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 69
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 70
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 71
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 72
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 73
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 74
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 75
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 76
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 77
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 78
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 79
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 80
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 81
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 82
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 83
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 84
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 85
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 86
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 87
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 88
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 89
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 90
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 91
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 92
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 93
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 94
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 95
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 96
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 97
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 98
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 99
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">100
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">101
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">102
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">103
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">104
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">105
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">106
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">107
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">108
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">109
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">110
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">111
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">112
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">113
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">114
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>from</span> transformers <span style=color:#ff79c6>import</span> AutoTokenizer
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> datasets <span style=color:#ff79c6>import</span> load_dataset
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> random
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> pandas <span style=color:#ff79c6>as</span> pd
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> datasets
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> transformers <span style=color:#ff79c6>import</span> AutoModelForSequenceClassification
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> numpy <span style=color:#ff79c6>as</span> np
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> evaluate
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> transformers <span style=color:#ff79c6>import</span> TrainingArguments, Trainer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>show_random_elements</span>(dataset, num_examples<span style=color:#ff79c6>=</span><span style=color:#bd93f9>10</span>):
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    查看数据集
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    :param dataset: 目标数据集
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    :param num_examples: 输出条数
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    :return:
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>assert</span> num_examples <span style=color:#ff79c6>&lt;=</span> <span style=color:#8be9fd;font-style:italic>len</span>(dataset), <span style=color:#f1fa8c>f</span><span style=color:#f1fa8c>&#34;数据集长度 </span><span style=color:#f1fa8c>{</span><span style=color:#8be9fd;font-style:italic>len</span>(dataset)<span style=color:#f1fa8c>}</span><span style=color:#f1fa8c> 小于 num_examples </span><span style=color:#f1fa8c>{</span>num_examples<span style=color:#f1fa8c>}</span><span style=color:#f1fa8c>&#34;</span>
</span></span><span style=display:flex><span>    picks <span style=color:#ff79c6>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> _ <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(num_examples):
</span></span><span style=display:flex><span>        pick <span style=color:#ff79c6>=</span> random<span style=color:#ff79c6>.</span>randint(<span style=color:#bd93f9>0</span>, <span style=color:#8be9fd;font-style:italic>len</span>(dataset) <span style=color:#ff79c6>-</span> <span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>while</span> pick <span style=color:#ff79c6>in</span> picks:
</span></span><span style=display:flex><span>            pick <span style=color:#ff79c6>=</span> random<span style=color:#ff79c6>.</span>randint(<span style=color:#bd93f9>0</span>, <span style=color:#8be9fd;font-style:italic>len</span>(dataset) <span style=color:#ff79c6>-</span> <span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>        picks<span style=color:#ff79c6>.</span>append(pick)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    df <span style=color:#ff79c6>=</span> pd<span style=color:#ff79c6>.</span>DataFrame(dataset[picks])
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> column, typ <span style=color:#ff79c6>in</span> dataset<span style=color:#ff79c6>.</span>featrues<span style=color:#ff79c6>.</span>items():
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>if</span> <span style=color:#8be9fd;font-style:italic>isinstance</span>(typ, datasets<span style=color:#ff79c6>.</span>ClassLabel):
</span></span><span style=display:flex><span>            df[column] <span style=color:#ff79c6>=</span> df[column]<span style=color:#ff79c6>.</span>transform(<span style=color:#ff79c6>lambda</span> i: typ<span style=color:#ff79c6>.</span>names[i])
</span></span><span style=display:flex><span>    <span style=color:#8be9fd;font-style:italic>print</span>(df)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 下载数据集</span>
</span></span><span style=display:flex><span>dataset <span style=color:#ff79c6>=</span> load_dataset(<span style=color:#f1fa8c>&#34;yelp_review_full&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#6272a4># 查看下载的数据集格式</span>
</span></span><span style=display:flex><span>show_random_elements(dataset[<span style=color:#f1fa8c>&#34;train&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 数据预处理</span>
</span></span><span style=display:flex><span>tokenizer <span style=color:#ff79c6>=</span> AutoTokenizer<span style=color:#ff79c6>.</span>from_pretrained(<span style=color:#f1fa8c>&#34;bert-base-cased&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>tokenize_function</span>(examples):
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    对超过长度的文本进行截断,长度不够的进行填充
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> tokenizer(examples[<span style=color:#f1fa8c>&#34;text&#34;</span>], padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;max_length&#34;</span>, truncation<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># datasets的map方法支持在整个数据集上应用预处理函数</span>
</span></span><span style=display:flex><span>tokenized_datasets <span style=color:#ff79c6>=</span> dataset<span style=color:#ff79c6>.</span>map(tokenize_function, batched<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span><span style=color:#6272a4># 删除原始文本，节省内存</span>
</span></span><span style=display:flex><span>tokenized_datasets <span style=color:#ff79c6>=</span> tokenized_datasets<span style=color:#ff79c6>.</span>remove_columns([<span style=color:#f1fa8c>&#34;text&#34;</span>])
</span></span><span style=display:flex><span><span style=color:#6272a4># 查看预处理后的数据集</span>
</span></span><span style=display:flex><span>show_random_elements(tokenized_datasets[<span style=color:#f1fa8c>&#34;train&#34;</span>], num_examples<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 数据抽样，全量跑的时间太长，测试的时候就取一点</span>
</span></span><span style=display:flex><span>small_train_dataset <span style=color:#ff79c6>=</span> tokenized_datasets[<span style=color:#f1fa8c>&#34;train&#34;</span>]<span style=color:#ff79c6>.</span>shuffle(seed<span style=color:#ff79c6>=</span><span style=color:#bd93f9>42</span>)<span style=color:#ff79c6>.</span>select(<span style=color:#8be9fd;font-style:italic>range</span>(<span style=color:#bd93f9>1000</span>))
</span></span><span style=display:flex><span>small_eval_dataset <span style=color:#ff79c6>=</span> tokenized_datasets[<span style=color:#f1fa8c>&#34;test&#34;</span>]<span style=color:#ff79c6>.</span>shuffle(seed<span style=color:#ff79c6>=</span><span style=color:#bd93f9>42</span>)<span style=color:#ff79c6>.</span>select(<span style=color:#8be9fd;font-style:italic>range</span>(<span style=color:#bd93f9>1000</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 加载模型,数据集是5分类，所以这里指定num_labels也是5</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># AutoModelForSequenceClassification 是专门为序列分类任务设计的,相对于AutoModel，AutoModelForSequenceClassification多了一些处理，比如分类操作，将概率转化为标签</span>
</span></span><span style=display:flex><span>model <span style=color:#ff79c6>=</span> AutoModelForSequenceClassification<span style=color:#ff79c6>.</span>from_pretrained(<span style=color:#f1fa8c>&#34;bert-base-cased&#34;</span>, num_labels<span style=color:#ff79c6>=</span><span style=color:#bd93f9>5</span>)
</span></span><span style=display:flex><span>model_dir <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#34;models/bert-base-cased-finetune-yelp&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># evaluation_strategy是评估策略，每完成1个epoch（遍历一次整个训练集）进行一次评估</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># batch size是16，如果是单核GPU的话就是每次向模型输入16条数据；epoch是3，整个数据集会被训练3次</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># logging_steps 默认值为500，根据我们的训练数据和步长，将其设置为每30步记录一次日志，比如只有1核GPU，就是每训练30 * 16条数据后记录一次日志</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 完整的参数：https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/trainer#transformers.TrainingArguments</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 配置在源码中的定义：https://github.com/huggingface/transformers/blob/v4.36.1/src/transformers/training_args.py#L161</span>
</span></span><span style=display:flex><span>training_args <span style=color:#ff79c6>=</span> TrainingArguments(output_dir<span style=color:#ff79c6>=</span>model_dir,
</span></span><span style=display:flex><span>                                  eval_strategy<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;epoch&#34;</span>,
</span></span><span style=display:flex><span>                                  per_device_train_batch_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>16</span>,
</span></span><span style=display:flex><span>                                  num_train_epochs<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>,
</span></span><span style=display:flex><span>                                  logging_steps<span style=color:#ff79c6>=</span><span style=color:#bd93f9>30</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 简单的加载一个准确率指标</span>
</span></span><span style=display:flex><span>metric <span style=color:#ff79c6>=</span> evaluate<span style=color:#ff79c6>.</span>load(<span style=color:#f1fa8c>&#34;accuracy&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>compute_metrics</span>(eval_pred):
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    统计模型能力，这里只根据准确率评估
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    :param eval_pred: 模型输出
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    :return: 概率最高的标签
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># labels是实际的标签</span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># logits是2维数组，行数是batch size，列数是分类大小，就是说每行都是对一个样本的所有标签的分数预测</span>
</span></span><span style=display:flex><span>    logits, labels <span style=color:#ff79c6>=</span> eval_pred
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 获取样本得分最高的标签，就是模型预测的标签</span>
</span></span><span style=display:flex><span>    predictions <span style=color:#ff79c6>=</span> np<span style=color:#ff79c6>.</span>argmax(logits, axis<span style=color:#ff79c6>=-</span><span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 使用模型预测的标签和真实标签比较，得到准确率</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> metric<span style=color:#ff79c6>.</span>compute(predictions<span style=color:#ff79c6>=</span>predictions, references<span style=color:#ff79c6>=</span>labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 开始训练</span>
</span></span><span style=display:flex><span>trainer <span style=color:#ff79c6>=</span> Trainer(
</span></span><span style=display:flex><span>    model<span style=color:#ff79c6>=</span>model,
</span></span><span style=display:flex><span>    args<span style=color:#ff79c6>=</span>training_args,
</span></span><span style=display:flex><span>    train_dataset<span style=color:#ff79c6>=</span>small_train_dataset,
</span></span><span style=display:flex><span>    eval_dataset<span style=color:#ff79c6>=</span>small_eval_dataset,
</span></span><span style=display:flex><span>    compute_metrics<span style=color:#ff79c6>=</span>compute_metrics,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>trainer<span style=color:#ff79c6>.</span>train()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 保存模型，后续可以通过 from_pretrained() 方法重新加载</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 训练完就要保存，要不后面抛异常就白训练了</span>
</span></span><span style=display:flex><span>trainer<span style=color:#ff79c6>.</span>save_model(model_dir)
</span></span><span style=display:flex><span><span style=color:#6272a4># 保存训练状态，一般和try-except结合，防止训练中断</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># trainer.save_state()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>small_test_dataset <span style=color:#ff79c6>=</span> tokenized_datasets[<span style=color:#f1fa8c>&#34;test&#34;</span>]<span style=color:#ff79c6>.</span>shuffle(seed<span style=color:#ff79c6>=</span><span style=color:#bd93f9>64</span>)<span style=color:#ff79c6>.</span>select(<span style=color:#8be9fd;font-style:italic>range</span>(<span style=color:#bd93f9>100</span>))
</span></span><span style=display:flex><span>test_results <span style=color:#ff79c6>=</span> trainer<span style=color:#ff79c6>.</span>evaluate(small_test_dataset)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#f1fa8c>f</span><span style=color:#f1fa8c>&#34;Test Accuracy: </span><span style=color:#f1fa8c>{</span>test_results[<span style=color:#f1fa8c>&#39;eval_accuracy&#39;</span>]<span style=color:#f1fa8c>:</span><span style=color:#f1fa8c>.4f</span><span style=color:#f1fa8c>}</span><span style=color:#f1fa8c>&#34;</span>)
</span></span></code></pre></td></tr></table></div></div><h5 id=量化>量化<a hidden class=anchor aria-hidden=true href=#量化>#</a></h5><p>量化就是对模型中系数（权重、激活值等）的压缩，用较少的信息表示数据，同时尽量不降低太多准确性。量化主要分2种：</p><ol><li>后训练量化（PTQ）：在模型训练后降低系数的精度，就好比打印东西，本来是10页，为了省纸改小字体变成5页了。没有降低训练成本，可以节省部署资源。GPTQ、AWQ、BitsAndBytes(BNB)等。</li><li>量化感知训练（QAT）：训练时就考虑量化，效果更好，并且微调时训练成本更低，PyTorch Quantization Toolkit、NVIDIA TensorRT等。</li></ol><p>当权重很大时，训练过程中矩阵相乘后产生的小数位会不断加长，这个时候量化后的精度过低就会导致精度丢失，也是梯度消失，所以模型的系数越大，参数的数据类型也越大。</p><p><strong>如果需要加载量化后的模型(比如bitsandbytes)必须要在Intel CPU上</strong>。</p><h5 id=lora微调demo>LoRA微调demo<a hidden class=anchor aria-hidden=true href=#lora微调demo>#</a></h5><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">60
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> torch
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> transformers <span style=color:#ff79c6>import</span> GPT2Tokenizer, AutoConfig, AutoModelForCausalLM, TrainingArguments, Trainer
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> peft <span style=color:#ff79c6>import</span> LoraConfig, get_peft_model
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> datasets <span style=color:#ff79c6>import</span> load_dataset, ClassLabel, Sequence
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model_id <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#34;facebook/opt-125m&#34;</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 加载模型</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 如果要加载量化后的模型可以使用model = AutoModelForCausalLM.from_pretrained(model_id, load_8bit=True)</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 这种写法会使用bitsandbytes，但是必须要在Intel GPU基础上，下面的代码使用torch_dtype=torch.float16也可以减少内存的占用</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 目前bitsandbytes要比quanto或者pytorch自带的量化工具效率高</span>
</span></span><span style=display:flex><span>model <span style=color:#ff79c6>=</span> AutoModelForCausalLM<span style=color:#ff79c6>.</span>from_pretrained(model_id, torch_dtype<span style=color:#ff79c6>=</span>torch<span style=color:#ff79c6>.</span>float16, device_map<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;cpu&#34;</span>)
</span></span><span style=display:flex><span>tokenizer <span style=color:#ff79c6>=</span> GPT2Tokenizer<span style=color:#ff79c6>.</span>from_pretrained(model_id)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 配置 LoRA</span>
</span></span><span style=display:flex><span>peft_config <span style=color:#ff79c6>=</span> LoraConfig(
</span></span><span style=display:flex><span>    r<span style=color:#ff79c6>=</span><span style=color:#bd93f9>8</span>, <span style=color:#6272a4># LoRA的秩</span>
</span></span><span style=display:flex><span>    lora_alpha<span style=color:#ff79c6>=</span><span style=color:#bd93f9>16</span>, <span style=color:#6272a4># 适应的比例因子</span>
</span></span><span style=display:flex><span>    target_modules<span style=color:#ff79c6>=</span>[<span style=color:#f1fa8c>&#34;q_proj&#34;</span>, <span style=color:#f1fa8c>&#34;v_proj&#34;</span>], <span style=color:#6272a4># 对哪些模块加 LoRA，可选的还有k_proj、out_proj</span>
</span></span><span style=display:flex><span>    lora_dropout<span style=color:#ff79c6>=</span><span style=color:#bd93f9>0.1</span>, <span style=color:#6272a4># 随机失效的神经元概率，防止过拟合，仅作用于lora的适配矩阵</span>
</span></span><span style=display:flex><span>    bias<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;none&#34;</span>, <span style=color:#6272a4># 不使用偏置，可选&#34;all&#34;、&#34;lora_only&#34;</span>
</span></span><span style=display:flex><span>    task_type<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;CAUSAL_LM&#34;</span> <span style=color:#6272a4># 表示这是因果(自回归)语言模型任务</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#6272a4># 自动包装模型，适配 LoRA（无需 prepare_model_for_int8_training）</span>
</span></span><span style=display:flex><span>model <span style=color:#ff79c6>=</span> get_peft_model(model, peft_config)
</span></span><span style=display:flex><span><span style=color:#6272a4># 看一下模型大小</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#f1fa8c>f</span><span style=color:#f1fa8c>&#34;</span><span style=color:#f1fa8c>{</span>model<span style=color:#ff79c6>.</span>get_memory_footprint() <span style=color:#ff79c6>/</span> (<span style=color:#bd93f9>1024</span> <span style=color:#ff79c6>**</span> <span style=color:#bd93f9>3</span>)<span style=color:#f1fa8c>:</span><span style=color:#f1fa8c>.2f</span><span style=color:#f1fa8c>}</span><span style=color:#f1fa8c>GB&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 数据集处理</span>
</span></span><span style=display:flex><span>dataset <span style=color:#ff79c6>=</span> load_dataset(<span style=color:#f1fa8c>&#34;Abirate/english_quotes&#34;</span>)
</span></span><span style=display:flex><span>tokenized_dataset <span style=color:#ff79c6>=</span> dataset<span style=color:#ff79c6>.</span>map(<span style=color:#ff79c6>lambda</span> samples: tokenizer(samples[<span style=color:#f1fa8c>&#34;quote&#34;</span>]), batched<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> transformers <span style=color:#ff79c6>import</span> DataCollatorForLanguageModeling
</span></span><span style=display:flex><span><span style=color:#6272a4># 数据集收集器，处理语言模型数据，mlm设置为不使用掩码语言模型</span>
</span></span><span style=display:flex><span>data_collator <span style=color:#ff79c6>=</span> DataCollatorForLanguageModeling(tokenizer, mlm<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 微调</span>
</span></span><span style=display:flex><span>model_dir <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#34;models&#34;</span>
</span></span><span style=display:flex><span>training_args <span style=color:#ff79c6>=</span> TrainingArguments(output_dir<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>f</span><span style=color:#f1fa8c>&#34;</span><span style=color:#f1fa8c>{</span>model_dir<span style=color:#f1fa8c>}</span><span style=color:#f1fa8c>/</span><span style=color:#f1fa8c>{</span>model_id<span style=color:#f1fa8c>}</span><span style=color:#f1fa8c>-lora&#34;</span>,
</span></span><span style=display:flex><span>                                  learning_rate<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2e-4</span>, <span style=color:#6272a4># 学习率，定义梯度下降更新参数时的步长</span>
</span></span><span style=display:flex><span>                                  per_device_train_batch_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>16</span>,
</span></span><span style=display:flex><span>                                  fp16<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>, <span style=color:#6272a4># 使用混合精度模型，上面设置了存的时候使用int8精度，但是计算的时候还是使用f16</span>
</span></span><span style=display:flex><span>                                  max_steps<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, <span style=color:#6272a4># 最大训练步长</span>
</span></span><span style=display:flex><span>                                  logging_steps<span style=color:#ff79c6>=</span><span style=color:#bd93f9>30</span>,
</span></span><span style=display:flex><span>                                 save_safetensors<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>) <span style=color:#6272a4># 有些模型会出现多个模块复用权重，训练时重复保存相同的权重会报错，需要把save_safetensors关掉</span>
</span></span><span style=display:flex><span>trainer <span style=color:#ff79c6>=</span> Trainer(
</span></span><span style=display:flex><span>    model<span style=color:#ff79c6>=</span>model,
</span></span><span style=display:flex><span>    args<span style=color:#ff79c6>=</span>training_args,
</span></span><span style=display:flex><span>    train_dataset<span style=color:#ff79c6>=</span>tokenized_dataset[<span style=color:#f1fa8c>&#34;train&#34;</span>],
</span></span><span style=display:flex><span>    data_collator<span style=color:#ff79c6>=</span>data_collator
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>trainer<span style=color:#ff79c6>.</span>train()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 保存和使用</span>
</span></span><span style=display:flex><span>model<span style=color:#ff79c6>.</span>save_pretrained(<span style=color:#f1fa8c>f</span><span style=color:#f1fa8c>&#34;</span><span style=color:#f1fa8c>{</span>model_dir<span style=color:#f1fa8c>}</span><span style=color:#f1fa8c>/</span><span style=color:#f1fa8c>{</span>model_id<span style=color:#f1fa8c>}</span><span style=color:#f1fa8c>-lora-int8&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>lora_model <span style=color:#ff79c6>=</span> trainer<span style=color:#ff79c6>.</span>model
</span></span><span style=display:flex><span>text <span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#34;two things are infinite:&#34;</span>
</span></span><span style=display:flex><span>inputs <span style=color:#ff79c6>=</span> tokenizer(text, return_tensors<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#34;pt&#34;</span>)
</span></span><span style=display:flex><span>out <span style=color:#ff79c6>=</span> lora_model<span style=color:#ff79c6>.</span>generate(<span style=color:#ff79c6>**</span>inputs, max_new_tokens<span style=color:#ff79c6>=</span><span style=color:#bd93f9>48</span>)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(tokenizer<span style=color:#ff79c6>.</span>decode(out[<span style=color:#bd93f9>0</span>], skip_special_tokens<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>))
</span></span></code></pre></td></tr></table></div></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://wangxiaohong123.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/>大模型应用开发</a></li></ul><nav class=paginav><a class=prev href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/spring/cloud-alibaba/dubbo/9.%E9%AB%98%E9%98%B6%E7%89%B9%E6%80%A7%E6%BA%90%E7%A0%81/><span class=title>« Prev</span><br><span>9.dubbo-高阶特性源码</span>
</a><a class=next href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/leecode/9.%E6%95%B4%E6%95%B0%E5%8F%8D%E8%BD%AC/><span class=title>Next »</span><br><span>9.整数反转</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 9.大模型微调 on x" href="https://x.com/intent/tweet/?text=9.%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83&amp;url=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f9.%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E5%25BE%25AE%25E8%25B0%2583%2f&amp;hashtags=%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%ba%94%e7%94%a8%e5%bc%80%e5%8f%91"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 9.大模型微调 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f9.%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E5%25BE%25AE%25E8%25B0%2583%2f&amp;title=9.%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83&amp;summary=9.%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83&amp;source=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f9.%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E5%25BE%25AE%25E8%25B0%2583%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 9.大模型微调 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f9.%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E5%25BE%25AE%25E8%25B0%2583%2f&title=9.%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 9.大模型微调 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f9.%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E5%25BE%25AE%25E8%25B0%2583%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 9.大模型微调 on whatsapp" href="https://api.whatsapp.com/send?text=9.%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83%20-%20https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f9.%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E5%25BE%25AE%25E8%25B0%2583%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 9.大模型微调 on telegram" href="https://telegram.me/share/url?text=9.%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83&amp;url=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f9.%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E5%25BE%25AE%25E8%25B0%2583%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 9.大模型微调 on ycombinator" href="https://news.ycombinator.com/submitlink?t=9.%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83&u=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f9.%25E5%25A4%25A7%25E6%25A8%25A1%25E5%259E%258B%25E5%25BE%25AE%25E8%25B0%2583%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>