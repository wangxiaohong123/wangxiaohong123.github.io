<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | 王小红的笔记</title><meta name=keywords content><meta name=description content="Posts - 王小红的笔记"><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangxiaohong123.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script><meta property="og:url" content="https://wangxiaohong123.github.io/posts/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="Posts"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://wangxiaohong123.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span class=active>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>3.物理模型</h2></header><div class=entry-content><p>hbase使用多维的稀疏排序map存储数据，比如像下面这样：
rowkey_01+列族1:列1+put+t3：v1，他的key是多维的，存储了rowkey、列族名称、列名称、操作方法、操作时间戳，并且根据key进行排序，value就是操作的值，这样看的话就是一个多维排序的map，稀疏的话说的是每一列不一定有值，这样看起来就很稀疏。
他是一种列簇式存储，把同一列族下的所有列的值存到一个大文件里，所以查询同一列族下的数据会很快，到是一次查找多个列族，就会涉及到读取多个文件，所以在建表的时候需要考虑好，尽量让每次插叙都是同一列族下的列数据，相对于列存储和行存储，列簇存储更灵活，如果一个表只有一个列簇，就变成了行存储，如果每一个列簇只有一个列，就变成了列存储。
架构图</p></div><footer class=entry-footer><span title='2021-06-14 06:27:35 +0000 UTC'>June 14, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 3.物理模型" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/hbase/03%E7%89%A9%E7%90%86%E6%A8%A1%E5%9E%8B/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>4.put流程</h2></header><div class=entry-content><p>hbase:meta put就是找到对应的regision，然后把数据写到HLog和对应的store里去，所以第一步就是要先拿到region信息，这个信息存到了一张meta表里，所属空间是hbase，当client端没找到region信息的时候就回去这个表里查出来region的信息，然后缓存在本地，下次直接读取本地的就可以了，但是hbase:meta也是一张表，client怎么知道这个表在那个region上呢？在zk中，zk里维护了一份meta表的信息，client先去zk上拿到meta在那，然后把数据读取出来，拿到了将要put的表的region信息，就可以进行put操作了。
hbase:meta只有一个列族，叫info，他的rowkey结构是表名+起始rowkey+region创建时间戳+这3个字段的md5，表里面有4个列，分别是info:regioninfo(包括md5值，region名称，起始rowkey，结束rowkey)、info:seqnumDuringOpen(region打开时的sequenceId)、info:server(存储Region在哪个RegionServer上)、info:serverstartcode(RegionServer的启动timestamp)。
开始put 找到region信息之前还需要判断是否开启了autoFlush，如果autoFlush=false(默认是true)，这个时候是不会想region发送数据的，他会在客户端缓存数据，当数据达到2M时一起推送到region，一般没人开这个，因为开了这个数据很容易就丢失。
拿到region信息之后就要把哪一行数据加锁，然后把这次的操作封装成一个FSWALEntry对象写入WAL的队列中，这是一个基于disruptor的无锁有界队列，消费者拿到这条数据后会把WAL日志写到缓存中，修改完成之后会释放锁，并且把结果封装成SyncFutrue对象发送到disruptor中，消费者拿到这条数据后就可以把WAL日志刷到hdfs里去了，对于HLog的持久化有5种机制，在调用JavaAPI的时候可以通过**put.setDurability(Durability.SYNC_WAL)**来设置：
SKIP_WAL：不写WAL日志，把数据写到memStore里就算成功，但是memStore里的数据可能还没写到HFile中，数据丢失的概率也非常大； ASYNC_WAL：这个也是把数据写到memStore里就算成功，然后异步去写WAL； SYNC_WAL：要把WAl日志写到hdfs里，但是也只是存在在hdfs的os cache中； FSYNC_WAL：强制刷到hdfs的磁盘里才算成功； USER_DEFAULT：默认级别，就是SYNC_WAL； memStore频繁full gc问题 大量的put操作会让memStore年青代频繁gc，短时间发生多次gc就会有大量的对象躲过gc并进入老年代，这样很快老年代也会满掉，频繁的发生full gc，HBase通过chunk数组的方式，每一个memStore会创建一个MemStoreLAB对象，对象里是一个2M的chunk数组，这里的2M可以和autoFlush的2M对应起来，当一个chunk数组写满后，就会申请一个新的chunk数组，这样就算老年代发生了full gc，但是使用了数组的数据结构，内存都是连续的，减少了内存碎片，第一gc的频率会比之前低很多，第二减少了gc之后的整理内存时间。但是还是会频繁的young gc，所以他把chunk放到了一个chunk池里反复利用。
memStore生成HFile的时机 当memStore中的数据达到128M的时候，使用hbase.hregion.memstore.flush.size控制这个数值； 当region中的所有memStore总和超过了hbase.hregion.memstore.block.multiplier * hbase.hregion.memstore.flush.size时； 当所有memStore的总和超过了hbase.regionserver.global.memstore.size.lower.limit * hbase.regionserver.global.memstore.size的时候，从大到小刷，刷到不满足为止； 当HLog数量超过了hbase.regionserver.maxlogs时，选择最早的HLog来刷； 默认一小时刷一次； 通过flush命令；</p></div><footer class=entry-footer><span title='2021-06-14 06:27:35 +0000 UTC'>June 14, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 4.put流程" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/hbase/04put%E6%B5%81%E7%A8%8B/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.habse基础</h2></header><div class=entry-content><p>HDFS和HBase的关系： HDFS能做的事非常少，也就是创建文件，删除文件，大文件读取，追加数据，如果想要修改或者根据某些条件查询就不行，hbase就是做这个的。
hbase是一个nosql，他不负责存储数据，需要基于HDFS来实现，但是他不能执行复杂的条件查询，对海量数据的简单的增删改查。
架构特点 hbase基于多台regionServer来管理数据分片，regionServer是高可用的，region是存储在HDFS中，本省就有两个副本。
主从强一致。
支持MapReduce和spark这种分布式计算引擎。
支持java API。
支持协处理器，块缓存和布隆过滤器。
可以使用web端管理和运维。
使用场景 海量数据的简单增删改查，不支持索引，也不知道事务，不支持SQL语法。想要上面的功能也没必要用hbase，实现索引可以用es，实现海量数据事务可以用TiDB，实现海量数据的的实时分析可以用clickhouse或者druid。
数据模型和物理模型 针对数据模型有几个概念：
rowkey：每行都有一个rowkey，和mysql的主键差不多，也会根据这个排序，所以要把相似的数据放到一起，这样的话好查，比如这里存了订单和订单明细，rowkey可以是这样的order_1_111，order-detail_1_110，就是用户1在的111订单，和用户1的110订单明细。
列族：就是列名，两部分组成，列族+分号+列限定符（column qualifier），列族就是一系列的类的family，有点像表的意思。
列：他的列是要存储多个版本的值的，每个值都带着一个时间戳（版本）。
单元格：取到某行某列的某个时间戳对应的值就是一个单元格。
rowkey order:base order:detail order:extent
order_1_110 xxx xxx
order_1_111 x1(t1); x2(t2) xxx xxx
实际存储上他会把数据根据列来拆分成行进行存储，所以叫列式存储，像下面这样：
rowkey timestamp 列 值
order_1_110 t1 order:detail xxx
order_1_111 t2 order:base xxx
order_1_111 t3 order:extent xxx
简单的语法 进入bin下执行**./hbase shell**连接hbase。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # 查看命令使用 help 'list' # 创建工作空间 create_namespace 'stats' # 修改工作空间 alter_namespace 'stats', {METHOD=>'set', NAME => 'stats1'} # 修改工作空间 drop_namespace 'stats' # 创建一张test表，制定工作空间是stats，指定一个列族cf，创建表时必须要有列族，可以是多个列族create 'test','cf1','cf2' create 'stats:test','cf' # 使用list获取所有表，也可以指定表，比如list 'test' list # 或者使用exist 表名 exists 'test' # 禁用表，所有dml操作都需要先禁用表 disable 'test' # 启用表 enable 'test' # 表是否启用 is_enabled 'test' # 查看表的明细 describe 'test' # 添加列族 alter 'test', 'Extra' # 删除列族 alter 'test', {NAME=>'Extra', METHOD=>'delete'} # 删除表，这一步是基于disable之后的 drop 'test' # 插入或者更新一行数据，put 表名,rowkey,列族：列名,值…… put 'test','row1','cf1:a','1','cf2:b' # 指定返回行数 scan 'test', {LIMIT=>10} # 获取列族或者列数据 scan 'test', {COLUMNS=>['cf1:a', 'cf2:b']} # 根据rowkey前缀匹配 scan 'test', {STARTROW => 'row1'} # 获取表数据，例子是倒叙，条件可以不带 scan 'test',{REVERSED=>true,STARTROW=>'row100~',ENDROW=>'row100',LIMIT=>5} # 再来个正序 scan 'test',{STARTROW=>'row100',ENDROW=>'row100~',LIMIT=>5} # 还可以根据row key获取一条数据 get 'test' 'row1' # 删除数据，表名,rowkey,列族:列名，列族和列名都不是必须的，这样是删除最新的一个数据 # 把所有版本全部删除时deleteall delete 'test','row1','cf1:a' 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 刷新memStore的阈值，默认是128M hbase.hregion.memstore.flush.size # 当所有memStore都超过了这么大的时候把memStore刷到hdfs中 hbase.regionserver.global.memstore.size.lower.limit # HLog数量上限 hbase.regionserver.maxlogs # 设置chunk大小，默认是2MB hbase.hregion.memstore.mslab.chunksize # 开启chunk pool，默认是0，可以设置0到1的数字 # 比如设置成0.3，就会把年轻代的大小 * 0.3分配给pool hbase.hregion.memstore.chunkpool.maxsize # pool中初始化多少个chunk hbase.hregion.memstore.chunkpool.initialsize # 每隔多久创建一个新的WAL日志文件，默认一小时 hbase.regionserver.logroll.period # 每隔多久删掉过期的old WAL文件，默认1分钟 hbase.master.cleaner.interval # old WAL文件过期时间，默认10分钟 hbase.master.logcleaner.ttl # 合并HFile的阈值 hbase.hstore.compactionThreshold # major compaction的周期（天），0是关闭 hbase.hregion.majorcompaction # 当未合并的文件数量低于这个阈值时，停止合并，默认是3 hbase.store.compaction.min # 合并文件的large线程池的线程数 hbase.regionserver.thread.compaction.large # 合并文件的small线程池的线程数 hbase.regionserver.thread.compaction.small # 合并的文件数超过这个值就会使用large线程池 hbase.regionserver.thread.compaction.throttle</p></div><footer class=entry-footer><span title='2021-06-06 06:27:35 +0000 UTC'>June 6, 2021</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to 1.habse基础" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/hbase/01%E5%9F%BA%E7%A1%80/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>2.habse安装</h2></header><div class=entry-content><p></p></div><footer class=entry-footer><span title='2021-06-06 06:27:35 +0000 UTC'>June 6, 2021</span>&nbsp;·&nbsp;0 min</footer><a class=entry-link aria-label="post link to 2.habse安装" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/hbase/02%E5%AE%89%E8%A3%85/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.分布式id-常见方案</h2></header><div class=entry-content><p>分布式id生成器(发号器)使用场景 主要是用来做分库分表中数据的id。
常见方案 1.数据库主键自增 专门搞一个库和一个表，这个表只生成id，比如在插入真正数据之前，先往这个id生成表里插入，返回值就是主键。这种方案非常简单但是不能抗高并发，因为他是单标抗高并发写，肯定不现实。如果是低并发，低负载只是数据量大还勉强，关键是生产还需要保证这个表时高可用的，否则一个库挂了整个系统都死了，而且生成id的表还需要定期清理，其实也不简单。
2.UUID 他应该是最简单的，直接本地生成，没有并发和可用问题，但是他生成的字符串，而且还很长，很长就会浪费空间，关键是他是字符串，而且不是自增，不是自增的主键会导致MySQL频繁的页分裂。如果有网卡的话UUID是基于Mac地址获得，容易暴露Mac地址。
3.snowflake 雪花算范最终得到的是一个long类型数字，但是在计算的时候使用的是二进制，结构如下：
| 0/1 | 41位二进制，当前时间 | n位二进制，n位机房id | 5位二进制，机器id | 12位二进制 |
第一位没有意义，是二进制标记位，0代表正数，1代表负数；
当前时间：使用当前时间毫秒时间戳转换为二进制，最高大约是69年；
10位的机房id和机器id：这两个可以随意传，比如服务器A、B、C，每台服务器部署了两个服务D、E，那么服务器A的机房id可以为1，服务器B的机房id为2，服务器C的机房id为3；服务D的机器id为1，服务E的id为2，或者这10位都是机器id，也就是发号器最多可以部署1024台服务；
12位二进制：当同一毫秒多个请求访问雪花算法工具类时，序号加1，意思是每台机器每毫秒最多生成4096个id，非常非常多了；
他有很多问题，比如始终回拨：在多服务器上生成全局id，如果想保证id递增性，需要以一个机器作为基准，其他机器定时与这台机器时间校准，如果出现一台机器的时间快了，进行时间回调的之后，在生成的id可能就与之前的重复。 而且他需要独立部署，独立维护。
4.redis自增 比如5台redis机器，每台机器分别从1、2、3、4、5开始自增，自增的步长是5，这样也能抗住并发，但是需要每次生成id的时候定位机器，redis的数量也要写死，如果涉及到扩容是非常麻烦的，要改代码，还要清洗之前的id。如果想用在集群上还是单机合适一点，可是如果是单机需要主从保证高可用，如果发生主备切换就可能导致id重复，因为redis的主从同步是异步的。
5.基于时间戳+业务id的组合 比如订单id基于时间戳+用户id这样可以保证唯一，除非他是用程序刷单或者系统bug。再比如打车软件是时间戳+地点id+手机号后4位之类的，这种冲突的概率就非常低了，但是理论上有可能会存在重复问题。他也只适合跟时间戳相关的业务。
第一优先级考虑这个。
6.flicker(雅虎下的图片分享平台) 首先创建一张生成id的表：
1 2 3 4 5 6 CREATE TABLE `id_generator` ( `id` bigint(20) unsigned NOT NULL auto_increment, `stub` char(1) NOT NULL default '', PRIMARY KEY (`id`), UNIQUE KEY `stub` (`stub`) ) ENGINE=MyISAM; 注意这里的引擎使用的MyISAM，他的表现比InnoDB好，生成id的语法：
1 2 REPLACE INTO id_generator(stub) VALUES ('a'); SELECT LAST_INSERT_ID(); 这样可以避免行数过大，一张表就一行数据。优化一下就是stub的值设置成每个服务的id，比如ip什么的，这样就会有多行，或者说stub设置成项目名，这样就支持多业务了，数据库只要双机主从高可用，在设置起始id和步长，类似redis自增的那种。但是他还是扛不住并发，但是生产可用，他和redis自增类似也会产生重复id问题。
...</p></div><footer class=entry-footer><span title='2021-01-19 06:27:35 +0000 UTC'>January 19, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 1.分布式id-常见方案" href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8Fid/1.%E5%B8%B8%E8%A7%81%E6%96%B9%E6%A1%88/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>2.分布式id-snowflake生产方案</h2></header><div class=entry-content><p>机器和机房id处理 机器id的话可以通过zk的顺序节点来实现，每台机器启动都去zk目录下创建持久化顺序节点，拿到顺序号就是自己机器的id了，拿到id之后写到本地磁盘里，下次启动直接从本地拿。
全局递增id 因为snowflake的id是局部递增的，只能保证每台机器生成的id是自增的，如果有个业务想要拿到绝对递增的id，需要把请求打到同一台发号器上去。唯一ID生成服务要两台节点以上保证可用性，所以要知道发号器的服务地址，需要根据地址做负载均衡和重试。这些都可以使用nacos+dubbo解决。
时钟回拨问题 只要有时钟同步问题就会有时钟回拨的问题，判断时钟回拨很简单。
把时钟同步关了，基本上不会关，可能会因为时间导致系统崩溃。 记录每次生成id的时间戳，每次生成id的时候比较这个时间戳和系统的时间，如果系统的时间小就说明时钟回拨了，这个时候可以等，如果判断要等的时间很短，就夯住，时间很长就可以直接返回失败，但是返回失败这个是非常不好的。 针对第二种方案的优化，如果时钟回拨后和之前差几秒，这个时候可以返回异常+持续时间，让发号器的客户端重试并且在持续时间内不请求这台服务器，如果差很多，已经几十秒了，发号器客户端直接把这台机器从服务列表里删除，然后发号器就直接报警在主动下线，等到时间到了再次上线。 在优化减少发号器的重试，可以保存1s内每1毫秒生成的id的最大值，因为时钟回拨很少超过1s，当发现时钟回拨时，如果时间在1s内，就从拿到这个毫秒之前生成id的最大值开始递增。 如果在重启时发生时钟回拨时没法检测的，就算检测到了也没办法解决，所以每次启动的时候都需要拿到一个新的机器id，再把之前创建的zk顺序节点删掉，没有持久化操作，如果zk上的节点超过了1024个直接切换目录。</p></div><footer class=entry-footer><span title='2021-01-19 06:27:35 +0000 UTC'>January 19, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 2.分布式id-snowflake生产方案" href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8Fid/2.snowflake%E7%94%9F%E4%BA%A7%E6%96%B9%E6%A1%88/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>3.分布式id-leaf</h2></header><div class=entry-content><p>leaf有两种实现方式，flicker和snowflake，[leaf文档][https://tech.meituan.com/2017/04/21/mt-leaf.html]，它实现的flicker和之前的方案一模一样，多了一个号段的buffer，当一个号段用完之后切换，实现一个号段buffer一只可用，没有号段用完的阻塞。
leaf实现的snowflake要简单一些，启动的时候判断是否发生长时间的时钟回拨，然后在生成id的时候简单判断当前时间和上次生成id的时候，如果比上次生成id的时间小就等10ms，如果还是不行就返回错误了，并且他建议关闭NTP同步服务，他把一些细节比如重试、服务下线什么的交给自己实现了。
源码非常简单。</p></div><footer class=entry-footer><span title='2021-01-19 06:27:35 +0000 UTC'>January 19, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 3.分布式id-leaf" href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E5%88%86%E5%B8%83%E5%BC%8Fid/3.leaf/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>spring-boot-1.Logback</h2></header><div class=entry-content><p>核心API
日志对象：ch.qos.logback.classic.Logger 日志级别：ch.qos.logback.classic.Level 日志管理上下文：ch.qos.logback.classic.LoggerContext 日志附加器：ch.qos.logback.core.Appender 日志过滤器：ch.qos.logback.core.filter.Filter 日志格式布局：ch.qos.logback.core.Layout 日志事件：ch.qos.logback.classic.spi.LoggingEvent 日志配置器：ch.qos.logback.classic.spi.Configurator 日志诊断上下文：org.slf4j.MDC api级实现logback的demo
1 2 3 4 5 6 7 8 9 10 11 12 13 14 public static void main(String[] args) { LoggerContext loggerContext = new LoggerContext(); // 会从一个cache里取，如果不存在就创建一个新的 Logger logger = loggerContext.getLogger(LogbackDemo.class); // 声明配置器 // 配置器中会声明默认的附加器和日志格式 BasicConfigurator configurator = new BasicConfigurator(); configurator.configure(loggerContext); logger.info("info测试"); } 不管是log4j还是logback，他们都有自己独立的api，所以开发的时候可能由于个人喜好出现多种日志框架，所以需要一个日志的API框架，比如apache的commons-loggin，slf4j，apache的几年前已经不维护了，现在使用最多的就是slf4j。slf4j会有很多适配包，根据我们引入的不同依赖去适配。如果按照logback的类编程，在以后需要换日志框架的时候很麻烦，如果按照slf4j的接口编程，以后换日志框架可能直接改个依赖就可以了。</p></div><footer class=entry-footer><span title='2021-01-19 06:27:35 +0000 UTC'>January 19, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to spring-boot-1.Logback" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/spring/spring-boot/logback/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>spring-boot-2.源码</h2></header><div class=entry-content><p>Spring boot的源码和spring的代码耦合的很多，所以看的时候不能看细节，一细就会进到spring的源码里，所以查看主要功能的思路就可以，比如自动装配。
源码都在spring-boot-project模块里，直接进到SpringApplication的run(Class&lt;?>[] primarySources, String[] args)方法里，这个也是我们启动服务的入口：
1 2 3 4 public static ConfigurableApplicationContext run(Class&lt;?>[] primarySources, String[] args) { // 先用我们自己的Application类初始化一个SpringApplication，然后调用他的run()方法 return new SpringApplication(primarySources).run(args); } 一、初始化SpringApplication源码： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public SpringApplication(ResourceLoader resourceLoader, Class&lt;?>... primarySources) { this.resourceLoader = resourceLoader; Assert.notNull(primarySources, "PrimarySources must not be null"); // 这个就是我们传进来的类 this.primarySources = new LinkedHashSet&lt;>(Arrays.asList(primarySources)); // 根据classpath推断工程类型,拿到的是SERVLET this.webApplicationType = WebApplicationType.deduceFromClasspath(); // ApplicationContextInitializer是个接口，我们自己或者第三方框架可能自定义他的实现类 // 在spring容器初始化的时候会被调用 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); // ApplicationListener他也是个接口，他是在发生事件的时候会被回调 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); } 1.推断工程类型就是看项目里有没有和对应类型匹配的类： 1 2 3 4 5 6 7 8 9 10 11 12 13 static WebApplicationType deduceFromClasspath() { // 他写死了一些类，然后再classpath里扫描jar包和我们自己开发的类，如果和写死的类匹配上了就返回对应的类型 if (ClassUtils.isPresent(WEBFLUX_INDICATOR_CLASS, null) && !ClassUtils.isPresent(WEBMVC_INDICATOR_CLASS, null) && !ClassUtils.isPresent(JERSEY_INDICATOR_CLASS, null)) { return WebApplicationType.REACTIVE; } for (String className : SERVLET_INDICATOR_CLASSES) { if (!ClassUtils.isPresent(className, null)) { return WebApplicationType.NONE; } } return WebApplicationType.SERVLET; } 2.设置ApplicationContextInitializer和ApplicationListener调用的是Spring的SpringFactoriesLoader里的方法，他会扫描各个META-INF/spring.factories文件里的配置类。 3.找到项目主类： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 private Class&lt;?> deduceMainApplicationClass() { try { // new RuntimeException().getStackTrace()可以获取方法的调用栈 StackTraceElement[] stackTrace = new RuntimeException().getStackTrace(); // 找到调用栈里第一个main方法所在的类 for (StackTraceElement stackTraceElement : stackTrace) { if ("main".equals(stackTraceElement.getMethodName())) { return Class.forName(stackTraceElement.getClassName()); } } } catch (ClassNotFoundException ex) { // Swallow and continue } return null; } 二、SpringApplication.run()方法源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 public ConfigurableApplicationContext run(String... args) { StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter> exceptionReporters = new ArrayList&lt;>(); configureHeadlessProperty(); // 拿到SpringApplicationRunListeners，里面放到是SpringApplicationRunListener的实现类 // 就是说我们可以自己实现SpringApplicationRunListener，在这个方法里就会调用对应的方法 SpringApplicationRunListeners listeners = getRunListeners(args); // 拿到所有的listener然后遍历调用starting()，就是广播了一下启动事件 listeners.starting(); try { ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 准备环境 // 在这里也会回调listener的一个方法 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); // 这个非常关键，创建AnnotationConfigServletWebServerApplicationContext context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] { ConfigurableApplicationContext.class }, context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 这个很关键，刷新刚才加载进去的postProcessor // 这里可能会执行核心代码逻辑，比如spring bean的初始化、spring mvc、tomcat等等 refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); } // 第一个spring容器启动之后会通过监听回调触发正式的spring容器初始化和后面的系统启动工作 listeners.started(context); callRunners(context, applicationArguments); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); } try { listeners.running(context); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); } return context; } refreshContext(context);时已知这个context是AnnotationConfigServletWebServerApplicationContext，refresh()方法会走到他的父类ServletWebServerApplicationContext的refresh()方法。
...</p></div><footer class=entry-footer><span title='2021-01-19 06:27:35 +0000 UTC'>January 19, 2021</span>&nbsp;·&nbsp;5 min</footer><a class=entry-link aria-label="post link to spring-boot-2.源码" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/spring/spring-boot/%E6%BA%90%E7%A0%81/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent></h2></header><div class=entry-content><p>虚拟机安装 虚拟机管理软件：virtual box；
虚拟机镜像版本：CentOS-7-x86_64-Everything-1810；
安装完成后启动配置固定ip，由于不知道那些ip可以分配，所以先设置成动态获取，在把获取的ip设成固定的：
1 2 # 编辑ifcfg-eth0文件 vi /etc/sysconfig/network-scripts/ifcfg-eth0 1 2 3 4 5 DEVICE=eth0 TYPE=Ethernet ONBOOT=yes # 动态ip BOOTPROTO=dhcp 1 2 3 4 # 重启network服务 service network restart #-->查看当前ip，比如192.168.0.3 ifconfig 再次编辑ifcfg-eth0文件
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to " href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/1.%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://wangxiaohong123.github.io/posts/page/3/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://wangxiaohong123.github.io/posts/page/5/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>