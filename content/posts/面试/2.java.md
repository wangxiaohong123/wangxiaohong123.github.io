---
title: 面试专题-2.java
tags:
  - 面试专题
categories: 面试专题
copyright: true
---

### java基础

##### 1.java中是值传递还是引用传递

java中都是值传递，基本数据类型是复制的具体值进行传递，引用类型复制的是对象的内存地址进行传递，所以就算是值传递，在方法中修改引用参数的属性会导致外部对象也发生改变。怎么证明引用对象也是值传递？

```java
public class Person {
    private String name;
}

public static void main(String[] args) {
    Person xiaoZhang = new Person("小张");
    Person xiaoLi = new Person("小李");
    swap(xiaoZhang, xiaoLi);
    System.out.println("xiaoZhang:" + xiaoZhang.getName());
    System.out.println("xiaoLi:" + xiaoLi.getName());
}

public static void swap(Person person1, Person person2) {
    Person temp = person1;
    person1 = person2;
    person2 = temp;
    System.out.println("person1:" + person1.getName());
    System.out.println("person2:" + person2.getName());
}

// 输出结果：
// person1:小李
// person2:小张
// xiaoZhang:小张
// xiaoLi:小李
```

可以发现虽然在方法里交换了两个Person对象，但是外面的对象的指向没有变，如果是引用传递的话外面的指向也会发生变化。

##### 2.序列化

###### 2.1 java自带的序列化中的serialVersionUID有什么用

这个id是用来版本比较的，如果反序列化之后的serialVersionUID和当前类的serialVersionUID是否相同，不相同说明版本不匹配，会抛出InvalidClassException异常。

###### 2.2 为什么不推荐使用java自带的序列化

第一它不支持跨语言；第二他的性能和序列化对数据的压缩都比其他框架差；反序列化的数据可以被随意构造，当执行被构造的恶意代码时会存在安全问题。

和他相比的ProtoBuf支持跨语言，使用时自己定义传输数据对应的IDL文件，然后生成对应的序列化代码，这样没有序列化漏洞，性能也挺好。

dubbo里还支持二次开发的Hessian2序列化框架。

##### 3.Unsafe类

Unsafe类可以用来访问操作系统的内存资源、操作内存屏障、线程调度，它里面也是使用类似指针的东西操作内存，很容易发生指针问题。所以当类加载器不是BootStrapClassLoader的时候，是不能够获取Unsafe类的实例的，来防止Unsafe类在不可控的代码中被使用。

如果要使用Unsafe类可以使用反射拿到theUnsafe变量或者修改使用Unsafe类的类加载器。

##### 4.switch只支持基本数据类型，那他怎么实现对String的支持？

switch其实只支持int类型的比较，如果是String类型会先比较字符串的hash码，如果hash码相同在使用equals进行字符串比较：

```java
switch (str) {
    case "world":
        System.out.println("hello");
        break;
    default:
        break;
}
// 编译后类似这样
switch ((s = str).hashCode()) {
    default:
        break;
    case 113318802:
        if(s.equals("world"))
            System.out.println("world");
        break;
}
```

##### 5.断言

java默认不启用断言，需要使用-enableassertions开启。

##### 6.ArrayList

ArrayList默认的长度是10，当插入元素时，如果计算插入完元素的长度大于当前数组的长度，就扩容当前长度的1.5倍。ArrayList不支持自动缩容，需要手动调用trimToSize()方法。

##### 7.fail fast

初始化迭代器的时候会设置一个exceptModCount和modCount变量值是当前集合长度，如果发生了增删改操作的时候会对modCount进行++操作，这样当调用next()方法时如果发现exceptModCount和modCount不相等就会抛出异常。

##### 8.HashMap

HashMap采用数组+链表/红黑树的方式存储数据，默认长度是0，第一次插入数据之后数组长度变成16，扩容阈值是数组长度 * 0.75，插入元素时先根据hash值和数组长度取模，采用(数组长度 - 1) & hash值，采用位运算取模更高效，但是数组长度只能是2^n^。

如果发生了hash冲突，当链表长度小于8的时候直接在末尾追加，当链表长度大于等于8时，如果数组长度小于64会扩容数组，反之会把链表转成红黑树。

根据泊松分布，当数组长度为64，发生8次hash冲突的概率是千万分之6，所以转红黑树的阈值设成了8。

当两个线程同时插入元素的时候发现需要扩容，假设第一个线程刚刚复制了一部分元素就发生了时间片切换，这个时候第二个线程开始执行并且完成扩容，切换回第一个线程，由于1.7使用尾插法，这样就会导致第一个线程刚刚复制的元素和前一个元素形成环形链表，这样就会在查找时导致CPU100%。1.8之后扩容不会改变指针的指向。

### java并发

##### 1.进程通信

*   管道：管道是linux中用来缓存传输的数据的，半双工的意思是数据只能向一个方向流动，只能一个进程写，一个进程读，使用fork可以复制一个子进程出来，这时候两个进程共享代码空间，独立数据空间。
*   命名管道：管道是没有名字的，只能进行父子进程的通信，把管道加上名字就可以不限制血缘关系通信了，命名管道的名字在文件系统上，数据在内存中。
*   消息队列：linux自带的链表结构，进程可以读写。
*   共享内存：把一块物理内存映射到多个进程的地址空间，任何一个进程对数据的修改都是对其他进程可见的，所以需要加锁来控制同步什么的。

##### 2.CAS

compare and set：比较并赋值，CAS的操作是原子性的，保证同一时间只有一个线程执行赋值操作，在赋值操作前需要比较持有的旧值是否和当前变量的值相同，如果相同就修改，不同就不断的获取对象的新值然后在比较，知道自己持有的值和对象值形同在执行set操作。

ABA问题：比如一个对象被两个线程操作，A线程将对象加一在减一，B对象进行CAS加一操作的时候发现和自己持有的1相同，直接修改，如果是单纯的数字是没问题的，但是对象是个bean，A修改了某些属性，B比较的属性没有改变于是就对对象进行修改，解决办法是保证对象每次被修改就有一个值递增，每次CAS比较这个递增的属性就可以了。

##### 3.AQS

AbstractQueuedSynchronizer, 队列同步器，源码中定义了一个state变量、thread变量、FIFO队列，多个线程访问共享变量时，使用CAS比较thread变量然后对state执行加一操作，当state不是0的时候，说明有线程持有锁，这时会将当前线程存到FIFO队列中，如果state等于0，则state加一，然后thread赋值当前线程，当线程释放锁时，将state减一，如果state等于0，thread赋值null，和synchronized很像，不过AQS的实现类更灵活，比如reentrantLock获取锁可以设置超时和使用condition，并且可以实现公平锁，缺点就是需要手动释放锁。

##### 4.线程

###### 4.1 线程状态

![线程状态](https://raw.githubusercontent.com/wangxiaohong123/p-bed/main/uPic/线程状态.png)

waiting和timed_waiting属于一类，他俩和blocked不一样，比如说tomcat和dubbo在收到请求之后会调用对应的方法，调用完会处于两个waiting状态，等待方法执行完唤醒自己，处于这个状态说明对应的业务时正常运行的，而blocked说明获取锁失败需要等待唤醒之后再去拿锁，业务是没开始的状态。

###### 4.2 线程切换

每个线程会被CPU分配时间片，到时间或者主动让出CPU(比如wait()方法)就会发生切换。

##### 4.3 wait()和sleep()的区别

他俩都可以让线程暂停执行，wait()释放资源，或者说wait()释放的是当前对象的对象锁，所以wait()方法在Object类中，sleep()让当前线程暂停，不涉及到当前对象，所以sleep()定义在Thread类中。

###### 4.4 为什么不能直接调用Thread的run()方法

调用start()方法线程会进入RUNNABLE状态，此时会执行线程的准备工作，之后等到被分配了时间片就开始执行run()方法的内容，如果直接调用Thread的run()方法只会被当成一个普通方法被执行。

##### 5.线程池

###### 5.1 为什么用线程池

池化技术是为了减少获取资源的消耗，提高资源利用率。如果项目里需要频繁的创建和销毁线程的话就需要用线程池。

###### 5.2 常见线程池

*   SingleThreadExecutor：里面只有一个线程，无界队列。
*   FixedThreadExecutor：固定数量线程池，使用了无界队列(LinkedBlockingQueue)。适合负载稳定的场景。
*   CachedThreadExecutor：无界线程池，无限制的创建线程，高峰之后回收大量的空闲线程，使用SynchronousQueue。适合大部分时间负载很低，但是有少量高峰期。
*   ScheduledThreadExecutor：他的线程数量也不是固定的，使用DelayedWorkQueue，支持定时调度的线程池。

###### 5.3 常见的线程池API

最基础的是Executor接口，他有一个execute()方法，扔进去一个Runnable对象，就可以分配一个线程去执行。
ExecutorService是Executor的子接口，他有销毁线程池的方法，一个ExecutorService就是一个线程池管理器。
Executors：线程池的辅助类，可以通过这个类创建常见的线程池。
ThreadPoolExecutor：他是ExecutorService的实现类，通过这个类可以创建自定义线程池。

###### 5.4 怎么设置线程池参数

首先根据业务分析高峰期波动来确定核心线程数和最大线程数是否需要相同，然后在计算处理一个任务需要多少时间，根据并发设置核心线程数。队列的话尽可能不要设置成无界队列。如果任务是一定不能丢失的话可以自己实现拒绝策略，把没进池子的任务寻到本地，定时扫描重新提交。

###### 5.5 运行原理

线程池是一个生产者-消费者模式，当项目启动时，线程池中没有线程，只有一个空队列，在线程池收到一个任务时判断线程池中的线程数是否大于corePoolSize（核心线程数）：

* 如果小于核心线程数就创建一个线程执行收到的任务，执行结束后会去等待消费队列中的数据；
* 如果大于等于核心线程数就把任务放到队列中去，没有任务的线程就会去消费；
* 如果线程都在消费，并且队列已经满了，这时候会判断线程数是不是大于设置的最大线程数：
* * 如果不大于，就创建线程消费队列放不下的任务，在新创建的线程执行完任务后会去帮助核心线程消费队列中的任务；
  * 如果大于等于最大线程数任务会执行拒绝策略；

当线程空闲一段时间会判断当前线程数是否大于核心线程数，如果大于就会销毁空闲的线程，最多保留核心线程数个线程。

![线程池原理](https://raw.githubusercontent.com/wangxiaohong123/p-bed/main/uPic/线程池原理.png)

###### 5.6 无界队列的线程池，远程服务异常的情况下导致内存飙升

使用无界队列如果遇到高峰或者突发大流量打进来的时候队列中一直积压任务会导致内存飙升，然后说一下远程服务异常也肯能会导致线程中的线程异常，崩溃。每次有worker挂掉，就会被移出线程池，如果线程池中的线程小于corePoolSize就会马上创建一个线程，这样就会导致远程服务异常，线程池会频繁的创建线程。

###### 5.7 线程池怎么关闭

调用shutdown()方法后不允许提交新任务，等到池子里的任务执行完之后会关闭线程池。
调用shutdownNow()会返回还没执行的task列表，停止正在执行的task，关闭线程池。

##### 6.内存模型

![java内存模型](https://raw.githubusercontent.com/wangxiaohong123/p-bed/main/uPic/java内存模型.png)

##### 7.原子性、有序性、可见性

java规范里说变量（包括引用类型）的赋值是原子性的，除了基础的赋值，其他的操作都保证不了原子性。但是在32位系统上，long和double的赋值并不保证是原子性的，因为32位系统只有32位，而long和double有64位，所以需要分成高32位和低32位分开赋值，在多线程中，可能出现两个线程，一个赋值高32位，一个赋值低32位，就出错了。

###### 7.1 可见性

可见性问题就是一个CPU修改主内存中的变量，其他CPU不知道，这是因为CPU有很多组件来存储数据，比如寄存器、写缓冲器、高速缓存，线程处理数据的时候如果这些地方都没有就会去主内存把数据读到CPU的这些组件中，在修改了数据之后，就回去刷新读取数据的那个组件，如果实在寄存器或者写缓冲器里面，那么即使刷新，其他CPU也不知道你修改了，还有一种情况是刷新到高速缓存，或者刷新到高速缓存然后在刷新到主内存（这个是硬件决定的），如果是刷新到主内存，其他CPU的高速缓存中有这个数据的快照，也是不回去主内存中读取的，这就导致队列可见性问题。这时候MESI协议就出来了。

**保证可见性**就是用MESI协议和内存屏障（flush和refresh），当共享变量被修改的时候根据硬件不同可能会有两种操作：

*   执行flush操作，把变量刷新到高速缓存中，然后向消息总线发送消息，其他CPU接收到消息后执行refresh操作，从发送消息的CPU的高速缓存中把变量的最新值刷新到自己的高速缓存中；
*   执行flush操作，把变量刷新到高速缓存中，在把变量刷新到主内存中，然后向消息总线发送消息，其他CPU接收到消息后执行refresh操作，从主内存中把变量的最新值刷新到自己的高速缓存中；

###### 7.2 有序性

有序性就是指令重排导致的，很多情况都会导致指令重排(指令重排只是执行顺序被打乱，但是结果会保证和顺序执行一致)：

1.  编译优化的指令重排；
2.  JIT动态编译的指令重排；
3.  处理器的指令重排，处理器会乱序执行指令，执行完之后会经过重排序处理器，重排序处理器会按照处理器接收到的指令进行排序，然后发给高速缓存或者写缓冲器；
4.  内存重排序，高速缓存、写缓冲器、无效队列的指令重排，就是load、store重排；

指令重排的目的是为了提高指令执行效率，他们都会遵循happens-before原则。

##### 8.synchronized和volatile

从原子性、可见性、有序性分别说实现。再说volatile和Synchornized是怎么加内存屏障来解决有序性和可见性的，Synchronized加锁单独说，从Mrak Word到锁升级在到Object Monitor原理。

###### 8.1 synchonized和lock的区别

lock基于AQS，可以支持公平锁、可中断锁、读写锁，但是需要手动释放锁，在代码层面实现，synchronized是非公平锁，jvm层面实现，不需要手动释放锁。

##### 9.MESI协议

了解MESI协议要先说高速缓存，高速缓存的数据结构是一个拉链散列表，它里面有很多bucket，每个bucket上有很多cache entry，cache entry中有tag、cache line、和flag，tag是一个指向主内存中变量的指针，cache line是变量的值，他可以有很多值，flag就是MESI有关的状态，所以处理器获取数据的时候需要先找到是哪个bucket，然后在找到是哪个cache entry，最后在找到cache line中的数据，那么在处理器解码的时候就会从地址中解出来三个值，index、tag、offset，分别对应上面的三个信息，高速缓存有三级，L1，L2，L3，离处理器越近，速度越快。

MESI协议规定cache entry中的flag有四种状态，数据都是通过消息总线传输，但是由于硬件不同，处理器读取数据的时候可能是主内存发送数据到总线，也可能是其他处理器的高速缓存发送数据到总线：

*   invalidate：无效的，当一个处理器要修改数据的时候，会给总线发invalidate消息，其他处理器嗅探到这条消息之后就会把自己的高速缓存中的这条数据的flag改成I，然后返回invalidate ack消息，只有所有处理器都返回ack消息之后，这个处理器才能去修改这条数据，如果有一个没返回，就说明正在修改这个数据，这不就是加锁了么；
*   shared：共享的，当一个处理器要获取数据的时候，高速缓存中没有，这时候就会给总线发read消息，然后主内存或者其他高速缓存把数据发到总线，这个处理器读取到了数据之后把数据写到高速缓存中，这时候数据没有人修改，所以是shared；
*   exclusive：独占的，如果收到了所有处理器的ack消息，这个处理器就会把高速缓存中的数据的flag改成E，然后去修改；
*   modified：修改过的，修改完数据之后就把flag改成M，当一个处理器去读取数据的时候，发现高速缓存中的数据的flag是I，这时候还是往总线发送read消息，然后有个高速缓存发现自己的这条数据是M，就说明自己的这条数据是最新的，就会把这个变量发到总线，别的处理器就能收到了；

他们的首字母连起来就是MESI，不过这样处理就会有问题，因为一个处理器要修改数据要等到所有处理器返回ack消息，如果有一个处理器正在修改这个数据，就不会返回，这样这个处理器就一直在等，这样太慢了，这时候写缓冲器和无效队列就起作用了。

有了写缓冲器，处理器只需要把要修改的数据放到写缓冲器里然后在发送invalidate消息，这个处理器就可以去干别的了，其他处理器收到invalidate消息之后把消息放到无效系列中，然后就返回ack，队列中的消息去慢慢消费，消费到了就把数据变成I级别，修改数据的处理器收到所有ack消息后先把cache line中的数据变成E，然后再把写缓冲器中的数据写入cache line，然后再把数据级别变成M。

这样的话，MESI协议就会产生有序性和可见性的问题了，这应该算得上是有序性和可见性的底层原理了

*   有序性问题：最根本就是因为写缓冲器的存在，比如两个写的指令，一个写发现本地是S，这样他就要去发送invalidate消息到总线，然后把修改的值放到写缓冲器中，第二个写指令发现数据的状态是M就说明没人改过，所以他可以直接把高速缓存中的值覆盖掉，这样看起来就像第二条指令先执行，第一条指令后执行，因为虽然第一条指令先制令了，但是结果还在写缓冲器里。
*   可见性：写缓冲器会让写不会马上生效，无效队列会让读不会马上生效，所以就有可见性问题了，比如无效队列中有一条消息是把a的状态改成I，但是还没有消费，a的状态还是S，这时候这个处理器去读a的值发现状态是S就会直接拿出来用了，就出现了可见性的问题。

所以要解决可见性和有序性，就要配合内存屏障强制执行flush和refresh。

##### 10.happens-before

happens-before是为了保证程序的有序性，当代码满足happens-before规则的时候虚拟机进行指令重排，见并发编程笔记第一篇。

##### 11.为什么wait()要放到while()循环里

因为在线程被唤醒是可能不会马山执行任务，需要判断是否有其他线程对资源进行了修改，所以需要循环判断，只有满足条件才会继续执行操作。第二个原因可能因为wait指定了时间或者默写硬件原因造成线程的**假唤醒**，这个时候在wait()外面套一个while循环判断条件页可以防止假唤醒。

### JVM

##### 1.为什么堆内存最小最大要设置成一样的

heap resize比较耗时

##### 2.指针压缩（compressed oops）

32位的机器jvm最多只能用4G，因为只有2^32^个地址，转换成gb就是4，再多也没用，64位的机器就可以使用很大了，但是64位的指针站的字节数更多，会占用更高CPU的缓存通信带宽，所以堆内存在4g以下，jvm会使用指针压缩，使用32位指针代替64位指针。

##### 3.JVM有那几块内存区域，Java8之后有什么改进

不管是SpringBoot还是原来放到web容器中的项目，启动的都不是我们的代码，而是tomcat这种容器，tomcat启动后本身就是一个JVM进程，他负责接收请求然后去执行我们的代码。

Java7中有永久代：存放类，静态变量，常量池；堆内存：存放对象；虚拟机栈：字节码执行引擎：执行代码指令；每个线程都有一个自己的虚拟机栈，存放方法调用层级关系，每个栈针就是一个方法，栈针中有局部变量表，操作数栈、方法出口等，每个变量都是gc root；每个栈对应一个计数器，记录执行到哪里了；本地方法栈：存放jdk使用的native方法，比如Unsafe相关；堆外内存：他不属于jvm，可以通过ByteBuffer.allocateDirect申请。

Java8之后没有永久代，代替的是metaspace，存放类，永久代的常量池移到了堆内存中。

##### 4.堆外内存

堆外内存是jvm进程之外的内存，在启动java进程的时候会去跟操作系统申请一块启动参数相关的内存，其中最大的应该是堆内存了，但是申请的内存不包括堆外内存，需要单独申请：

```java
// 申请1k的堆外内存
ByteBuffer byteBuffer = ByteBuffer.allocateDirect(1024);
```

为什么要用堆外内存呢，因为当我们进行网络传输比如socket数据包或者磁盘IO的时候是要先将堆内存中的数据拷贝到堆外内存中，如果申请堆外内存并直接把数据写进去，这样在进行磁盘IO的时候就会少一次拷贝。

可以配置最大堆外内存大小。堆外内存存储的是对象，但是引用是在堆内存中的，在堆内存中有很多DirectByteBuffer，里面放的都是指针，指向堆外内存对象，当你去申请一块堆外内存，但是堆外内存剩余空间不够的时候就会把可以回收的directByteBuffer回收掉，释放一些堆外内存，如果这步之后还不够，就进行System.gc()，9次fullGC之后还内存不够就会抛出异常，当然是OOM。

##### 5.CPU100%排查

1.  定位进程：使用top -c查看耗费CPU的进程，然后输入P按使用率排序；
2.  定位线程：使用top -Hp 【PID】然后输入P按CPU使用率排序；
3.  把线程的PID转成16进制；
4.  jstack 【进程PID】 | grep '【线程16PID进制】' -C5 --color把线程的堆栈信息打印出来，看一下那个方法导致的CPU100%。

##### 6.类加载器和双亲委派

最上层是bootstrap加载器，加载java的核心类库，lib目录下的类；

第二层是ext的加载器，加载其他类库，lib/ext目录下的类；

第三层是application加载器，加载我们写的类；

最后一层是我们自定义的类加载器；

双亲委派说得是加载类时先到最顶层，如果最顶层没有就找下一层，这样可以避免重复加载。

##### 7.类加载机制

加载：使用类加载器把类加载到mateSpace中；

验证：jvm验证语法、字节码是否被篡改；

准备：给类分配内存空间，给类变量分配内存空间并且赋值成初始值；

解析：把符号引用替换成直接引用，就是把变量换成物理地址；

初始化：类变量赋值、执行静态代码块；

使用、卸载。

##### 8.对象在jvm中如何分配？如何流转

首先创建对象后会在堆内存的年轻代的Eden区分配一块内存，或者对象很大会直接进入老年代，当e区放不下新创建的对象时，会进行垃圾回收，如果找不到gc root就会被回收掉，当对象在年轻代躲过了一定次数的垃圾回收后会进入老年代，或者通过动态年龄判断后也会进入老年代，老年代快满的时候会执行full gc，清理掉没有gc root的对象。

##### 9.什么样的对象会被回收

使用可达性分析找不到gc root的对象会被回收，当存在gc root，但是是弱引用，也会被回收，如果是软引用，内存不够的时候才回收。

##### 10.常见的回收算法

标记清除：把垃圾对象标记，然后回收垃圾对象，会有内存碎片；

复制清除：分为两块区域，正常情况下有一块是空的，垃圾回收时，把有用对象复制到另一块内存中，再把第一块内存清掉，缺点，浪费空间，优化，把内存分成三块区域，一个Eden区，两个survivor区，对象在Eden区创建，垃圾回收时，把Eden区和一个s区的有用对象复制到另一个s区，在清空e区和一个s区；

##### 11.年轻代和老年代适合什么样的垃圾算法？

年轻代垃圾对象较多，适合复制清除算法，老年代大部分都是有用的对象，适合标记整理算法。

**G1**：G1中我们可以限制gc的时间，他有三个区域，年轻代、老年代和大对象，不过都是逻辑上的区分，他把堆内存分成2048个region，刚开始默认给年轻代5%个region存放对象，最多不能超过堆内存的60%，他的回收不是等到内存满了才进行，而是G1判断现在回收收益最高就执行一次回收，当老年代占用内存不超过45%的时候，老年代和年轻代都是使用复制算法回收，并且每个region属于年轻代还是老年代都是动态的，老年代占用内存超过45%的时候使用混合回收（Mixed gc），混合回收的前三个阶段都和CMS一样，第四个阶段会stw，如果一次回收不完就分多次回收，默认是8次，每次时间都不能超过我们设置的gc时间，如果空闲region达到5%（默认），就停止此次回收。

g1有缺点，他以region为单位回收，如果region中的85%都是存活对象，那么就不回收这个region，但是15%的垃圾对象也不回收了，相比G1，ParNew+CMS更可控，G1很难发现内存泄漏。

##### 12.频繁full gc的可能

如果CPU负载折线上升或者过一会就会卡死一会，可能就是频繁的full gc导致的。

*   内存分配不合理，s很小，放不下回收之后的存活对象；
*   创建的对象都很大，直接进入老年代；
*   内存泄漏，莫名其妙大量对象始终无法回收；
*   永久代满了，比如反射创建大量的类；
*   代码中调用System.gc()；

查看或者使用jstat查看gc情况，如果是第1种情况就修改新生代参数，如果是第2、3种原因需要dump内存快照，用mat工具分析，如果内存使用不多还频繁full gc一定是最后两种情况。

##### 13.CMS加ParNew调优

垃圾回收会导致stw，老年代回收更会占用CPU，所以调优一般都是尽量减少老年代回收，减少stw的时间。

什么时候会进入老年代？

1）默认躲过15次gc，进入老年代；

2）大对象直接进入老年代；

3）动态年龄判断；

4）当s区放不下的时候，所有对象都进入老年代；

1和2是可控的，一般会把15次调小点，因为假设30s一次young gc，躲过6次gc就是3分钟，很少有垃圾对象能存活三分钟，换句话说一般嫩存活3分钟的对象，大部分都能存活更久，所以把次数调小点，让他更早进入老年代，减少对s区内存的占用；大对象的话可以设置大一点，一般都是大数组这种，直接放到老年代中；

然后可以使用jstat -gc 30000 100这种命令观察jvm的内存情况，先看eu参数的增长速率，young gc的频率，然后看看young gc后有多少对象进入老年代，如果gc之后s区都是0，那么s区就给小了，放不下这些对象，s区不是0，老年代还增长了，那么可能是动态年龄判断导致的，也可以加大s区内存，如果老年代自己在增长，那么就是大对象，可以看看对象到底多大，调一下大对象的参数。

调整几次之后如果老年代还在增长，可以看一下gc频率，比如10分钟一次，那么就十分钟打印一次信息，再看看每次old gc回收多少内存，如果大部分都是存活的，那么可能就是内存泄漏，可以使用jmap打印一份快照，使用mat分析栈信息看看哪里泄露。

##### 14.jvm是怎么调优的

第一步先要预估每秒钟接收多少个请求，产生多少对象，每个对象大概多大，每秒钟会占用多少空间等等；

然后计算出来Eden区多长时间会占满，然后估算多长时间会发生young gc，每次gc的存活对象是多少，有多少对象进入老年代，多久触发一次old gc；

计算完初步分配年轻代和老年代比例，尽可能减少old gc；

然后压测，使用jstat观察内存使用，调整参数；

上线后持续观察；

比如说订单模块，在压测时估高峰算十万人同时在线，一人每分钟查询一次订单，高峰期四个小时，每人下一单，每秒钟大约有1700个请求左右，按照每个服务每秒抗400并发算，查询订单列表一条数据1kb，一次请求时10条，在加上折扣、商品其他信息一次请求大约会产生200k的对象，1s会产生60m左右的对象，这样一台4核8g的机器，jvm给4g，虚拟机栈分配1m，这样几百个线程占用几百兆，元数据空间分配256兆，这样也超不多1g了，堆内存分配3g，先按默认的年轻代，老年代每人一半，e区会占用1.1g，s区每个有150兆左右，这样来看，20s左右会触发一次young gc，并且150兆是完全够用的，但是实际压测时，17s左右的时候就会触发young gc，并且s区没增长，反倒是老年代在增长，每次增长90多兆，所以看出来，是young gc回收时存活对象超过了75兆，导致动态年龄判断，存活对象全部进入老年代，然后调整老年代大小为1g，这样s区就有200兆，就够用了。

在压测时，首先网关随便部署的，当时考虑他就是路由，没多少对象，就随便 放在一台服务器上，一共分配1g内存，但是压测时发生服务器卡死，CPU被占满，当时感觉网关的问题，使用jstat查看发现full gc频率很高，就是因为所有请求都走网关，所以1g肯定不够用。

##### 15.线上遇见的OOM事故

网关的堆外内存溢出

SQL获取数据过大

##### 16.G1和parnew+cms对比

parnew+cms方便管理，他只有e区、s区和老年代，G1需要管理很多region，并且region逻辑上是e区、s区、老年代区、大对象区和空闲分区。在小内存里parnew+cms并不会停顿很长时间，同时G1需要记录很多region相关的信息就需要占用更多的内存，在大内存里parnew+cms停顿时间过长，G1基于停顿预测模型可以空停顿时间，他可以调整垃圾回收和程序运行的一个平衡。
