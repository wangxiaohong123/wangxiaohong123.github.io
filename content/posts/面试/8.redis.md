---
title: 面试-8.redis
tags:
  - 面试专题
categories: 面试专题
copyright: true
---

##### 1.项目里怎么使用缓存，为什么用缓存

用缓存的地方比较多，比如一些读多写少的场景，动态、用户信息、存漂流瓶的池子等等；分布式锁；我还见过推荐系统的用户画像也存到redis里的。

使用redis可以减少数据库的压力(高并发)，还能减少接口的响应时间(高性能)。

##### 2.redis使用不当会有什么问题

###### 2.1.双写不一致问题

比如说获取用户信息的流程是先读缓存，缓存中没有就去数据库中查，然后在写缓存，修改数据库的流程是先改数据库，然后在更新缓存，如果在修改用户的同时有线程去查询用户，这个时候缓存刚好过期，那么就会把旧数据查出来然后放到缓存里，但是这个时候修改数据已经成功，再次把用户的新信息写到缓存中，此刻缓存的数据时没问题的，但是查询用户的线程会把从数据库里拿到的旧数据再次写到缓存中，就会出现问题。

最简单的方法就是加分布式锁，把读和写都加同一把锁，写请求可以把整个操作都加上锁，但是读操作的第一步先去缓存中查找是没有必要加锁的，而且加锁之后会严重影响性能，读操作需要在第二步也就是缓存中没有的话就先去数据库中查找，然后在写缓存，这步和写竞争同一把锁就可以了，还可以在拿到锁之后先去redis中再次查询，这样的double check可以优化上面的场景。
上面的解决方案有个问题就是大量的查询同一个用户的请求过来，这些大量的请求会串行执行，这样的性能也不高，所以可以在加锁的时候设置一个超时时间，如果到时见还没加锁成功就直接查缓存，这个超时转并发可以结局大量相同key读取的性能问题，但是有个问题就是一个写和大量读一起过来还是会有不一致问题，伪代码：

```java
public User getUserInfo(long userId) {
    String userInfoKey = "";
    String userInfoLockKey = "";
    String userString = redis.get(userInfoKey);
    if (StringUtils.hasLength(userString)) {
        return JsonObject.parseObject(userString, User.class);
    }

    try(加锁) {
        String userString = redis.get(userInfoKey);
        if (StringUtils.hasLength(userString)) {
            return JsonObject.parseObject(userString, User.class);
        }
        User user = userMapper.get(userId);
        redis.set(userInfoKey, user.toString(), 2天+随机几小时);
        if (加锁超时) {
            String userString = redis.get(userInfoKey);
            if (StringUtils.hasLength(userString)) {
                return JsonObject.parseObject(userString, User.class);
            } else {
                return fail;
            }
        }
    } catch(Exception e) {
        String userString = redis.get(userInfoKey);
        if (StringUtils.hasLength(userString)) {
            return JsonObject.parseObject(userString, User.class);
        } else {
            return fail;
        }
    }
}

public void updateUser(User user) {
    try (加锁) {
        userMapper.update(user);
        redis.set(userInfoKey, user.toString(), 2天+随机几小时);
    } catch(Exception e) {
        return fail;
    }
}
```

##### 2.2惊群和缓存穿透问题

惊群也叫雪崩就是突然在某个时间点出了一个故障，一堆机器或者线程或者进程被同时惊动，在redis中，比如存在一大批用户的缓存过期时间相同，同一时间点全部过期(加上过期时间是为了冷热分离，长时间没人访问的用户信息没必要存在缓存中)，这个时候查询这批用户的请求会全部打到MySQL中，出现惊群，首先要保证redis高可用，然后可以在写入redis时过期时间加上一个小随机数，可以是几个小时或者几十分钟。

缓存穿透也是redis中没有，去读数据库，但是数据库里也没有，比如bug或者被别人攻击，如果在查询，MySQL的时候也没有就给一个空值放到redis里。

##### 2.3并发冲突问题

可能会出现连续两个修改同一个信息的请求分发给了两个服务，这两个服务执行顺序错乱导致脏数据问题，如果顺序不对就是并发冲突。

解决：使用分布式锁来解决，修改的时候需要先比较时间，如果redis中的时间旧，才更新。

##### 3.为什么单线程的还这么快

redis线程模型：

![redis线程模型](https://raw.githubusercontent.com/wangxiaohong123/p-bed/main/uPic/redis线程模型.png)

redis和客户端是通过socket通信的，所以首先要有个socket server，在接收到连接请求后，会生成一个AE_READABLE事件，然后还有一个组件叫做IO多路复用程序，他负责轮询所有socket，当他发现socket产生了事件之后就会把事件压到队列中，还有个组件叫做文件事件分派器，文件事件分派器拿到队列的事件会分配给对应的事件处理器，这时候会把事件交给链接应答处理器，连接应答处理器会创建一个socket和客户端链接，然后把AE_READABLE事件和命令请求处理器关联，当下次收到AE_READABLE事件的时候会发现已经建立连接了，就会把事件分给命令请求处理器，命令请求处理器处理redis操作，然后把这个socket连接的AE_WRITEABLE事件和命令回复处理器关联，然后客户端说我准备好接收结果了，socket连接会产生一个AE_WRITEABLE事件，文件时间分派器会把AE_WRITEABLE交给命令回复处理器，命令回复处理器通过socket返回操作结果，然后取消事件绑定。

整个模型都在文件事件处理器中，文件事件处理器是单线程，之所以快因为两点：

1.  异步非阻塞，每个组件都有自己的任务，并且干完就会去干下一个，比如多路复用器，只把socket数据放到队列中就回去轮询下一个socket，事件处理器只负责自己的，应答处理器处理结束后就会去处理下一个应答，命令处理器处理完就回去处理下一个命令；
2.  三个处理器都是基于纯内存操作，可能一个操作只需要几微妙；

##### 4.数据类型

String：数据结构式SDS，分布式锁；

Hash：压缩列表或者hashTable；

List：压缩列表或者linkedList；

Set：压缩列表或者HashTable，hashTable的值都是null，这样就实现去重，为什么不直接用set？因为c语言没有set。

ZSet：压缩列表或者跳表，项目里漂流瓶的池子使用ZSet；

##### 5.过期策略和淘汰机制

一般使用redis时都会设置一下过期时间。

###### 5.1删除策略

删除策略：定期删除加惰性删除；每隔一段时间就找一部分过期key进行删除，因为如果每隔一段时间检查所有key对性能影响很大，所以每次抽一部分检查；还有没有删除的过期key，在查询数据的时候会发现这个key过期了就删掉；这样的可能会有大量的过期key堆积。

###### 5.2淘汰机制

*   noeviction：内存不足的时候直接报错；
*   allkeys-lru：移出最少使用的key；
*   alkeys-random：随机移除key；
*   volatile-lru：在设置了过期时间的key中移除最少使用的；
*   volatile-random：在设置了过期时间的key种随机移除；
*   volatile-ttl：优先移除最早过期的；

相关配置：

```properties
# 设置redis存放数据的内存大小，超过这个大小就会触发清理策略，64位机器如果不设置会不限制大小，32位机器默认3g
maxmemory 3gb
# 清理策略
maxmemory-policy
# 采样大小，因为redis默认使用的是pool加上近似LRU算法，采样越大LRU效果越好，但是消耗的CPU越高
maxmemory-samples 5
```

##### 6.高可用

单机redis能支持的QPS其实没多少，万级的。支持高并发的方案思路是读写分离或者集群，因为本身redis的使用场景就是读高并发。

*   redis replication：一个主节点负责写，多个salve负责读取操作，主节点会把数据同步到slave上，如果并发量更高的话直接添加slave就可以了。但是这个复制是异步的，或者脑裂这两种情况可能导致数据丢失，这两种情况的数据丢失可以通过参数控制。master必须要做持久化，因为如果没有持久化master宕机之后重启是没有数据的，然后他在把空数据同步到slave上，整个redis就都空了。主从读写分离的高可用主要是通过哨兵的主备切换和master检测实现的。
*   cluster：主从读写分离能存储的数量有限，如果数据量很大的话要使用集群，集群就是多master，当内存不够的时候就可以横向扩容。redis cluster使用的hash slot算法存储数据。

###### 6.1主从及原理：

slave node启动时保存配置文件中的master信息，然后启动一个定时任务，每秒检查master是否有变化和每秒上报offect，如果master配置了口令认证，就去认证，master会存储一个backlog，这个是断点续传用的，master和slave都有一份replic offect，用来记录数据同步到哪，slave会发送psync请求到master节点，master会根据传过来的master的run id，判断是否需要全量复制，因为根据ip加端口很不靠谱，可能master重启做了一些操作，这时候slave需要重新同步一下数据，根据ip加端口是判断不出来的，如果需要全量复制，master会执行full resynchronization的操作，生成全量的rdb快照（如果是无磁盘化就在内存中生成），这时候会在内存中记录最新的数据，把rdb文件发给slave，然后slave把rdb文件保存到磁盘上去，在加载到内存中（如果slave开启了aof会马上执行rewrite操作），然后master再把内存中最新的数据同步给slave。如果是重启的slave，master会把这之间的数据同步给slave。正常情况下master收到写请求就会异步给slave。slave不会过期key，只能是master发送del命令。master每10s向slave发送一次心跳，slave每1s向master发送一次心跳。

**主备切换的过程：**

首先先找到和master断开时间超过down-after-millionseconds * 10 + master宕机时间的slave，这些slave不参加选举，然后根据slave的优先级排序，找到第一个，存在相同优先级的就在找offset，找offset最大的，如果offset还相同就根据run id排序，取第一个。

**相关配置：**

```shell
# 无磁盘化赋值，master在内存中生成RDB文件
repl-diskless-sync no
# 等多少s后在开始，因为在内存中生成RDB，尽可能等更多的slave连上来
repl-diskless-sync-delay 5
# 从节点配置全量复制的超时时间，默认一分钟
repl-timeout 60

# 脑裂或者异步复制导致数据丢失配置
# 要求至少有1个slave数据的同步和延迟不能超过10s，一旦所有slave都超过10s，master就拒绝写，需要配合java客户端在本地缓存一下，然后降级减少写入的速度
min-slaves-to-write 1
min-slaves-max-lag 10
```

###### 6.2哨兵

一般和主从一起用。监控集群、故障转移（主备切换）、配置中心。

sdown：主观宕机，就是一个 哨兵认为master宕机了；如果一个哨兵ping master超过`is-master-down-after-millionseconds`秒后没有响应那么就是sdown了。

odown：客观宕机，大部分哨兵觉得master宕机；quorum数量的哨兵都sdown了master，就变成odown了。

```shell
# slave被选为master的优先级，越小优先级越高
slave-priority 100
```

###### 6.3集群

hash slot 整个集群固定16384个slot，每个master持有一部分，然后根据key的CRC16的值对16384取模，数据迁移的时候只要把对应slot移到别的master上就可以了。这样能保证一台机器宕机，只丢了一部分数据，找数据是去slot上找，而不是机器，一万多个slot也能保证数据分布的更均匀。

哨兵是用来保证redis的高可用性的，最少要部署三个节点，因为在主备切换的时候要求大部分哨兵同意才可以，如果两个哨兵节点，并且有一个哨兵节点宕机了，剩下的一个哨兵节点是没有办法完成选举的。

cluster使用的gossip协议，每个节点都维护了其他master的元数据信息，元数据变更了通知所有master去更新自己的元数据信息，这样可能会导致节点数据更新的延时。cluster是包含了主从和哨兵的，他们可以像哨兵一样客观认为一个master宕机，然后宕机master的slave根据自己同步数据的偏移量去选举一个新的master。

##### 7.持久化

###### 7.1持久化意义

为了故障恢复，如果没有持久化，在redis挂掉之后虽然会马上重启，但是里面没有数据，大量的查询会直接打到MySQL上，数据库就可能挂掉了。

###### 7.2RDB

每隔一段时间fork一个子进程生成一份完整的redis内存中数据的快照，然后替换原来的RDB文件。虽然是子进程在备份，但是会占用CPU资源，当数据过大时可能会导致redis卡顿。

优点：RDB更适合做冷备。虽然AOF也能做冷备，但是AOF做冷备需要自己实现定时copy一份文件，而且基于RDB来重启redis时恢复数据更快，因为他存的是数据，恢复的时候直接把数据放到内存就好了，所以他更适合做冷备。使用crontab定时把RDB文件拷贝到指定目录，每个一段时间上传到oss上。

缺点：因为是每隔一段时间生成一份备份，宕机之后可能会丢一部分数据；如果数据很多，生成备份的时候可能会使redis卡住一段时间，所以RDB的时间间隔一般不要太长。

配置：

```shell
# save检查点可以有多个
save 900 1
save 300 10
save 60 10000
```

意思是达到60s并且数据变化超过10000条或者300s数据变化超过10条或者900s数据变化超过1条就生成一个新的dump.rdb文件，生成完成后覆盖老的快照文件。

###### 7.3AOF

redis会把写操作放到os cache中，每隔一段时间（默认是1s）调用os cache的fsync操作把写命令添加到AOF文件的末尾，AOF文件只有一个，所以会越来越大，当大到一定程度的时候redis会另起一个线程，对照内存中的现有的数据，重医搞一份AOF文件，这个过程叫做rewrite。在这期间，如果有写操作发生，刷盘时会同时刷两个AOF文件，操作结束后删掉旧的AOF文件。

优点：数据更全；如果一个人不小心执行了flushall操作，可以把AOF日志的最后一个flushall命令删掉在重启redis，数据就回复了。

缺点：因为存的是命令，所以日志文件更大；rewrite操作可能会出现数据不一致；数据恢复比RDB慢。

配置：

```shell
# 是否开启aof，默认是关闭的
appendonly no
# aof备份名称
appendfilename "appendonly.aof"

# aof备份模式

# 每次redis中写入数据就同步写入到磁盘
# appendfsync always
# 将写入指令放到os cache中不管，由操作系统控制
# appendfsync no
# 每秒执行一次写入
appendfsync everysec

#rewirte条件，当下面两个条件都满足时进行rewrite操作
# aof文件大小超过上次rewrite之后大小的100%并且大小超过了auto-aof-rewrite-min-size就会去write
auto-aof-rewrite-percentage 100
# aof文件最小64m
auto-aof-rewrite-min-size 64mb
```

AOF文件破损之后可以使用./redis-check-aof --fix  [aof文件路径]来修复。

在使用redis-cli shutdown停掉redis时候会生成一份完整的RDB文件。RDB和AOF同时只能有一个在执行，因为太消耗磁盘IO了。

**注意：**

当同时存在aof和rdb文件时，redis默认使用aof恢复数据，因为redis认为aof数据更全更可靠，可以设置appendonly为no先关闭aof，这样redis会使用rdb恢复，数据回复完成后修改appendonly为yes，然后重启redis。

##### 8 redis故障怎么处理

redis出现节点挂掉一般都是临时原因，比如网络抖动，可以尝试重启，如果重启无法解决需要可以添加新节点，平时需要注意redis的监控和告警，可以通过配置redis exporter来使用普罗米修斯监控redis。

##### 9.redis6.0之后的raft协议和多线程

redis6.0之后针对处理网络io的请求使用了多线程，不过进入队列之后还是单线程来处理。

redis6.0之后集群使用raft协议，这个协议中只有leader能够读写请求，follower只能处理读请求(和6.0之前一样)，只用来当做leader宕机之后参加选举的候选人，在收到写请求时，leader会把数据同步到所有follower，超过半数follower返回同步成功后才给客户端返回成功响应。当通过raft协议选举出新的leader之后，首先会等待所有节点数据完成同步，这可以保证数据量少的节点被选择成leader后的数据不丢失，在数据同步完成前不会处理客户端请求。

我认为6.0之后采用的raft协议对数据的一致性和可用性都提高很多，也可以解决采用redis集群添加分布式锁时，leader宕机导致的锁失效。但是因为数据的同步机制和选举时不处理客户端请求会对性能有一点影响。

