---
title: 10.kafka源码-服务端网络通信
date: 2021-09-20 06:27:35
tags:
  - 大数据
categories: kafka
copyright: true
---

在本地安装scala2.10.7、gradle3.1、和zk。

到kafka官网下载0.10.01的源码，然后进入kafka-0.10.0.1-src目录执行下面目录为idea构建：

```shell
gradle idea
```

构建的时候出现如下错误：

![](https://tva1.sinaimg.cn/large/008i3skNly1gtjdo5h9p3j61z40l8ada02.jpg)

打开build.gradle文件，在import和build script中间加上以下代码重新构建即可：

```
ScalaCompileOptions.metaClass.daemonServer = true
ScalaCompileOptions.metaClass.fork = true
ScalaCompileOptions.metaClass.useAnt = false
ScalaCompileOptions.metaClass.useCompileDaemon = false
```

然后打开idea安装scala插件，导入kafka源码。

### 结构

*   bin：一些执行脚本
*   checkstyle：静态代码的检查配置
*   clients：客户端代码，用java写的
*   config：配置文件
*   connect：这个是kafka一个新的项目，把数据源的数据引入进来，比如说把数据交给clients项目
*   core：消息系统，使用scala写的
*   streams：kafka提供的流式计算的项目，java写的

修改server.properties的log.dirs路径，然后在edit configurations做如下配置：

![](https://tva1.sinaimg.cn/large/008i3skNly1gtjevv6zy8j61ko0u0tck02.jpg)

运行core下的kafka文件启动测试。

进入core模块，在最下面有一个kafka的类，这个就是启动类，里面有一个main方法：

```scala
def main(args: Array[String]): Unit = {
    try {
        // 读取配置
        val serverProps = getPropsFromArgs(args)
        // 创建KafkaServerStartable对象
        val kafkaServerStartable = KafkaServerStartable.fromProps(serverProps)

        // 处理control + c杀掉进程用的
        Runtime.getRuntime().addShutdownHook(new Thread() {
            override def run() = {
                kafkaServerStartable.shutdown
            }
        })
		// kafkaServerStartable启动，其实里面调用的就是server包下的KafkaServer的startup()方法
        kafkaServerStartable.startup
        // 关闭事件
        kafkaServerStartable.awaitShutdown
    }
    catch {
        case e: Throwable =>
        fatal(e)
        System.exit(1)
    }
    System.exit(0)
}
```

在KafkaServer的startUp()中初始化了所有组件，核心的是下面这些：

```scala
// 设置成启动中状态
val canStartup = isStartingUp.compareAndSet(false, true)
// 统计组件
metrics = new Metrics(metricConfig, reporters, kafkaMetricsTime, true)
brokerState.newState(Starting)
// 后台的一些定时任务
kafkaScheduler.startup()
// zookeeper
zkUtils = initZk()
// 操作磁盘文件的组件
logManager = createLogManager(zkUtils.zkClient, brokerState)
logManager.startup()
/* generate brokerId */
config.brokerId =  getBrokerId
// 网络通信组件
socketServer = new SocketServer(config, metrics, kafkaMetricsTime)
socketServer.startup()
// 管理副本的组件
replicaManager = new ReplicaManager(config, metrics, time, kafkaMetricsTime, zkUtils, kafkaScheduler, logManager, isShuttingDown)
replicaManager.startup()
// 管理集群的
kafkaController = new KafkaController(config, zkUtils, brokerState, kafkaMetricsTime, metrics, threadNamePrefix)
kafkaController.startup()
// 管理消费者的
groupCoordinator = GroupCoordinator(config, zkUtils, replicaManager, kafkaMetricsTime)
groupCoordinator.startup()
// 这个是处理请求的
apis = new KafkaApis(socketServer.requestChannel, replicaManager, groupCoordinator,
                     kafkaController, zkUtils, config.brokerId, config, metadataCache, metrics, authorizer)
// 启动处理请求的线程池，大小为num.io.threads(默认8)个
requestHandlerPool = new KafkaRequestHandlerPool(config.brokerId, socketServer.requestChannel, apis, config.numIoThreads)
brokerState.newState(RunningAsBroker)
……
// 停止用到的CountDownLatch
shutdownLatch = new CountDownLatch(1)
// 状态变成启动完成
startupComplete.set(true)
isStartingUp.set(false)
```

### 初始化

上面看到网络通信的源码有两部分，第一个是负责接收请求、返回响应的的socketServer.startup()，还有一个是真正处理请求的KafkaApis，先看SocketServer的startUp方法：

```scala
def startup() {
    this.synchronized {
		// 管理连接上线的，就是说每个ip建立的连接不能超过多少
        connectionQuotas = new ConnectionQuotas(maxConnectionsPerIp, maxConnectionsPerIpOverrides)
		// 接收、发送缓冲大小和brokerId
        val sendBufferSize = config.socketSendBufferBytes
        val recvBufferSize = config.socketReceiveBufferBytes
        val brokerId = config.brokerId
        var processorBeginIndex = 0
        // 这个endpoints就是配置中的listeners，监听的ip加端口，是一个数组，配置中用逗号分割
        endpoints.values.foreach { endpoint =>
            val protocol = endpoint.protocolType
            // numProcessorThreads是process线程的大小，对应配置num.network.threads
            // 在config模块里的server.properties中看到默认是3个
            val processorEndIndex = processorBeginIndex + numProcessorThreads
            for (i <- processorBeginIndex until processorEndIndex)
            	// 实例化Processor，可以看到会创建listener大小 * (默认3个)的Processor
            	// 把创建的Processor存到数组中
            	processors(i) = newProcessor(i, connectionQuotas, protocol)
			// 实例化一个Acceptor，他是一个Runnable
            val acceptor = new Acceptor(endpoint, sendBufferSize, recvBufferSize, brokerId,
                                        processors.slice(processorBeginIndex, processorEndIndex), connectionQuotas)
            // acceptors是一个map，就是说每一个listener或者说每一个endpoint都会对应一个Acceptor
            acceptors.put(endpoint, acceptor)
            // 然后把Acceptor放到线程里启动
            Utils.newThread("kafka-socket-acceptor-%s-%d".format(protocol.toString, endpoint.port), acceptor, false).start()
            // 这个里面是一个countdownLunch的await，意思是要等这个线程启动完了在进行后面的操作
            // 后面有一些不重要的代码没有放上来
            acceptor.awaitStartup()
            processorBeginIndex = processorEndIndex
        }
    }
}
```

简单看一下Processor类，他也是一个Runnable，里面有一个KSelector实例，这一看就是kafka对nio的Selector的封装，还有一个run方法，Processor一定是在别的地方封到了线程里然后启动，所以这里先看一下run方法里面的东西：

```scala
while (isRunning) {
    try {
        // 处理队列中的连接
        configureNewConnections()
        // 响应逻辑
        processNewResponses()
        // poll逻辑
        poll()
        // 接收完成的数据处理
        processCompletedReceives()
        // 发送完成的数据处理
        processCompletedSends()
        // 连接断开处理
        processDisconnected()
    }
}
// 结束逻辑
shutdownComplete()
```

这里不具体看每个方法的内容，继续往下走，进入实例化Acceptor中：

```scala
// 这里有启动了一个NSelector，这个就是原生的nio的Selector
private val nioSelector = NSelector.open()
// 启动ServerSocketChannel，设置非阻塞、接收缓冲大小什么的
val serverChannel = openServerSocket(endPoint.host, endPoint.port)
this.synchronized {
    // 把刚才放进数组的Processor实例封装成线程启动
    processors.foreach { processor =>
        Utils.newThread("kafka-network-thread-%d-%s-%d".format(brokerId, endPoint.protocolType.toString, processor.id), processor, false).start()
    }
}
```

到此请求的监听就启动完成了，接着看请求处理逻辑的初始化，KafkaApis的实例化差不多把之前的所有创建的组件都传了进去，KafkaApis的handle方法是处理请求的主入口，里面封装了各种请求的处理分支：

```scala
def handle(request: RequestChannel.Request) {
    try {
        ApiKeys.forId(request.requestId) match {
            case ApiKeys.PRODUCE => handleProducerRequest(request)
            case ApiKeys.FETCH => handleFetchRequest(request)
            case ApiKeys.LIST_OFFSETS => handleOffsetRequest(request)
            case ApiKeys.METADATA => handleTopicMetadataRequest(request)
            case ApiKeys.LEADER_AND_ISR => handleLeaderAndIsrRequest(request)
            case ApiKeys.STOP_REPLICA => handleStopReplicaRequest(request)
            case ApiKeys.UPDATE_METADATA_KEY => handleUpdateMetadataRequest(request)
            case ApiKeys.CONTROLLED_SHUTDOWN_KEY => handleControlledShutdownRequest(request)
            case ApiKeys.OFFSET_COMMIT => handleOffsetCommitRequest(request)
            case ApiKeys.OFFSET_FETCH => handleOffsetFetchRequest(request)
            case ApiKeys.GROUP_COORDINATOR => handleGroupCoordinatorRequest(request)
            case ApiKeys.JOIN_GROUP => handleJoinGroupRequest(request)
            case ApiKeys.HEARTBEAT => handleHeartbeatRequest(request)
            case ApiKeys.LEAVE_GROUP => handleLeaveGroupRequest(request)
            case ApiKeys.SYNC_GROUP => handleSyncGroupRequest(request)
            case ApiKeys.DESCRIBE_GROUPS => handleDescribeGroupRequest(request)
            case ApiKeys.LIST_GROUPS => handleListGroupsRequest(request)
            case ApiKeys.SASL_HANDSHAKE => handleSaslHandshakeRequest(request)
            case ApiKeys.API_VERSIONS => handleApiVersionsRequest(request)
            case requestId => throw new KafkaException("Unknown api code " + requestId)
        }
    } finally
    request.apiLocalCompleteTimeMs = SystemTime.milliseconds
}
```

实例化完KafkaApis之后就把他提交到了requestHandlerPool中封装成线程启动。

##### Acceptor接收请求

Acceptor中的run方法就是不断的在轮询selector，和客户端的代码差不多，只不过多了一个iter.remove()，删除处理的selectionKey，核心代码：

```scala
var currentProcessor = 0
while (isRunning) {
    try {
        val ready = nioSelector.select(500)
        if (ready > 0) {
            val keys = nioSelector.selectedKeys()
            val iter = keys.iterator()
            while (iter.hasNext && isRunning) {
                val key = iter.next
                iter.remove()
                // 如果key是建立连接请求
                if (key.isAcceptable)
                	// 建立连接
                	accept(key, processors(currentProcessor))
                // 通过取余-轮询的方式获取下一个分发的processor索引
                currentProcessor = (currentProcessor + 1) % processors.length
            }
        }
    }
}
```

建立连接代码：

```scala
// 创建SocketChannel
val serverSocketChannel = key.channel().asInstanceOf[ServerSocketChannel]
val socketChannel = serverSocketChannel.accept()
try {
    // 配置一些参数，长连、TcpNoDelay、发送缓冲大小
    connectionQuotas.inc(socketChannel.socket().getInetAddress)
    socketChannel.configureBlocking(false)
    socketChannel.socket().setTcpNoDelay(true)
    socketChannel.socket().setKeepAlive(true)
    socketChannel.socket().setSendBufferSize(sendBufferSize)
    // 然后把SocketChannel放进ConcurrentLinkedQueue队列中
    processor.accept(socketChannel)
} 
```

把创建好的SocketChannel放进队列之后Processor线程的在run方法中的第一行configureNewConnections()就会拿到刚刚创建SocketChannel注册到Selector上：**selector.register(connectionId, channel)**，其中的connectionId是当前服务器和客户端服务器的ip、端口的组合，所以直接看kafka封装的Selector的register方法：

```scala
// 直接注册到nioSelector上去，并且关注OP_READ事件
SelectionKey key = socketChannel.register(nioSelector, SelectionKey.OP_READ);
// 封装一个channel，把channel和SelectionKey相互关联
KafkaChannel channel = channelBuilder.buildChannel(id, key, maxReceiveSize);
key.attach(channel);
// channels是一个map，存放<connectionId,KafkaChannel>
this.channels.put(id, channel);
```

到此Acceptor的任务就结束了。

##### Processor接收请求

Processor处理接收请求就是上面的while(true)循环中的几个方法，第一个就是处理连接，在Acceptor中已经说完了，直接看处理响应的方法：

```scala
private def processNewResponses() {
    // 响应会放到队列中，这个就是从队列里poll出来
    var curr = requestChannel.receiveResponse(id)
    while (curr != null) {
        try {
            curr.responseAction match {
                // 当响应是无动作的时候，什么时候会产生无动作的响应这里还不知道
                case RequestChannel.NoOpAction =>
                	curr.request.updateRequestMetrics
                	// 这个就是说据需关注OP_READ事件
                	selector.unmute(curr.request.connectionId)
                // 发送响应
                case RequestChannel.SendAction =>
                	sendResponse(curr)
                case RequestChannel.CloseConnectionAction =>
                	curr.request.updateRequestMetrics
                	// 关闭的处理
                	close(selector, curr.request.connectionId)
            }
        } finally {
            curr = requestChannel.receiveResponse(id)
        }
    }
}
```

sendResponse方法里面也没什么代码，最关键的两行：

```scala
// 这个其实就是增加关注OP_WRITE事件
selector.send(response.responseSend)
// inflightResponses是一个map，把connectionId和对应的response放到map中
inflightResponses += (response.request.connectionId -> response)
```

poll()方法最终会走到Selector的poll方法中

```java
public void poll(long timeout) throws IOException {
    // 清除一些队列
    clear();
    long startSelect = time.nanoseconds();
    // readyKeys和客户端的是一样的，判断有事件的SelectionKey的个数
    int readyKeys = select(timeout);
    long endSelect = time.nanoseconds();
    currentTimeNanos = endSelect;
    this.sensors.selectTime.record(endSelect - startSelect, time.milliseconds());

    if (readyKeys > 0 || !immediatelyConnectedKeys.isEmpty()) {
        // 这块和客户端的代码也很像
        // 完成连接就维护连接
        // 读事件就从stagedReceives拿到channel对应的ArrayDeque，然后插入队列的尾部
        // 写事件就直接调用channel.write，然后取消关注OP_WRITE事件
        pollSelectionKeys(this.nioSelector.selectedKeys(), false);
        pollSelectionKeys(immediatelyConnectedKeys, true);
    }
	// 遍历stagedReceives，他的数据结构是这样的Map<KafkaChannel, Deque<NetworkReceive>
    // 往completedReceives中插入NetworkReceive
    addToCompletedReceives();
    long endIo = time.nanoseconds();
    // 检查有没有超时的连接
    maybeCloseOldestConnection();
}
```

继续走到接收完成processCompletedReceives()的处理逻辑中，这里也就是把二进制转换成RequestChannel.Request，然后入队，追加到requestQueue中，这是一个ArrayBlockingQueue。

往下走到发送完成processCompletedSends()方法中，这个方法里把发送完的请求从inflightResponses中移除，然后取消关注OP_READ事件，取消是为了每次每个客户端只读取一个请求。

最后一个processDisconnected方法，其实在检查出来超时连接的时候已经在selector中调用channel.close();关闭了连接，这里就是处理inflightResponses和connectionQuotas。

##### KafkaApis处理请求

在启动的时候是吧KafkaApis封装到KafkaRequestHandler类中，这个类是一个Runnable，然后在封装到线程中通过线程池启动，在KafkaRequestHandler的run方法里的一个while(true)中不断地读取请求然后交给apis的handle方法，还记得上面看到的读取完的请求时放到了RequestChannel的requestQueue中去的吧？while(true)循环中就是在调用requestQueue的poll方法，这样处理请求就闭环了，核心的处理逻辑都在apis的handleProducerRequest()方法中，这个方法不想粘代码了，主要就是把消息写到replica中，在kafka中，不管是leader还是follower都是replica，然后封装response然后放到RequestChannel的responseQueues中。

