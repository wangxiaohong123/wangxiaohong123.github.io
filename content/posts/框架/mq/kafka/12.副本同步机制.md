---
title: 12.kafka源码-副本同步机制
date: 2021-09-25 06:27:35
tags:
  - 大数据
categories: kafka
copyright: true
---

##### 大致流程

之前在看刷盘的源码的时候看到初始化ReplicaManager的时候创建了一些组件，其中就有一个replicaFetcherManager，看名字就知道这个是负责副本同步的，他实例化了一个ReplicaFetcherManager对象，这个类只有两个方法，createFetcherThread()和shutdown()，再进父类AbstractFetcherManager中看一下，发现父类中多了两个方法：addFetcherForPartitions和removeFetcherForPartitions，add方法就是为一部分分区创建同步的线程，回到ReplicaManager中找一下在哪用到了add方法，然后就找到了方法：makeFollowers()，思路大概就懂了，在broker感知到自己负责了某个partition的副本后，就调用这个方法，然后创建线程，不断地拉取和更新数据，首先看下方法注释：

```scala
/*
   * 说得是让这个broker负责的一批partition变成follower都有哪些步骤
   * Make the current broker to become follower for a given set of partitions by:
   *
   * 把这些分区的leader从leader的set中移除
   * 1. Remove these partitions from the leader partitions set.
   * 把这些partition标记成follower，这样任何producer都不能往这写分区中写数据
   * 2. Mark the replicas as followers so that no more data can be added from the producer clients.
   * 对这些分区停止已有的replica fetcher线程
   * 3. Stop fetchers for these partitions so that no more data can be added by the replica fetcher threads.
   * 把这些分区的日志阶段，记录offset
   * 4. Truncate the log and checkpoint offsets for these partitions.
   * 清理掉分区的延迟调度
   * 5. Clear the produce and fetch requests in the purgatory
   * 给新的副本分区添加fetcher
   * 6. If the broker is not shutting down, add the fetcher to the new leaders.
   *
   * 保证不会有脏数据
   */
```

进到AbstractFetcherManager的addFetcherForPartitions()方法，循环创建fetcherThread：

```scala
for ((brokerAndFetcherId, partitionAndOffsets) <- partitionsPerFetcher) {
    var fetcherThread: AbstractFetcherThread = null
    fetcherThreadMap.get(brokerAndFetcherId) match {
        case Some(f) => fetcherThread = f
        case None =>
        // createFetcherThread调用的是子类的方法
        fetcherThread = createFetcherThread(brokerAndFetcherId.fetcherId, brokerAndFetcherId.broker)
        fetcherThreadMap.put(brokerAndFetcherId, fetcherThread)
        fetcherThread.start
    }
}
```

子类的createFetcherThread方法只是在创建ReplicaFetcherThread对象，这个类继承了AbstractFetcherThread，子类中没找到run方法，去父类中看一下，父类AbstractFetcherThread继承了ShutdownableThread，ShutdownableThread是一个线程，里面有run方法，run方法中是一个死循环调用doWork()方法，doWork()在AbstractFetcherThread类中，大概的流程差不多知道了，核心逻辑就在dowork中：

```scala
override def doWork() {
    val fetchRequest = inLock(partitionMapLock) {
        // partitionMap是真对leader都在某个broker上的一批分区
        // 封装了一个fetchRequest发送给一个broker，说我们这有一批分区的副本的leader都在你的机器上，我现在要拉取数据
        val fetchRequest = buildFetchRequest(partitionMap)
        if (fetchRequest.isEmpty) {
            partitionMapCond.await(fetchBackOffMs, TimeUnit.MILLISECONDS)
        }
        fetchRequest
    }
    if (!fetchRequest.isEmpty)
    	// 处理fetch
    	processFetchRequest(fetchRequest)
}
```

##### 构建fetchRequest

构建的方法buildFetchRequest()是在子类实现的：

```scala
protected def buildFetchRequest(partitionMap: Map[TopicAndPartition, PartitionFetchState]): FetchRequest = {
    val requestMap = mutable.Map.empty[TopicPartition, JFetchRequest.PartitionData]
    // 遍历一个map
    partitionMap.foreach { case ((TopicAndPartition(topic, partition), partitionFetchState)) =>
        if (partitionFetchState.isActive)
        	// 创建这个对象JFetchRequest.PartitionData
        	// 传进去了两个关键的参数，一个从什么地方开始拉取，一个拉取的最大值
        	// 拉取的最大值fetchSize默认是1M
        	requestMap(new TopicPartition(topic, partition)) = new JFetchRequest.PartitionData(partitionFetchState.offset, fetchSize)
    }
	// minBytes：一次请求过去至少要拉取多少数据，默认是1
    // 最多等待maxWait(默认500ms)，超过了这个事件就算没拉取到数据也会返回
    // JFetchRequest中还有很多参数
    // 然后封装成FetchRequest返回
    new FetchRequest(new JFetchRequest(replicaId, maxWait, minBytes, requestMap.asJava))
}
```

##### 发送请求

封装完FetchRequest就会走到processFetchRequest()方法，开始处理请求，进入方法就执行了fetch()方法：

```scala
// 发送请求
val clientResponse = sendRequest(ApiKeys.FETCH, Some(fetchRequestVersion), fetchRequest.underlying)
// 封装响应
new FetchResponse(clientResponse.responseBody).responseData.asScala.map { case (key, value) =>
    TopicAndPartition(key.topic, key.partition) -> new PartitionData(value)
}
```

再看sendRequest()方法：

```scala
// 继续封装一层请求
val send = new RequestSend(sourceBroker.id.toString, header, request.toStruct)
val clientRequest = new ClientRequest(time.milliseconds(), true, send, null)
// 同步发送
// networkClient之前都看过了，就是把请求放到inflightRequest中
// 怎么实现同步的不太懂scala的语法，应该就是处理完nio响应唤醒或者一直轮询从那个地方读
networkClient.blockingSendAndReceive(clientRequest)(time)
```

另一个broker端是怎么处理请求的呢？通过networkClient发送的请求之前已经看到了所有的处理都在KafkaApis中，然后找到处理fetch请求的方法handleFetchRequest()，这个方法中定义了一个回调函数，然后在最底部通过ReplicManager的fetchMessages来处理请求：

```scala
def fetchMessages(timeout: Long,
                    replicaId: Int,
                    fetchMinBytes: Int,
                    fetchInfo: immutable.Map[TopicAndPartition, PartitionFetchInfo],
                    responseCallback: Map[TopicAndPartition, FetchResponsePartitionData] => Unit) {
    // 从本地磁盘读取数据，这里面肯定有分区索引的使用，需要定位到磁盘位置
    val logReadResults = readFromLocalLog(fetchOnlyFromLeader, fetchOnlyCommitted, fetchInfo)
    // 更新follower的leo和leader的hw
    if(Request.isValidBrokerId(replicaId))
    	// 这个方法里不止更新follower的fetch结果
    	// 还有之前如果ack=-1的时候，leader没有返回结果，等到follower来拉取数据的时候判断所有副本是不是都同步了最新的消息
    	// 如果所有follower都fetch到了最新的消息还要唤醒等待返回发送结果的任务
    	// 就是调用了delayedProducePurgatory.checkAndComplete(key)
		updateFollowerLogReadResults(replicaId, logReadResults)
    // 读取到数据的处理，直接就封装数据然后通过回调函数返回
    if(timeout <= 0 || fetchInfo.size <= 0 || bytesReadable >= fetchMinBytes || errorReadingData) {
        val fetchPartitionData = logReadResults.mapValues(result =>
                                                          FetchResponsePartitionData(result.errorCode, result.hw, result.info.messageSet))
        responseCallback(fetchPartitionData)
    } else {
        // 没读取到数据也会封装成一个DelayedFetch
        val fetchPartitionStatus = logReadResults.map { case (topicAndPartition, result) =>
            (topicAndPartition, FetchPartitionStatus(result.info.fetchOffsetMetadata, fetchInfo.get(topicAndPartition).get))
        }
        val fetchMetadata = FetchMetadata(fetchMinBytes, fetchOnlyFromLeader, fetchOnlyCommitted, isFromFollower, fetchPartitionStatus)
        val delayedFetch = new DelayedFetch(timeout, fetchMetadata, this, responseCallback)
        val delayedFetchKeys = fetchPartitionStatus.keys.map(new TopicPartitionOperationKey(_)).toSeq
		// 尝试完成或者放到延迟调度的组件中
        // delayedFetchPurgatory是一个基于时间轮实现的延时调度，以后可以看一下
        delayedFetchPurgatory.tryCompleteElseWatch(delayedFetch, delayedFetchKeys)
    }
}
```

readFromLocalLog()方法是非常琐碎的逻辑，比如找到leader的分区信息，拿到高水位，找到segment等等，最终会走到LogSegment的read()方法，先根据offset和position找到消息：

```scala
// 根据稀疏索引你确定从那个物理位置找到数据
val startPosition = translateOffset(startOffset)
```

然后读取磁盘，细节就不看了：

```scala
FetchDataInfo(offsetMetadata, log.read(startPosition.position, length))
```

继续往下走到updateFollowerLogReadResults()方法，这个方法是更新leo、hw、isr的入口，更新这些东西有两个入口，一个是之前看到的启动时创建的定时任务，还有一个这个，最终都会走到Replic里，定时任务调用的是maybeShrinkIsr()方法，fetch的时候调用的是maybeExpandIsr()方法，先看maybeShrinkIsr：

```scala
def maybeShrinkIsr(replicaMaxLagTimeMs: Long) {
    val leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) {
        leaderReplicaIfLocal() match {
            case Some(leaderReplica) =>
            // 拿到同步太慢的follower
            // 这个方法的注释中说超过10s没来拉取或者10s没落后的太多的follower都要从isr移除
            // 但是这个方法只处理了超时
            val outOfSyncReplicas = getOutOfSyncReplicas(leaderReplica, replicaMaxLagTimeMs)
            if(outOfSyncReplicas.size > 0) {
                val newInSyncReplicas = inSyncReplicas -- outOfSyncReplicas
                assert(newInSyncReplicas.size > 0)
                // 更新isr列表
                updateIsr(newInSyncReplicas)
                replicaManager.isrShrinkRate.mark()
                // 更新hw，两种情况会更新
                // isr列表变更和副本的leo变更
                // 拿到所有副本的leo最小值赋值给hw
                maybeIncrementLeaderHW(leaderReplica)
            }
        }
    }
}
```

再看maybeExpandIsr()方法：

```scala
def maybeExpandIsr(replicaId: Int) {
    val leaderHWIncremented = inWriteLock(leaderIsrUpdateLock) {
        leaderReplicaIfLocal() match {
            case Some(leaderReplica) =>
            val replica = getReplica(replicaId).get
            val leaderHW = leaderReplica.highWatermark
            // 如果当前fetch的follower的leo大于leader的hw
            if(!inSyncReplicas.contains(replica) &&
               assignedReplicas.map(_.brokerId).contains(replicaId) &&
               replica.logEndOffset.offsetDiff(leaderHW) >= 0) {
                val newInSyncReplicas = inSyncReplicas + replica
                // 就把这个follower加到isr列表里
                updateIsr(newInSyncReplicas)
                replicaManager.isrExpandRate.mark()
            }
			// 更新hw
            maybeIncrementLeaderHW(leaderReplica)
            case None => false // nothing to do if no longer leader
        }
    }
}
```

放入实践时间轮后等到时间到或者有新的消息时，之前看到在Partition的appendMessagesToLeader中有一行代码：

```scala
// 这个方法调用的是delayedFetchPurgatory.checkAndComplete(key)
replicaManager.tryCompleteDelayedFetch(new TopicPartitionOperationKey(this.topic, this.partitionId))
```

细节没有再看，具体是让任务直接调用callback返回空然后马上会在发送fetch请求过来，还是拿到任务的信息，重新走一遍fetch方法？两个用到时间轮的地方以后再看。