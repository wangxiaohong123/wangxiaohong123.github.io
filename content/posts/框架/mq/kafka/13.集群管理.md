---
title: 13.kafka源码-集群管理
date: 2021-09-27 06:27:35
tags:
  - 大数据
categories: kafka
copyright: ture
---

在KafkaServer中有一个组件是KafkaController，这个组件就是管理集群的核心组件，每个broker都会有一个controller，但是多个broker中只会有一个controller能够选举成功，其他broker也需要监听controller的状态，controller自己也需要自己检查健康状态，所以还有两个组件也是跟集群相关的，一个是zkUtils还有一个是KafkaHealthcheck线程。

##### 选举controller

先看KafkaController的startup()方法：

```scala
def startup() = {
    inLock(controllerContext.controllerLock) {
        // 注册一个跟zk会话断开的监听器
        registerSessionExpirationListener()
        isRunning = true
        // 竞争
        controllerElector.startup
    }
}
```

然后进到ZookeeperLeaderElector的startup()方法：

```scala
def startup {
    inLock(controllerContext.controllerLock) {
        // 在/controller这个znode上，注册一个监听器
        // 如果有人竞争成为controller，他会感知到
        // 如果有人已经成为了controller，然后自己挂掉了，不再是controller，也会感知到
        controllerContext.zkUtils.zkClient.subscribeDataChanges(electionPath, leaderChangeListener)
        // 发起选举
        elect
    }
}
```

上面的leaderChangeListener是ZookeeperLeaderElector的内部类，它里面有两个方法，一个handleDataChange，一个handleDataDeleted，就是节点变更和删除的回调。

发起选举的代码其实就是注册节点，注册成功就是选举成功：

```scala
def elect: Boolean = {
    val timestamp = SystemTime.milliseconds.toString
    val electString = Json.encode(Map("version" -> 1, "brokerid" -> brokerId, "timestamp" -> timestamp))
    // 获取controllerId
    leaderId = getControllerID 
    // 如果不是-1就说明集群里有人成为controller了
    // 直接返回就可以
    if(leaderId != -1) {
        return amILeader
    }
    try {
        // 尝试创建/controller这个znode
        // 里面的值就是electString，代表自己的controller
        val zkCheckedEphemeral = new ZKCheckedEphemeral(electionPath,
                                                        electString,
                                                        controllerContext.zkUtils.zkConnection.getZookeeper,
                                                        JaasUtils.isZkSecurityEnabled())
        zkCheckedEphemeral.create()
        // zk会保证同一时间只有一个broker创建成功这个节点
        // 创建成功了就把自己标记成controller
        leaderId = brokerId
        // KafkaController的onControllerResignation()方法
        // 处理一些状态
        onBecomingLeader()
    } catch {
        case e: ZkNodeExistsException =>
            // 失败就拿到controller的id
            leaderId = getControllerID 
        case e2: Throwable =>
        	resign()
    }
    amILeader
}
```

再看一下controller宕机的监听：handleDataDeleted()

```scala
def handleDataDeleted(dataPath: String) {
    inLock(controllerContext.controllerLock) {
        if(amILeader) {
            // 如果当前节点是controller就要重置一些状态
            onResigningAsLeader()
        }
        // 重新注册节点
        elect
    }
}
```

##### 选举完了broker是怎么注册的

注册的组件是KafkaHealthcheck，broker启动的时候会注册到/brokers/ids/[0...N]节点上，后面的数字就是broker的Id，然后这个类的注释说了一下这个类名起的很幼稚，很不认同，如果注册成功就是Health的，如果不成功就是dead。

他的startup方法会调用register()方法

```scala
def register() {
    val jmxPort = System.getProperty("com.sun.management.jmxremote.port", "-1").toInt
    val updatedEndpoints = advertisedEndpoints.mapValues(endpoint =>
        if (endpoint.host == null || endpoint.host.trim.isEmpty)
			EndPoint(InetAddress.getLocalHost.getCanonicalHostName, endpoint.port, endpoint.protocolType)
        else
            endpoint
    )
    val plaintextEndpoint = updatedEndpoints.getOrElse(SecurityProtocol.PLAINTEXT, new EndPoint(null,-1,null))
    // 封装broker的ip、端口这些信息，注册到zk上
    zkUtils.registerBrokerInZk(brokerId, plaintextEndpoint.host, plaintextEndpoint.port, updatedEndpoints, jmxPort, rack,
                               interBrokerProtocolVersion)
}
```

回到KafkaController的构造方法中，他在创建选举组件的时候传了一个方法进去

```scala
// 选举组件
  private val controllerElector = new ZookeeperLeaderElector(controllerContext, ZkUtils.ControllerPath, onControllerFailover,onControllerResignation, config.brokerId)
```

就是这个onControllerFailover，这个里面会注册大量的监听：

1.   controller变更的时间
2.   增加controller的epoch
3.   初始化controller上下文
4.   初始化controller跟其他broker的通信组件
5.   监听副本状态
6.   监听分区状态，包括分区的isr列表

方法中有一行代码很关键：

```scala
replicaStateMachine.registerListeners()
```

注册broker状态改变的监听，里面调用的是registerBrokerChangeListener()方法，就是在zk上添加BrokerChangeListener监听。

BrokerChangeListener里面就干一件事，拿到新的broker和宕机的broker，新的就添加，然后建立连接，宕机的就删掉。然后在KafkaController的onBrokerStartup()方法中把节点变更的消息通过nio发送给所有broker。在删掉宕机的broker的时候会判断是不是leader，是leader还要重新选举。

##### 监听topic变更

还是在onControllerFailover方法里注册针对/broker/topics的监听：

```scala
// 这个方法里会注册topic变更事件、删除事件
partitionStateMachine.registerListeners()
```

##### Rebalance

重平衡使用的是kafka-reassign-partitions.sh脚本，在bin目录下，点进去看到他只是执行kafka.admin.ReassignPartitionsCommand这个类，这个类有个main方法：

```scala
// 前面是获取参数，实例化一个zkUtil
try {
    if(opts.options.has(opts.verifyOpt)) {
        // 生成方案
        verifyAssignment(zkUtils, opts)
    } else if(opts.options.has(opts.generateOpt)) {
        // 检查方案
        generateAssignment(zkUtils, opts)
    } else if (opts.options.has(opts.executeOpt)) {
        // 执行方案
        executeAssignment(zkUtils, opts)
    }
} catch {
    case e: Throwable =>
    println("Partitions reassignment failed due to " + e.getMessage)
    println(Utils.stackTrace(e))
} finally {
    // 关闭zkClient
    val zkClient = zkUtils.zkClient
    if (zkClient != null)
    zkClient.close()
}
```

执行的方法中，把文件里的内容读出来继续调用executeAssignment(zkUtils, reassignmentJsonString)方法，然后先校验后执行：

```scala
val reassignPartitionsCommand = new ReassignPartitionsCommand(zkUtils, partitionsToBeReassigned.toMap)
// 对于一个分区现获取当前的分区副本方案
val currentPartitionReplicaAssignment = 
zkUtils.getReplicaAssignmentForTopics(partitionsToBeReassigned.map(_._1.topic))
// 执行方案
if(reassignPartitionsCommand.reassignPartitions())
```

最后在reassignPartitions方法把重平衡方案写到zk中，controller一定会监听这个节点，一旦感知到节点变更，就会执行副本重分配

```scala
val jsonReassignmentData = zkUtils.formatAsReassignmentJson(validPartitions)
zkUtils.createPersistentPath(ZkUtils.ReassignPartitionsPath, jsonReassignmentData)
```

KafkaController在启动的时候会注册重平衡组件：

```scala
private val partitionReassignedListener = new PartitionsReassignedListener(this)
```

在这个重平衡监听类中的handleDataChange方法会拿到刚刚设置的重平衡信息，遍历调用controller.initiateReassignReplicasForTopicPartition(partitionToBeReassigned._1, context)方法，执行重平衡，然后在这个方法里又调用了onPartitionReassignment(topicAndPartition, reassignedPartitionContext)来重新分配副本，这个方法只读了注释，代码没看：

```scala
/**
   * RAR = Reassigned replicas 重新分配的副本
   * OAR = Original list of replicas for partition 这个分区原始的副本
   * AR = current assigned replicas 新分配的副本的列表
   *
   * 每个topic在创建的时候都有副本分配方案写入zk中
   * 基于重分配的方案更新zk中分区副本方案
   * 1. Update AR in ZK with OAR + RAR.
   *
   * 对于重新分配的副本，每个副本所在的broker都发一个LeaderAndIsr的请求
   * 2. Send LeaderAndIsr request to every replica in OAR + RAR (with AR as OAR + RAR). We do this by forcing an update
   *    of the leader epoch in zookeeper.
   *
   * 把分配走的副本迁移
   * 3. Start new replicas RAR - OAR by moving replicas in RAR - OAR to NewReplica state.
   *
   * 等待重新分配的副本跟leader保持同步就认为重新分配成功
   * 4. Wait until all replicas in RAR are in sync with the leader.
   *
   * 把迁移后的新分配的副本改成online状态
   * 5  Move all replicas in RAR to OnlineReplica state.
   *
   * 更新内存中的分区的实际副本状态
   * 6. Set AR to RAR in memory.
   *
   * 重新选举
   * 7. If the leader is not in RAR, elect a new leader from RAR. If new leader needs to be elected from RAR, a LeaderAndIsr
   *    will be sent. If not, then leader epoch will be incremented in zookeeper and a LeaderAndIsr request will be sent.
   *    In any case, the LeaderAndIsr request will have AR = RAR. This will prevent the leader from adding any replica in
   *    RAR - OAR back in the isr.
   *
   * 一堆更新
   * 8. Move all replicas in OAR - RAR to OfflineReplica state. As part of OfflineReplica state change, we shrink the
   *    isr to remove OAR - RAR in zookeeper and sent a LeaderAndIsr ONLY to the Leader to notify it of the shrunk isr.
   *    After that, we send a StopReplica (delete = false) to the replicas in OAR - RAR.
   * 9. Move all replicas in OAR - RAR to NonExistentReplica state. This will send a StopReplica (delete = false) to
   *    the replicas in OAR - RAR to physically delete the replicas on disk.
   * 10. Update AR in ZK with RAR.
   * 11. Update the /admin/reassign_partitions path in ZK to remove this partition.
   * 12. After electing leader, the replicas and isr information changes. So resend the update metadata request to every broker.
   */
```

