---
title: 14.kafka源码-consumer
date: 2021-09-27 06:27:35
tags:
  - 大数据
categories: kafka
copyright: true
---

先看看consumer是怎么初始化的，进到KafkaConsumer的构造方法里，里面初始化了一堆东西，retryBackoffMs、metadata、NetworkClient这些之前都看过了，然后又实例化一个ConsumerCoordinator，最后是一个Fetcher。在我们自己的代码中使用consumer的poll方法拉取消息，所以猜测主要功能都在这个方法中实现，比如自动提交offset，进到ConsumerCoordinator的构造方法里看一下：

```java
// 父类的构造方法
super(client,
      groupId,
      sessionTimeoutMs,
      heartbeatIntervalMs,
      metrics,
      metricGrpPrefix,
      time,
      retryBackoffMs);
// 元数据
this.metadata = metadata;
this.metadata.requestUpdate();
this.metadataSnapshot = new MetadataSnapshot(subscriptions, metadata.fetch());
// 我们代码里consumer负责的topic
this.subscriptions = subscriptions;
this.defaultOffsetCommitCallback = defaultOffsetCommitCallback;
this.autoCommitEnabled = autoCommitEnabled;
this.assignors = assignors;
addMetadataListener();
if (autoCommitEnabled) {
    // 自动提交任务
    this.autoCommitTask = new AutoCommitTask(autoCommitIntervalMs);
    this.autoCommitTask.reschedule();
} else {
    this.autoCommitTask = null;
}
this.sensors = new ConsumerCoordinatorMetrics(metrics, metricGrpPrefix);
this.interceptors = interceptors;
this.excludeInternalTopics = excludeInternalTopics;
```

但是没看到把consumer加入group的代码，其实加入group的代码在KafkaConsumer的pollOnce()方法中，这个方法被poll调用，在这个方法里有一行代码

```java
coordinator.ensureCoordinatorReady();
// 保证coordinator已经分配好了分区
coordinator.ensurePartitionAssignment();
```

这个方法中会继续调用ensureActiveGroup()方法，这个是父类AbstractCoordinator中的方法，这个方法里继续调用ensureCoordinatorReady()方法，妈的调用了这个方法，在pollOnce方法中第一行就是调用这个方法，这个方法中继续调用sendGroupCoordinatorRequest()方法，这个方法里封装了一个GroupCoordinatorRequest然后获取consumer group的Coordinator信息，回到ensureActiveGroup方法中，会调用下面代码发送joinGroup请求：

```java
// 请求类型是ApiKeys.JOIN_GROUP
RequestFutrue<ByteBuffer> futrue = sendJoinGroupRequest();
```

##### consumer leader选举

到KafkaApis中找到JPIN_GROUP对应的处理方法handleJoinGroupRequest(request)，首先定义了一个回调函数：

```scala
// 定义一个回调函数
def sendResponseCallback(joinResult: JoinGroupResult) {
    // group成员
    val members = joinResult.members map { case (memberId, metadataArray) => (memberId, ByteBuffer.wrap(metadataArray)) }
    // 响应消息
    val responseBody = new JoinGroupResponse(joinResult.errorCode, joinResult.generationId, joinResult.subProtocol,
                                             joinResult.memberId, joinResult.leaderId, members)
    requestChannel.sendResponse(new RequestChannel.Response(request, new ResponseSend(request.connectionId, responseHeader, responseBody)))
}
```

然后调用GroupCoordinator的handleJoinGroup()方法：

```java
coordinator.handleJoinGroup(
    joinGroupRequest.groupId,
    joinGroupRequest.memberId,
    request.header.clientId,
    request.session.clientAddress.toString,
    joinGroupRequest.sessionTimeout,
    joinGroupRequest.protocolType,
    protocols,
    // 刚才定义的回调，很关键
    sendResponseCallback)
```

```scala
var group = groupManager.getGroup(groupId)
// 如果还没创建这个消费者组
if (group == null) {
    if (memberId != JoinGroupRequest.UNKNOWN_MEMBER_ID) {
        responseCallback(joinError(memberId, Errors.UNKNOWN_MEMBER_ID.code))
    } else {
        // 创建组消费者组
        group = groupManager.addGroup(new GroupMetadata(groupId, protocolType))
        // 加入消费者组
        doJoinGroup(group, memberId, clientId, clientHost, sessionTimeoutMs, protocolType, protocols, responseCallback)
    }
} else {
    doJoinGroup(group, memberId, clientId, clientHost, sessionTimeoutMs, protocolType, protocols, responseCallback)
}
```

看一下doJoinGroup的代码，里面就是根据group的状态来执行具体的逻辑：

```scala
group.currentState match {
    case Dead =>
    	// 如果是dead状态，可能是group被别的线程删了，或者coordinator不稳定，需要重试
    	responseCallback(joinError(memberId, Errors.UNKNOWN_MEMBER_ID.code))
    case PreparingRebalance =>
    	// 在一定时间内收到consumer请求后就是这个状态
        if (memberId == JoinGroupRequest.UNKNOWN_MEMBER_ID) {
            addMemberAndRebalance(sessionTimeoutMs, clientId, clientHost, protocols, group, responseCallback)
        } else {
            val member = group.get(memberId)
            updateMemberAndRebalance(group, member, protocols, responseCallback)
        }
    case AwaitingSync =>
    	// 等一段时间之后就会变成这个状态
        if (memberId == JoinGroupRequest.UNKNOWN_MEMBER_ID) {
            addMemberAndRebalance(sessionTimeoutMs, clientId, clientHost, protocols, group, responseCallback)
        } else {
            val member = group.get(memberId)
            if (member.matches(protocols)) {
                responseCallback(JoinGroupResult(
                    members = if (memberId == group.leaderId) {
                        group.currentMemberMetadata
                    } else {
                        Map.empty
                    },
                    memberId = memberId,
                    generationId = group.generationId,
                    subProtocol = group.protocol,
                    leaderId = group.leaderId,
                    errorCode = Errors.NONE.code))
            } else {
                updateMemberAndRebalance(group, member, protocols, responseCallback)
            }
        }
    case Stable =>
        if (memberId == JoinGroupRequest.UNKNOWN_MEMBER_ID) {
            addMemberAndRebalance(sessionTimeoutMs, clientId, clientHost, protocols, group, responseCallback)
        } else {
            val member = group.get(memberId)
            if (memberId == group.leaderId || !member.matches(protocols)) {
                updateMemberAndRebalance(group, member, protocols, responseCallback)
            } else {
                responseCallback(JoinGroupResult(
                    members = Map.empty,
                    memberId = memberId,
                    generationId = group.generationId,
                    subProtocol = group.protocol,
                    leaderId = group.leaderId,
                    errorCode = Errors.NONE.code))
            }
        }
}
```

但是一看不管是那种状态走的好像都是updateMemberAndRebalance方法，在这个方法中调用了group.add(member.memberId, member)方法：

```scala
def add(memberId: String, member: MemberMetadata) {
    // 谁先请求，谁就是leader
    if (leaderId == null)
    	leaderId = memberId
    members.put(memberId, member)
}
```

##### consumer leader指定分区方案

回到ensureActiveGroup方法中，调用完sendJoinGroupRequest()方法后会收到一个RequestFutrue的响应，拿到结果后会走到RequestFeatrue的响应监听里：

```java
futrue.addListener(new RequestFutrueListener<ByteBuffer>() {
    @Override
    public void onSuccess(ByteBuffer value) {
        // 成功处理，感觉在这里会制定分区方案
        onJoinComplete(generation, memberId, protocol, value);
        needsJoinPrepare = true;
        heartbeatTask.reset();
    }
    @Override
    public void onFailure(RuntimeException e) {
        // 没有动作
    }
});
```

还有一个点就是在sendJoinGroupRequest()方法中构建了一个CoordinatorResponseHandler的子类JoinGroupResponseHandler，看这个类的handle()方法：

```java
if (joinResponse.isLeader()) {
    // 是leader的处理
    onJoinLeader(joinResponse).chain(futrue);
} else {
    // 是follower的处理
    onJoinFollower().chain(futrue);
}
```

先看onJoinComplete()方法：

```java
// 分区分配组件
PartitionAssignor assignor = lookupAssignor(assignmentStrategy);
// 分区
assignor.onAssignment(assignment);
```

再看是leader的处理，就是把结果发送给group coordinator

```java
private RequestFutrue<ByteBuffer> onJoinLeader(JoinGroupResponse joinResponse) {
    try {
        Map<String, ByteBuffer> groupAssignment = performAssignment(joinResponse.leaderId(), joinResponse.groupProtocol(), joinResponse.members());
        SyncGroupRequest request = new SyncGroupRequest(groupId, generation, memberId, groupAssignment);
        return sendSyncGroupRequest(request);
    } catch (RuntimeException e) {
        return RequestFutrue.failure(e);
    }
}
```

然后在服务端收到请求后还是在KafkaApis里会调用handleSyncGroupRequest方法，根据每个member的回调把信息发送给每个member

##### poll消费数据

直接进到pollOnce方法中：

```java
private Map<TopicPartition, List<ConsumerRecord<K, V>>> pollOnce(long timeout) {
    // 之前看过的确保coordinator和partition是可用的
    coordinator.ensureCoordinatorReady();
    if (subscriptions.partitionsAutoAssigned())
        coordinator.ensurePartitionAssignment();
    if (!subscriptions.hasAllFetchPositions())
        updateFetchPositions(this.subscriptions.missingFetchPositions());

    long now = time.milliseconds();
    // execute delayed tasks (e.g. autocommits and heartbeats) prior to fetching records
    client.executeDelayedTasks(now);
    // fetch数据
    Map<TopicPartition, List<ConsumerRecord<K, V>>> records = fetcher.fetchedRecords();
    // 拉取到数据就返回
    if (!records.isEmpty())
        return records;
	// 没有拉取到就异步拉取
    fetcher.sendFetches();
    client.poll(timeout, now);
    return fetcher.fetchedRecords();
}
```

然后在ConsumerCoordinator里面有一个AutoCommitTask，会自动提交offset，看一下run方法：

```java
public void run(final long now) {
    if (coordinatorUnknown()) {
        reschedule(now + retryBackoffMs);
        return;
    }

    if (needRejoin()) {
        reschedule(now + interval);
        return;
    }

    commitOffsetsAsync(subscriptions.allConsumed(), new OffsetCommitCallback() {
        @Override
        public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets, Exception exception) {
            if (exception == null) {
                reschedule(now + interval);
            } else {
                reschedule(now + interval);
            }
        }
    });
}
```

##### 宕机及rebalance

在创建ConsumerCoordinator的时候父类会创建一个心跳线程：HeartbeatTask，run方法里有个sendHeartbeatRequest()，就是发送心跳，然后coordinator就可以感知到consumer的存活，当感知到这个consumer宕机的时候就会把这个consumer负责的分区分配给其他consumer。

到KafkaApis中看handleHeartbeatRequest()方法，方法里会调用GroupCoordinator的handleHeartbeat()方法，这里就是一些判断，更新状态什么的，然后最关键的是会创建一个定时任务completeAndScheduleNextHeartbeatExpiration(group, member)，当定时任务执行的时候还没有收到心跳，就认为cosumer宕机了：

```scala
private def completeAndScheduleNextHeartbeatExpiration(group: GroupMetadata, member: MemberMetadata) {
    // complete current heartbeat expectation
    member.latestHeartbeat = time.milliseconds()
    val memberKey = MemberKey(member.groupId, member.memberId)
    heartbeatPurgatory.checkAndComplete(memberKey)
    // 计算下一次检查心跳时间
    val newHeartbeatDeadline = member.latestHeartbeat + member.sessionTimeoutMs
    // 创建心跳超时检查
    // DelayedHeartbeat里面有个方法onExpiration()
    // 会执行GroupCoordinator的onExpireHeartbeat()方法
    val delayedHeartbeat = new DelayedHeartbeat(this, group, member, newHeartbeatDeadline, member.sessionTimeoutMs)
    // 把任务放到时间轮中
    heartbeatPurgatory.tryCompleteElseWatch(delayedHeartbeat, Seq(memberKey))
}
```

跟到onExpireHeartbeat方法中

```scala
def onExpireHeartbeat(group: GroupMetadata, member: MemberMetadata, heartbeatDeadline: Long) {
    group synchronized {
        // 如果没收到心跳的处理
        if (!shouldKeepMemberAlive(member, heartbeatDeadline))
        	onMemberFailure(group, member)
    }
}
```

```scala
private def onMemberFailure(group: GroupMetadata, member: MemberMetadata) {
    // 把consumer从group中移除
    group.remove(member.memberId)
    group.currentState match {
        case Dead =>
        // 重新分配分区
        case Stable | AwaitingSync => maybePrepareRebalance(group)
        case PreparingRebalance => joinPurgatory.checkAndComplete(GroupKey(group.groupId))
    }
}
```

