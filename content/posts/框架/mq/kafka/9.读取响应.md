---
title: 9.kafka源码-读取响应
date: 2021-08-06 06:27:35
tags:
  - 大数据
categories: kafka
copyright: ture
---

之前看到过producer的连接、发送、读取消息都是在Selector的poll方法中，跟进去之后看到读取消息在attemptRead()方法中：

```java
private void attemptRead(SelectionKey key, KafkaChannel channel) throws IOException {
    // 如果channel连接正常，并且关注了读事件或者有缓冲池中有消息可以读取
    // hasStagedReceive(channel)，这个是一个暂存队列，没搞懂，可能防止重复读取
    // explicitlyMutedChannels.contains(channel)这个会判断一个list中是否有这个channel，但是没看到插入的动作，所以这个判断一直是true
    if (channel.ready() && (key.isReadable() || channel.hasBytesBuffered()) && !hasStagedReceive(channel)
        && !explicitlyMutedChannels.contains(channel)) {
        NetworkReceive networkReceive;
        // 开始读取
        while ((networkReceive = channel.read()) != null) {
            madeReadProgressLastPoll = true;
            // 往上面的暂存队列里插入这个channel
            // 在poll方法的最后一行会把channel从stage里移出
            addToStagedReceives(channel, networkReceive);
        }
        if (channel.isMute()) {
            outOfMemory = true; //channel has muted itself due to memory pressure.
        } else {
            madeReadProgressLastPoll = true;
        }
    }
}
```

进到kafkaChannel的read()方法里：

```java
public NetworkReceive read() throws IOException {
    NetworkReceive result = null;
    if (receive == null) {
        receive = new NetworkReceive(maxReceiveSize, id, memoryPool);
    }
    // 读取数据
    receive(receive);
    // 判断receive是否完成，
    // !size.hasRemaining() && buffer != null && !buffer.hasRemaining()
    if (receive.complete()) {
        // position设置成0
        receive.payload().rewind();
        result = receive;
        // 接收完了就要置成null
        receive = null;
    }
    return result;
}
```

继续往下跟进入读取数据的核心代码，在NetWorkReceive的readFromReadableChannel()中：

```java
public long readFromReadableChannel(ReadableByteChannel channel) throws IOException {
    // read存放已经读取出来的字节数
    int read = 0;
    // 如果size可以读取
    if (size.hasRemaining()) {
        // 数据读取到size中
        int bytesRead = channel.read(size);
        if (bytesRead < 0)
            throw new EOFException();
        read += bytesRead;
        if (!size.hasRemaining()) {
            size.rewind();
            int receiveSize = size.getInt();
            requestedBufferSize = receiveSize; //may be 0 for some payloads (SASL)
            if (receiveSize == 0) {
                buffer = EMPTY_BUFFER;
            }
        }
    }
    if (buffer == null && requestedBufferSize != -1) { 
        buffer = memoryPool.tryAllocate(requestedBufferSize);
    if (buffer != null) {
        int bytesRead = channel.read(buffer);
        if (bytesRead < 0)
            throw new EOFException();
        read += bytesRead;
    }

    return read;
}
```

上面的几十行代码是工业级的拆包粘包的解决方案，主要就是通过size和buffer来实现的，size表示整个消息的大小，4个字节，buffer是消息体：

##### 解决粘包问题

在readFromReadableChannel方法中会先判断size.hasRemaining()，这个意思就是说position和limit中间差了多少位，表示能不能读取数据，如果可以读取，就会读取4个字节的数据到size中，然后直接size.getInt()取出来buffer的长度，然后下面通过buffer = memoryPool.tryAllocate(requestedBufferSize)创建一个刚刚读取出来的长度的buffer，通过channel.read(buffer)把数据读到buffer中，通过这个逻辑解决了粘包的问题。

##### 解决拆包问题

拆包就分为size的拆包和buffer的拆包，当size被拆包的时候判断**if (!size.hasRemaining()) {**不会继续往下走，因为没有读完，然后buffer是空，但是requestedBufferSize是-1，所以不会去读取buffer，然后就一直返回进行下一轮poll，但是之前创建的NetworkReceive没有变成空，里面还有没读完的size，在下一次poll进来的时候会发现size.hasRemaining()为true，继续读取size，知道size读完。

当buffer被拆包的时候有一步关键的判断是receive.complete()，里面的实现是**!size.hasRemaining() && buffer != null && !buffer.hasRemaining()**，buffer.hasRemaining()为真，没有完成，并不会把NetworkReceive设置成空，所以还是会在下一次poll中继续读取buffer，知道buffer.hasRemaining()为false。

##### 拿到请求后的处理

回到NetworkClient的poll方法，this.selector.poll()执行完后继续往下走：

```java
long updatedNow = this.time.milliseconds();
List<ClientResponse> responses = new ArrayList<>();
// 发送完成
handleCompletedSends(responses, updatedNow);
// 接收完成
handleCompletedReceives(responses, updatedNow);
// 连接失败
handleDisconnections(responses, updatedNow);
handleConnections();
handleInitiateApiVersionRequests(updatedNow);
// 判断超时
handleTimedOutRequests(responses, updatedNow);
// 处理刚刚解析出来的响应
completeResponses(responses);
```

直接进到handleCompletedReceives方法中

```java
// 遍历刚刚读到的数据
for (NetworkReceive receive : this.selector.completedReceives()) {
    String source = receive.source();
    // 从inFlightRequests移除完成的请求
    InFlightRequest req = inFlightRequests.completeNext(source);
    // 下面两行是吧buffer转成消息实体的，就是先把头读出来，然后多少个字节对应那个字段这样的
    Struct responseStruct = parseStructMaybeUpdateThrottleTimeMetrics(receive.payload(), req.header,
                                                                      throttleTimeSensor, now);
    AbstractResponse body = AbstractResponse.parseResponse(req.header.apiKey(), responseStruct);
    // 是否是元数据
    if (req.isInternalRequest && body instanceof MetadataResponse)
        metadataUpdater.handleCompletedMetadataResponse(req.header, now, (MetadataResponse) body);
    // 是否是api信息
    else if (req.isInternalRequest && body instanceof ApiVersionsResponse)
        handleApiVersionsResponse(responses, req, now, (ApiVersionsResponse) body);
    // 正常消息
    else
        responses.add(req.completed(body, now));
}
```

把消息放进responses中后会执行几步的简单处理，然后进入completeResponses方法，这个方法里会调用ClientResponse的callback.onComplete(this)方法，这个callback是创建Response的时候传进来的，但是是在发送的时候，也就是Sender的sendProduceRequest()方法中创建的，所以我们回到了Sender的创建callback方法：handleProduceResponse()中：

```java
// 连接失败的处理
if (response.wasDisconnected()) {
    for (ProducerBatch batch : batches.values())
        completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.NETWORK_EXCEPTION), correlationId, now);
} else if (response.versionMismatch() != null) {
    log.warn("Cancelled request {} due to a version mismatch with node {}",
             response, response.destination(), response.versionMismatch());
    for (ProducerBatch batch : batches.values())
        completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.UNSUPPORTED_VERSION), correlationId, now);
} else {
    // 处理请求，ack不是0，有响应的正常处理逻辑
    if (response.hasResponse()) {
        ProduceResponse produceResponse = (ProduceResponse) response.responseBody();
        // 遍历响应的partition
        for (Map.Entry<TopicPartition, ProduceResponse.PartitionResponse> entry : produceResponse.responses().entrySet()) {
            TopicPartition tp = entry.getKey();
            ProduceResponse.PartitionResponse partResp = entry.getValue();
            // 拿到partition对应的batch
            ProducerBatch batch = batches.get(tp);
            // 处理响应
            completeBatch(batch, partResp, correlationId, now);
        }
        this.sensors.recordLatency(response.destination(), response.requestLatencyMs());
    } else {
        // 这个是没有响应的情况，也就是ack=0
        for (ProducerBatch batch : batches.values()) {
            completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.NONE), correlationId, now);
        }
    }
}
```

多个参数的completeBatch方法主要是判断异常，如果是正常会走到2个参数的completeBatch方法中：

```java
private void completeBatch(ProducerBatch batch, ProduceResponse.PartitionResponse response) {
    ……
    // 这里调用callback方法
    if (batch.done(response.baseOffset, response.logAppendTime, null))
        // 这块的意思是释放这个batch，其实主要就是把这个batch在放到freebuffer里
        // 然后还有一步就是使用condition的await唤醒之前因为内存不够阻塞的线程
        this.accumulator.deallocate(batch);
}
```

一步一步跟进最后进入到ProducerBatch的completeFutureAndFireCallbacks方法：

```java
// 设置偏移量什么的
produceFuture.set(baseOffset, logAppendTime, exception);
// Thunk就对应了我们实现的callback
for (Thunk thunk : thunks) {
    try {
        if (exception == null) {
            RecordMetadata metadata = thunk.future.value();
            if (thunk.callback != null)
                // onCompletion就是我们实现callback重写的那个方法
                thunk.callback.onCompletion(metadata, null);
        } else {
            if (thunk.callback != null)
                thunk.callback.onCompletion(null, exception);
        }
    } catch (Exception e) {
        // 打印了一个日志
    }
}
// CountDownLatch操作了一下
produceFuture.done();
```

正常的逻辑就走完了，然后回到多个参数的completeBatch方法中看一下异常的处理

```java
if (error == Errors.MESSAGE_TOO_LARGE && batch.recordCount > 1 &&
    (batch.magic() >= RecordBatch.MAGIC_VALUE_V2 || batch.isCompressed())) {
    // 当请求太大的处理
    if (transactionManager != null)
        transactionManager.removeInFlightBatch(batch);
    // 这里会把batch拆分重新放进缓存
    this.accumulator.splitAndReenqueue(batch);
    // 释放当前的batch
    this.accumulator.deallocate(batch);
    this.sensors.recordBatchSplit();
} else if (error != Errors.NONE) {
    // 如果存在异常
    // canRetry判断的是重试次数到没到上限
    if (canRetry(batch, response)) {
        if (transactionManager == null) {
            // 重试的代码
            reenqueueBatch(batch, now);
        } else if (transactionManager.hasProducerIdAndEpoch(batch.producerId(), batch.producerEpoch())) {
            // 如果开启了幂等，就会推送到相同的broker上去
            reenqueueBatch(batch, now);
        } else {
            failBatch(batch, response, new OutOfOrderSequenceException("Attempted to retry sending a " +
                                                                       "batch but the producer id changed from " + batch.producerId() + " to " +
                                                                       transactionManager.producerIdAndEpoch().producerId + " in the mean time. This batch will be dropped."), false);
        }
    } else if (error == Errors.DUPLICATE_SEQUENCE_NUMBER) {
        // 如果是sequence超出了范围，这个时候不增加本地的偏移量和时间戳，直接返回成功
        completeBatch(batch, response);
    } else {
        // 这里设置异常类型
        final RuntimeException exception;
        if (error == Errors.TOPIC_AUTHORIZATION_FAILED)
            exception = new TopicAuthorizationException(batch.topicPartition.topic());
        else if (error == Errors.CLUSTER_AUTHORIZATION_FAILED)
            exception = new ClusterAuthorizationException("The producer is not authorized to do idempotent sends");
        else
            exception = error.exception();
        // 直接失败，源码里还说重试了之后不确定sequence是否还能被接受
        failBatch(batch, response, exception, batch.attempts() < this.retries);
    }
    if (error.exception() instanceof InvalidMetadataException) {
        metadata.requestUpdate();
    }

}
```

重试的方法reenqueueBatch(batch, now)里面只有两行代码，调用缓存重新进入队列，统计重试次数，进入重新进入队列的方法：

```java
public void reenqueue(ProducerBatch batch, long now) {
    // 这里设置了几个数值
    // attempts自增
    // lastAttemptMs设置成now
    // lastAppendTime设置成now
    batch.reenqueued(now);
    Deque<ProducerBatch> deque = getOrCreateDeque(batch.topicPartition);
    synchronized (deque) {
        if (transactionManager != null)
            insertInSequenceOrder(deque, batch);
        else
            // 插入的是队头，这样下次循环的时候就会优先处理需要重试的batch
            deque.addFirst(batch);
    }
}
```

##### 超时检测

在Sender的sendProducerData()中进行batch的超时检测：

```java
// 拿到所有的缓存中的超时batch
List<ProducerBatch> expiredBatches = this.accumulator.expiredBatches(this.requestTimeout, now);
// 遍历释放资源
for (ProducerBatch expiredBatch : expiredBatches) {
    failBatch(expiredBatch, -1, NO_TIMESTAMP, expiredBatch.timeoutException(), false);
    if (transactionManager != null && expiredBatch.inRetry()) {
        transactionManager.markSequenceUnresolved(expiredBatch.topicPartition);
    }
}
```

发送的超时在上面poll之后的一堆处理方法中，有一个handleTimedOutRequests(responses, updatedNow);方法：

```java
private void handleTimedOutRequests(List<ClientResponse> responses, long now) {
    // 拿到所有超时节点
    List<String> nodeIds = this.inFlightRequests.getNodesWithTimedOutRequests(now, this.requestTimeoutMs);
    for (String nodeId : nodeIds) {
        // 关闭连接，然后做一些内存清理
        this.selector.close(nodeId);
        processDisconnection(responses, nodeId, now, ChannelState.LOCAL_CLOSE);
    }

    // 标记一下，需要更新节点信息，因为上面判断超时就是broker可能死了，这里需要更新元数据
    // 否则下次发送消息又会和关闭连接的broker建立连接
    if (!nodeIds.isEmpty())
        metadataUpdater.requestUpdate();
}
```

