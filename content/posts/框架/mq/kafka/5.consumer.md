---
title: 5.consumer
date: 2021-08-06 06:27:35
tags:
  - 大数据
categories: kafka
copyright: true
---

### 参数

1.   heartbeat.interval.ms：心跳的时间间隔。
2.   session.timeout.ms：默认10s，如果broker10s内感知不到consumer的心跳就会认为consumer宕机，进行rebalance。
3.   max.poll.interval.ms：两次pool的间隔超时，比如说虽然你一直在发心跳，但是poll一次消息之后，很长时间都没消费完，那broker就会认为你不靠谱，也会把你踢出去。
4.   fetch.max.bytes：消费消息的最大值，一般可以设置成10M（10485760），要不然来一条大消息就消费不了了。
5.   max.poll.records：每次最多拉多少条数据，默认500，如果消费的吞吐量特别大，这个参数可以调大。
6.   connection.max.idle.ms：这个是说如果socket连接空闲得话会不会回收，可以设置成-1，不要回收。
7.   enable.auto.commit：开启自动提交，开启之后消息消费完会有consumer自己去定时提交offset，这样会出现一个问题，就是每次重启都会重复消费一批数据。
8.   auto.commit.ineterval.ms：自动提交的间隔。
9.   auto.offset.reset：重启后发现offet在broker中找不到，怎么处理，可以设置成earliest，从最早的开始消费。

### 原理

 每个consumer都要有一个组，并且每个分区只能被一个consumer消费，但是一个consumer可以消费多个分区，所以如果只有3个分区，创建10个consumer是没用的。consumer收到消息之后默认定时自动提交offset，就是把offset发送到_consumer_offsets队列。

### coordinator

coordinator是负责consumer的心跳、宕机判断以及rebalance的，当consumer group启动的时候，会对consumer group id的hash取模，然后根据_consumer_offsets的分区数，默认是50进行取余，拿到的分区的leader所在的broker就是这个group的coordinator。

每个consumer都发送JoinGroup请求到Coordinator，然后Coordinator从一个consumer group中选择一个consumer作为leader，把consumer group情况发送给这个leader，接着这个leader会负责制定分区方案，通过SyncGroup发给Coordinator，接着Coordinator就把分区方案下发给各个consumer，他们会从指定的分区的leader broker开始进行socket连接以及消费消息。

rebalance策略：

*   range：按照区间给，比如0-2的分区给第一个consumer，3-5分区给第二个consumer。
*   round-robin：轮询，第一个消费者消费0分区，第二个消费1分区……。
*   sticky：强两个分区方式问题很大，比如第二个consumer死了，可能所有的consumer被新分配的分区和之前的都不一样，为了解决上面的问题sticky把宕机的consumer的分区在均匀的分配给现有的consumer。

### 自定义消费分区

```java
List<PartitionInfo> partitions = consumer.partitionsFor(“order-topic”);
new TopicPartition(partitionInfo.topic(), partitionInfo.partition());
// 指定每个consumer要消费哪些分区，你就不是依靠consumer的自动的分区分配方案来做了
consumer.assign(partitions);
```

