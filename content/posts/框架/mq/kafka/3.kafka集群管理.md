---
title: 3.kafka集群管理
date: 2021-08-06 06:27:35
tags:
  - 大数据
categories: kafka
copyright: true
---

##### 删除topic：

删除topic需要先设置delete.topic.enable为true，执行命令删除：

```shell
# 删除是异步的，可能需要删除很长时间
./kafka-topics.sh --delete --zookeeper cluster01:2181,cluster02:2181,cluster03:2181 --topic test-topic
```

##### topic管理平台：

一般的小公司是不需要这个topic管理的，因为小公司可能就1个人或者几个人来维护kafka，像实时计算团队或者业务团队可能就跟你说一声要使用哪个topic，平时是没人管这个topic的，所以维护的人可以直接在命令行看一看就可以了。

##### 查看消息数量：

查看消息数量需要先查看当前的消息索引，然后在查看其实的消息索引，他俩一减就是消息数量，为什么要减呢，因为kafka的消息不止一只保留的，可能只是最近7天的：

```shell
# 查看每个分区最大的消息位移
./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list cluster01:9092,cluster02:9092,cluster03:9092 --topic test01 --time -1
# 查看每个分区最小的消息位移
./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list cluster01:9092,cluster02:9092,cluster03:9092 --topic test01 --time -2
```

##### 扩容partition

```shell
# 把partition数量调整到10，kafka的分区只能增不能减
./kafka-topics.sh --alter --zookeeper cluster01:2181 --partitions 10 --topic test-topic
```

##### 自研监控平台

其实就是在代码里执行一些命令或者api，或者直接掉kafka的脚本，可以每天凌晨扫描topic的数据量，如果发现topic数据量增长的很快，就可以自动扩容分区。

##### leader分布不均匀怎么办

kafka的配置auto.leader.rebalance.enable，默认是true，就是说他默认每300s会自动重新选举，防止leader分配不均匀到是某些机器负载过高，或者手动执行命令，让他现在就重新选举：

```shell
./kafka-preferred-replica-election.sh
```

##### 增加副本数

首先要把增加的信息写到一个文件里，格式是json，类似下面这样：

```json
{“version”:1,”partitions”:[{“topic”:”test01”,”partition”:0,”replicas”:[0,1,2]},{“topic”:”test01”,”partition”:1,”replicas”:[0,1,2]},{“topic”:”test01”,”partition”:2,”replicas”:[0,1,2]}]}
```

比如这个文件叫increase-replication-factor.json，然后执行命令：

```shell
./kafka-reassign-partitions.sh --zookeeper cluster01:2181 --reassignment-json-file increase-replication-factor.json --execute

# 查看迁移进度
./kafka-reassign-partitions.sh --zookeeper cluster01:2181 --reassignment-json-file increase-replication-factor.json --verify
```

##### JMX指标

官网上有几百个JMX指标，启动的时候指定了JMXPort就可以通过JMX查看kafka状态，比如每隔5s监控过去15分钟的消息接收速率：

```shell
./kafka-run-class.sh kafka.tools.JmxTool --object-name kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec --jmx-url service:jmx:rmi:///jndi/rmi://:9997/jmxrmi --date-format “YYYY-MM-dd HH:mm:ss” --attributes FifteenMinuteRate --reporting-interval 5000
```

如果想指定topic可以加个topic参数：

```shell
kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=test
```

通过工具的话会很方便，比如kafka-manager（现在不维护了）或者kafka-eagle（中国人写的）等等，使用开源的监控可能会出现满足不了我们的需求，很正常，如果发现开源的监控满足不了我们可以自研，或者二次开发，自研也是基于这些命令实现，其实监控只要就是监控磁盘资源的使用量，每台机器的吞吐量（每秒的读写消息、字节的数据），jvm状态等等。

##### broker扩容

新加broker机器就会自动注册在zk上，然后controller就会感知到，主要是新增机器后怎么保证数据的负载均衡，一般检测到数据负载不均衡可以让他自动的对分区和副本重新分配一下机器：

比如把那些topic需要重新分配写到一个文件里：

```shell
vi topics-to-move.json

# 把你所有的topic都写在这里
{“topics”: [{“topic”: “test01”}, {“topic”: “test02”}], “version”: 1}
```

执行下面的命令生成分配方案

```shell
# 把所有的partition均匀的分散在各个5、6的机器上
# 此时会生成一个迁移方案，可以保存到一个文件里去：expand-cluster-reassignment.json
./kafka-reassgin-partitions.sh --zookeeper hadoop03:2181,hadoop04:2181,hadoop05:2181 --topics-to-move-json-file topics-to-move.json --broker-list "5,6" --generate
```

重新分配：

```shell
./kafka-reassign-partitions.sh --zookeeper hadoop01:2181,hadoop02:2181,hadoop03:2181 --reassignment-json-file expand-cluster-reassignment.json --execute

./kafka-reassign-partitions.sh --zookeeper hadoop01:2181,hadoop02:2181,hadoop03:2181 --reassignment-json-file expand-cluster-reassignment.json --verify
```

这种数据迁移操作一定要在晚上低峰的时候来做，因为他会在机器之间迁移数据，非常的占用带宽资源，如果不指定--broker-list，会把分区分配到所有的机器上，一般都是这种局部的重新分配多。

##### 版本升级

1.   在所有的broker的server.properties中填写当前的版本号，比如：

     ```shell
     inter.broker.protocol.version=0.10.0
     log.message.format.version=0.10.0
     ```

2.   在每台机器上都用新版本（比如0.10.2.0）的kafka代码替换老版本的kafka代码，然后依次重启每台机器上的broker

3.   更新上述两个版本号为0.10.2

4.   再次在各个机器上重启broker即可

这个过程中可能会导致消息的重复消费，因为可能某个消息没法成功的提交offset消费记录到broker，所以会导致broke给消费者重复消费某个消息

##### 要不要做认证授权和数据加密

一般都是2B或者对数据要求很高的公司在用，kafka是支持的，一般不用配置。

