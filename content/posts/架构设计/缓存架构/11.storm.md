### 集群架构

![](https://tva1.sinaimg.cn/large/008i3skNly1grgjczpgipj30u018gha8.jpg)

### 并行度和流分组

task就是并行度，当excutor中只有一个task的时候，excutor也可以被说为并行度；

每个task执行的都是spout或者bolt的代码副本，当task执行完spout或者bold的代码的代码后如何向下游的bolt传递数据就叫流分组：

* Shuffle Grouping：随机发射，负载均衡；
* Fields Grouping：每条数据都存储到tuple中，根据tuple的某一个，或者某些个字段进行分组，值相同的会被分到下游bolt的固定task中；
* All Grouping：有点像MQ的广播模式，下游bold的每个tak都会接到数据；
* Global Grouping：根据taskId选择分给那个task；
* None Grouping：和Shuffle Grouping一样；
* Direct Grouping：自己指定发给那个task；
* Local or Shuffle Grouping：只会对同一个进程（excutor）中的下游bolt的task发送数据，并且使用Shuffle Grouping；

### wordcount

大数据的入门不是写hello word，是单词计数，写一个spout随机发送一个句子，然后创建两个bolt，一个拆分句子，一个统计单词数。使用的是storm1.1.1

```java
public class WordCountTopology {

	/**
	 * spout
	 * 生产或者获取数据
	 */
	public static class RandomSentenceSpout extends BaseRichSpout {

		private static final long serialVersionUID = 1938838116523430511L;

		private SpoutOutputCollector spoutOutputCollector;

		private Random random;

		/**
		 * 对spout初始化
		 * 比如说创建线程池或者数据库连接池或者http客户端
		 * 被woork下的某个excutor下的某个task运行
		 * @param map
		 * @param topologyContext
		 * @param collector
		 */
		@Override
		public void open(Map map, TopologyContext topologyContext, SpoutOutputCollector collector) {
			/**
			 * open初始化的时候会传进来一个SpoutOutputCollector，他是用来向下游传递数据的
			 */
			this.spoutOutputCollector = collector;
			// 构造一个随机数生产对象
			this.random = new Random();
		}

		/**
		 * work下的excutor下的task会无限调用nextTuple方法
		 */
		@Override
		public void nextTuple() {
			Utils.sleep(100);
			// 定义一些句子
			String[] sentences = new String[]{"the cow jumped over the moon", "an apple a day keeps the doctor away", "four score and seven years ago", "snow white and the seven dwarfs", "i am at two with natrue"};
			String sentence = sentences[random.nextInt(sentences.length)];
			System.out.println("发射数据" + sentence);
			// new Values就是构建tuple，一个tuple里面是一条数据，多个tuple组成stream
			spoutOutputCollector.emit(new Values(sentence));
		}

		/**
		 * 定义发射出去的每个tuple的每个字段是什么
		 * @param outputFieldsDeclarer
		 */
		@Override
		public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer) {
			outputFieldsDeclarer.declare(new Fields("sentence"));
		}
	}

	/**
	 * bolt
	 * 处理数据
	 * 被woork下的某个excutor下的某个task运行
	 *
	 * 将收到的句子分割然后发射出去
	 */
	public static class SplitSentence extends BaseRichBolt {
		private static final long serialVersionUID = -7296430331665354940L;

		// 发射数据
		private OutputCollector outputCollector;

		/**
		 * Bolt初始化方法
		 * @param stormConf
		 * @param context
		 * @param collector
		 */
		@Override
		public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) {
			this.outputCollector = collector;
		}

		/**
		 * 每次收到数据后都会交给execute方法执行
		 * @param input
		 */
		@Override
		public void execute(Tuple input) {
			String sentence = input.getStringByField("sentence");
			String[] words = sentence.split(" ");
			for(String word : words){
				outputCollector.emit(new Values(word));
			}
		}

		/**
		 * 定义发射出去的tuple的字段名
		 * @param declarer
		 */
		@Override
		public void declareOutputFields(OutputFieldsDeclarer declarer) {
			declarer.declare(new Fields("word"));
		}
	}

	/**
	 * 第二个bolt
	 * 收到单词，放到map中，value是单词出现的次数
	 */
	public static class WordCount extends BaseRichBolt {

		private static final long serialVersionUID = 3392070844258731973L;

		private OutputCollector outputCollector;
		Map<String, Long> counts = new HashMap<>();

		@Override
		public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) {
			this.outputCollector = collector;
		}

		@Override
		public void execute(Tuple input) {
			String word = input.getStringByField("word");
			Long count = counts.get(word);
			if(count == null){
				count = 0L;
			}
			count++;
			counts.put(word, count);
			System.out.println("单词:" + word + "出现的次数:" + count);
			outputCollector.emit(new Values(word, count));
		}

		@Override
		public void declareOutputFields(OutputFieldsDeclarer declarer) {
			declarer.declare(new Fields("word", "count"));
		}
	}

	public static void main(String[] args) {
		// 将spout和bolt组合成一个拓扑
		TopologyBuilder topologyBuilder = new TopologyBuilder();
		// 设置spout
		topologyBuilder.setSpout("randomSentence", // 名字
				new RandomSentenceSpout(),
				2 // 设置excutor数量
		);
		// 设置第一个bolt
		topologyBuilder.setBolt("splitSentence",
				new SplitSentence(),
				5 // 设置excutor数量
		).setNumTasks(10).shuffleGrouping("randomSentence"); // 设置task数量
		// 设置第二个bolt
		// 相同的单词从splitSentence发射出来后一定会进入到下游的同一个task中
		topologyBuilder.setBolt("wordCount", new WordCount(), 10)
				.setNumTasks(20).fieldsGrouping("splitSentence", new Fields("word"));

		Config config = new Config();
		// 如果args有值说明是在命令行执行，提交到strom集群上去
		if(args != null && args.length > 0){
			// 指定几个wordker执行
			config.setNumWorkers(3);
			try {
				StormSubmitter.submitTopology(args[0], config, topologyBuilder.createTopology());
			} catch (AlreadyAliveException e) {
				e.printStackTrace();
			} catch (InvalidTopologyException e) {
				e.printStackTrace();
			} catch (AuthorizationException e) {
				e.printStackTrace();
			}
		}else{
			config.setMaxTaskParallelism(5);
			LocalCluster cluster = new LocalCluster();
			cluster.submitTopology("wordCountTopology", config, topologyBuilder.createTopology());
			Utils.sleep(50000);
			cluster.shutdown();
		}
	}
}
```

### 集群部署

需要先安装java和python，之后下载storm压缩包传到虚拟机03上然后解压重命名为storm；然后配置环境变量：

```shell
vi /etc/profile

# 添加
export STORM_HOME=/usr/local/storm
# path添加
$STORM_HOME/bin

# 保存之后刷新一下
source /etc/profile
```

修改storm/conf下的storm.yaml：

```shell
storm.zookeeper.servers:
    - "192.168.0.3"
    - "192.168.0.5"    
    - "192.168.0.6"
nimbus.seeds: ["192.168.0.3"]
storm.local.dir: "/var/storm"
# 指定每个机器可以启动多少个worker，一个端口号代表一个worker
supervisor.slots.ports:
    - 6700
    - 6701
    - 6702
    - 6703
```

创建目录：**mkdir /var/storm**。

在虚拟机02、01上也安一个storm；

启动：

```shell
# 虚拟机01上启动nimbus
storm nimbus >/dev/null 2>&1 &
# 三台机器都启动supervisor
storm supervisor >/dev/null 2>&1 &
# 虚拟机03上启动ui
storm ui >/dev/null 2>&1 &
# 两台supervisor机器上启动logviewer
storm logviewer >/dev/null 2>&1 &
```

然后在浏览器访问ui界面： http://192.168.0.6:8080/ 

### 运行拓扑

将上面的代码打包传到nimbus虚拟机上，然后执行：

```shell
storm jar storm-helloword-0.0.1-SNAPSHOT.jar com.xiaohong.eshop.storm.WordCountTopology wordCountTopology
```

关闭运行的拓扑：storm kill [topology-name]