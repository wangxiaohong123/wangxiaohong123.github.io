### zookeeper安装

现在eshoop-cache01上安装，将zk压缩包传到/usr/local/下，解压并重命名为zk：

```shell
tar -zxvf zookeeper-3.4.5.tar.gz

mv zookeeper-3.4.5 zk
```

配置环境变量：

```shell
vi /etc/profile
```

path中添加zk的文件位置：

```shell
export ZOOKEEPER_HOME=/usr/local/zk
export PATH=$ZOOKEEPER_HOME/bin
```

保存之后刷新配置文件：

```shell
source /etc/profile
```

进入zk/conf/目录下复制zoo_sample.cfg并修改复制出来的文件：

```shell
cp zoo_sample.cfg zoo.cfg
vi zoo.cfg
```

修改data地址，添加集群信息：

```shell
# 修改
dataDir=/usr/local/zk/data
# 新增
server.0=eshoop-cache01:2888:3888	
server.1=eshoop-cache02:2888:3888
server.2=eshoop-cache03:2888:3888
```

在zk下新建data目录和myid文件，写个0退出：

```shell
cd /usr/local/zk
mkdir data
vi myid

i -->0 -->esc -->:wq -->回车
```

然后远程拷贝配置文件和zk到cache02和cache03上：

```shell
scp /etc/profile root@eshoop-cache02:/etc
scp /etc/profile root@eshoop-cache03:/etc
scp -r zk root@eshoop-cache02:/usr/local/
scp -r zk root@eshoop-cache03:/usr/local/
```

在cache02和03上分别刷新profile和修改data下的myid文件的值为1和2。启动zk:

```shell
zkServer.sh start

# 查看zk状态
zkServer.sh status
```

### kafka

#### scala

kafka使用scala语言写的，所以需要先安装scala，将scala解压并重命名，然后配置环境变量：

```shell
ar -zxvf scala-2.11.4.tgz
mv scala-2.11.4 scala
# 配置环境变量
vi /etc/profile

export SCALA_HOME=/usr/local/scala
export PATH=$SCALA_HOME/bin
# 保存退出并刷新
source /etc/profile
# 查看scala是否配置成功
scala -version

scp /etc/profile root@eshoop-cache02:/etc
scp /etc/profile root@eshoop-cache03:/etc
scp -r scala root@eshoop-cache02:/usr/local/
scp -r scala root@eshoop-cache03:/usr/local/
# profile文件语法错误会导致命令不好使，执行这个然后打开profile检查语法
export PATH=/sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin
```

#### kafka

解压kafka然后重命名：

```shell
tar -zxvf kafka_2.9.2-0.8.1.tgz
mv kafka_2.9.2-0.8.1 kafka
```

修改配置文件：

```shell
vi /usr/local/kafka/config/server.properties
```

修改zk地址：

```shell
# 三台kafka的broker集群id，唯一，分别设置成0、1、2
broker.id=0
# 设置成本机的ip
advertised.host.name=192.168.0.3
zookeeper.connect=192.168.0.3:2181,192.168.0.5:2181,192.168.0.6:2181
```

将slf4j-nop-1.7.6.jar复制到kafka的libs目录下面，然后修改kafka-run-class.sh防止kafka报错：Unrecognized VM option 'UseCompressedOops'：

```shell
vi /usr/local/kafka/bin/kafka-run-class.sh
# 找到UseCompressedOops将对应配置删除
if [ -z "$KAFKA_JVM_PERFORMANCE_OPTS" ]; then
  KAFKA_JVM_PERFORMANCE_OPTS="-server  -XX:+UseCompressedOops -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled -XX:+CMSScavengeBeforeRemark -XX:+DisableExplicitGC -Djava.awt.headless=true"
fi
```

使用scp把kafka拷贝到另外两台机器并修改broker.id：

```shell
scp -r kafka root@eshoop-cache02:/usr/local/
scp -r kafka root@eshoop-cache03:/usr/local/
```

进入kafka目录下启动kafka：

```shell
nohup bin/kafka-server-start.sh config/server.properties &
```

使用jps查看是否启动成功。

```shell
# 创建名为test的topic
bin/kafka-topics.sh --zookeeper 192.168.0.3:2181,192.168.0.5:2181,192.168.0.6:2181 --topic test --replication-factor 1 --partitions 1 --create
# 启动testtopic的producer控制台
bin/kafka-console-producer.sh --broker-list 192.168.0.3:9092,192.168.0.5:9092,192.168.0.6:9092 --topic test
# 启动testtopic的consumer控制台
bin/kafka-console-consumer.sh --zookeeper 192.168.0.3:2181,192.168.0.5:2181,192.168.0.6:2181 --topic test --from-beginning
```

