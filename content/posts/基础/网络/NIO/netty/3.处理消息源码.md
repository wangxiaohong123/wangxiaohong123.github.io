---
title: 3.netty-处理消息源码
tags:
  - 网络
categories: netty
copyright: true
---

已经知道了NioEventLoop继承SingleThreadEventLoop，而SingleThreadEventLoop是实现了EventLoop的。

SingleThreadEventLoop其实就是一个线程池，只不过它里面只有1个线程，在SingleThreadEventExecutor中自己定义了一个run()方法，在LocalServerChannel的doRegister方法被调用时，需要时会调用SingleThreadEventExecutor的addShutdownHook()方法，这个方法里调用了自己的execute()方法，在execute方法中调用了run()方法。

在run()方法中是一个死循环，不断地执行`processSelectedKeys();`方法：

```java
private void processSelectedKeys() {
    if (selectedKeys != null) {
        processSelectedKeysOptimized();
    } else {
        // 拿到selectedKeys
        processSelectedKeysPlain(selector.selectedKeys());
    }
}
```

拿到selectedKeys之后就是要循环了，把SelectionKey交给processSelectedKey()方法处理：

```java
private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) {
    final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe();
    if (!k.isValid()) {
        final EventLoop eventLoop;
        try {
            eventLoop = ch.eventLoop();
        } catch (Throwable ignored) {
            return;
        }
        if (eventLoop == this) {
            // close the channel if the key is not valid anymore
            unsafe.close(unsafe.voidPromise());
        }
        return;
    }

    try {
        int readyOps = k.readyOps();
        // 处理OP_CONNECT事件
        if ((readyOps & SelectionKey.OP_CONNECT) != 0) {
            // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking
            // See https://github.com/netty/netty/issues/924
            int ops = k.interestOps();
            // 这部设置完了，原来关注什么事件，结果不变
            // 除非原来就关注OP_CONNECT事件，经过下面的运算会变成关注OP_ACCEPT事件
            ops &= ~SelectionKey.OP_CONNECT;
            k.interestOps(ops);

            unsafe.finishConnect();
        }

        // 处理OP_WRITE事件
        if ((readyOps & SelectionKey.OP_WRITE) != 0) {
            ch.unsafe().forceFlush();
        }

        // 处理读和建立连接事件
        // 这里通过检查readyOps == 0解决jdk自旋错误
        if ((readyOps & (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) {
            unsafe.read();
        }
    } catch (CancelledKeyException ignored) {
        unsafe.close(unsafe.voidPromise());
    }
}
```

### 收消息源码

上面的unsafe.read();会经过NioMessageUnsafe的read()方法->DefaultChannelPipeline的fireChannelRead()方法->AbstractChannelHandlerContext的invokeChannelRead()方法，最后到AbstractChannelHandlerContext的invokeChannelRead()方法：

```java
private void invokeChannelRead(Object msg) {
    if (invokeHandler()) {
        try {
            // 猜测这个就是获取处理链条
            // 之前在创建NioServerSocketChannel的时候在pipeline中添加了一个ServerBootstrapAcceptor
            // 所以下面的channelRead()方法会进到ServerBootstrapAcceptor类中
            ((ChannelInboundHandler) handler()).channelRead(this, msg);
        } catch (Throwable t) {
            invokeExceptionCaught(t);
        }
    } else {
        fireChannelRead(msg);
    }
}
```

ServerBootstrapAcceptor的channelRead()：

```java
public void channelRead(ChannelHandlerContext ctx, Object msg) {
    final Channel child = (Channel) msg;

    child.pipeline().addLast(childHandler);

    setChannelOptions(child, childOptions, logger);
    setAttributes(child, childAttrs);

    try {
        // ServerBootstrapAcceptor是ServerBootstrap的内部类
        // 这个childGroup也是ServerBootstrap的childGroup
        // 这个register还是会继续走MultithreadEventLoopGroup的register()
        // 剩下的步骤就和ServerSocketChannel注册是一样的了
        childGroup.register(child).addListener(new ChannelFutrueListener() {
            @Override
            public void operationComplete(ChannelFutrue futrue) throws Exception {
                if (!futrue.isSuccess()) {
                    forceClose(child, futrue.cause());
                }
            }
        });
    } catch (Throwable t) {
        forceClose(child, t);
    }
}
```

**TODO：没有找到设置关注事件的代码，一直设置的都是0**

如果是OP_READ事件，会通过AbstractNioByteChannel把数据读取到ByteBuf里然后交给我们自己实现的ChannelInboundHandlerAdapter的子类处理。

AbstractNioByteChannel的read()的核心代码：

```java
public final void read() {
	……
    ByteBuf byteBuf = null;
    boolean close = false;
    try {
        do {
            // 把数据读取到ByteBuf中
            byteBuf = allocHandle.allocate(allocator);
            if (allocHandle.lastBytesRead() <= 0) {
                byteBuf.release();
                byteBuf = null;
                close = allocHandle.lastBytesRead() < 0;
                if (close) {
                    readPending = false;
                }
                break;
            }

            allocHandle.incMessagesRead(1);
            readPending = false;
            // 这个还是之前DefaultChannelPipeline的fireChannelRead()方法->AbstractChannelHandlerContext的invokeChannelRead()方法这一套
            // 只不过最后的handler是我们自己创建的ChannelInboundHandlerAdapter的子类
            pipeline.fireChannelRead(byteBuf);
            byteBuf = null;
        } while (allocHandle.continueReading());
}
```

### 发消息源码

发消息分为两种，write和writeAndFlush，不管是那种都会走到AbstractChannelHandlerContext的write方法中：

```java
private void write(Object msg, boolean flush, ChannelPromise promise) {
	……
    final AbstractChannelHandlerContext next = findContextOutbound(flush ?
                                                                   (MASK_WRITE | MASK_FLUSH) : MASK_WRITE);
    final Object m = pipeline.touch(msg, next);
    EventExecutor executor = next.executor();
    if (executor.inEventLoop()) {
        // 如果是writeAndFlush，这个flush会传true
        if (flush) {
            next.invokeWriteAndFlush(m, promise);
        } else {
            next.invokeWrite(m, promise);
        }
    }
    ……
}
```

##### 1.invokeWrite0()

```java
/**
 * AbstractChannelHandlerContext的invokeWriteAndFlush()
 */
void invokeWriteAndFlush(Object msg, ChannelPromise promise) {
    if (invokeHandler()) {
        // 发消息的入口
        invokeWrite0(msg, promise);
        invokeFlush0();
    } else {
        writeAndFlush(msg, promise);
    }
}
```

invokeWrite0()会调用HeadContext(DefaultChannelPipeline的内部类)的write()方法，然后调用到AbstractUnsafe(AbstractChannel的内部类)的write()方法：

```java
/**
 * AbstractUnsafe的write的核心代码
 */
public final void write(Object msg, ChannelPromise promise) {
    ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;

    int size;
    try {
        msg = filterOutboundMessage(msg);
        size = pipeline.estimatorHandle().size(msg);
        if (size < 0) {
            size = 0;
        }
    }
	// 其实就是往outboundBuffer队列中添加消息
    // 这个是netty自己写的数据结构
    outboundBuffer.addMessage(msg, size, promise);
}
```

##### 2.invokeFlush0

不管是invokeWriteAndFlush合适invokeWrite都会执行invokeWrite0，只不过invokeWriteAndFlush多了一步执行invokeFlush0()方法，然后调用HeadContext(DefaultChannelPipeline的内部类)的flush()：

```java
public final void flush() {
    ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;
	// 添加flush
    outboundBuffer.addFlush();
    flush0();
}
```

通过flush0()最后会走到NioSocketChannel的doWrite方法中，在这个方法里执行发送的逻辑：

```java
protected void doWrite(ChannelOutboundBuffer in) throws Exception {
    SocketChannel ch = javaChannel();
    int writeSpinCount = config().getWriteSpinCount();
    do {
        if (in.isEmpty()) {
            // All written so clear OP_WRITE
            clearOpWrite();
            // Directly return here so incompleteWrite(...) is not called.
            return;
        }

        // Ensure the pending writes are made of ByteBufs only.
        int maxBytesPerGatheringWrite = ((NioSocketChannelConfig) config).getMaxBytesPerGatheringWrite();
        ByteBuffer[] nioBuffers = in.nioBuffers(1024, maxBytesPerGatheringWrite);
        int nioBufferCnt = in.nioBufferCount();

        // Always use nioBuffers() to workaround data-corruption.
        // See https://github.com/netty/netty/issues/2761
        switch (nioBufferCnt) {
            case 0:
                // We have something else beside ByteBuffers to write so fallback to normal writes.
                writeSpinCount -= doWrite0(in);
                break;
            case 1: {
                // Only one ByteBuf so use non-gathering write
                // Zero length buffers are not added to nioBuffers by ChannelOutboundBuffer, so there is no need
                // to check if the total size of all the buffers is non-zero.
                ByteBuffer buffer = nioBuffers[0];
                int attemptedBytes = buffer.remaining();
                // nio的写数据逻辑
                final int localWrittenBytes = ch.write(buffer);
                if (localWrittenBytes <= 0) {
                    incompleteWrite(true);
                    return;
                }
                adjustMaxBytesPerGatheringWrite(attemptedBytes, localWrittenBytes, maxBytesPerGatheringWrite);
                in.removeBytes(localWrittenBytes);
                --writeSpinCount;
                break;
            }
            default: {
                // Zero length buffers are not added to nioBuffers by ChannelOutboundBuffer, so there is no need
                // to check if the total size of all the buffers is non-zero.
                // We limit the max amount to int above so cast is safe
                long attemptedBytes = in.nioBufferSize();
                final long localWrittenBytes = ch.write(nioBuffers, 0, nioBufferCnt);
                if (localWrittenBytes <= 0) {
                    incompleteWrite(true);
                    return;
                }
                // Casting to int is safe because we limit the total amount of data in the nioBuffers to int above.
                adjustMaxBytesPerGatheringWrite((int) attemptedBytes, (int) localWrittenBytes,
                                                maxBytesPerGatheringWrite);
                in.removeBytes(localWrittenBytes);
                --writeSpinCount;
                break;
            }
        }
    } while (writeSpinCount > 0);

    incompleteWrite(writeSpinCount < 0);
}
```

**TODO：如果不是writeAndFlush什么时候触发flush操作**

![](https://tva1.sinaimg.cn/large/008vxvgGly1h776f54jgij32540u0q74.jpg)

**TODO：动态缓冲源码**
