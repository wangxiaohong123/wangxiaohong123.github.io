<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>大模型应用开发 on 王小红的笔记</title><link>https://wangxiaohong123.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/</link><description>Recent content in 大模型应用开发 on 王小红的笔记</description><generator>Hugo -- 0.150.0</generator><language>zh-CN</language><atom:link href="https://wangxiaohong123.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/index.xml" rel="self" type="application/rss+xml"/><item><title>10.RAG</title><link>https://wangxiaohong123.github.io/posts/ai/10.rag/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangxiaohong123.github.io/posts/ai/10.rag/</guid><description>&lt;h4 id="langchain"&gt;LangChain&lt;/h4&gt;
&lt;p&gt;LangChain是用来构建大模型应用的框架，相当于python的django、java的Spring。尤其是在RAG领域作用非常大。&lt;/p&gt;
&lt;h5 id="rlhf基于人类反馈的强化学习"&gt;RLHF（基于人类反馈的强化学习）&lt;/h5&gt;</description></item><item><title>9.大模型微调</title><link>https://wangxiaohong123.github.io/posts/ai/9.%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangxiaohong123.github.io/posts/ai/9.%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/</guid><description>&lt;p&gt;大语言中的大型主要体现在参数规模和训练数据量，一般参数规模达到1B(10亿)量级才叫大模型，只有达到这个量级才会有机遇Scaling law的涌现现象，涌现现象是大模型的魅力，有点像初中物理学的液态变固态。&lt;/p&gt;
&lt;p&gt;模型的参数数量跟显存占比的计算，以OPT-6.7B举例：OPT-6.7B就是6.7Billion个参数，假设参数的类型是Float16，即每个参数占用16位（2字节）的显存。总显存占用=参数总量×每个参数的显存占用。总内存 = 67亿 * 2 = 134亿字节。转换成GB就是134亿 / 1024 / 1024 / 1024 = 12.5GB的显存。&lt;/p&gt;
&lt;p&gt;使用大显存的GPU加载整个模型可以加快训练速度，部署时也可以提高响应速度，但是可以只使用CPU+内存的方式训练或者部署，只不过这种方式的训练很慢，因为训练时需要大量的矩阵相乘操作。但是使用部署后的模型只是一个前向传播操作，CPU+内存的方式不会比GPU慢很多，除非是有并发量的批量推理，GPU的优势会很明显。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;现在是一个信息过载的时代，搜什么都会出现一堆，大模型工具的使用可以帮助我们筛选出有用的信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;模型分类：自回归(&lt;code&gt;CAUSAL_LM&lt;/code&gt;，文本生成任务，比如GPT)、序列分类(&lt;code&gt;SEQ_CLS&lt;/code&gt;，情感分析、文本分类)、token级分类(&lt;code&gt;TOKEN_CLS&lt;/code&gt;，命名实体识别NER)、问答任务(&lt;code&gt;QUESTION_ANS&lt;/code&gt;)&lt;/p&gt;
&lt;h4 id="大模型应用4个阶段"&gt;大模型应用4个阶段&lt;/h4&gt;
&lt;h5 id="1提示词工程"&gt;1提示词工程&lt;/h5&gt;
&lt;p&gt;面向的是终端用户，大模型时代的沟通手段，通过提示词从大模型挖掘知识。就是如何通过对话框跟大模型更好交流。大模型都是概率模型，很多能力他都没有，比如数学运算，但是我们可做到通过描述让他理解。这也是为什么基于注意力机制的模型很容易回答错误一个描述很复杂的小学数学应用题。&lt;/p&gt;
&lt;h5 id="2ai智能体ai-agent"&gt;2AI智能体（AI Agent）&lt;/h5&gt;
&lt;p&gt;基于ReAct范式，就是大模型自主判断应该使用哪些工具，比如chatGPT+联网搜索。分为3类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;行动代理（Action agents）：自主决定使用工具，比如OpenAI的Function Call；&lt;/li&gt;
&lt;li&gt;模拟代理（Simulation agents）：通常设计用于模拟角色扮演，在模拟的环境中运行，比如生成式智能体，CAMEL。以后可能会应用在游戏领域，类似于美剧西部世界；&lt;/li&gt;
&lt;li&gt;自主智能体（Autonomous agents）：独立执行实现长期目标，比如Auto-GPT，manus（国产的，好像是Claude套壳）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;基于大模型开发应用的开发人员，比如自动客服，虚拟助手。&lt;/p&gt;
&lt;h5 id="3大模型微调fine-tuning"&gt;3大模型微调（Fine-tuning）&lt;/h5&gt;
&lt;p&gt;在预训练模型的基础上，使用较小的数据集进一步训练来调整模型参数。当有和目标相关的较小的数据集，并且希望模型在这个任务上表现更好的时候使用。&lt;/p&gt;
&lt;p&gt;未来是面向基础模型编程。&lt;/p&gt;
&lt;h5 id="4预训练技术pre-training"&gt;4预训练技术（Pre-training）&lt;/h5&gt;
&lt;p&gt;使用大量的未标记数据（比如维基百科内容）来训练一个初步的模型，为后续的微调提供基础模型。适合有资源的大厂，有大量的数据集，数据清洗做的好，然后大力出奇迹。&lt;/p&gt;
&lt;p&gt;能自己预训练模型的都是顶级大厂，因为需要的资源实在是太大了，比如LLaMA-65B就需要780G显存。&lt;/p&gt;
&lt;h4 id="rag"&gt;RAG&lt;/h4&gt;
&lt;p&gt;把我们从外部拿到的数据通过处理之后变成向量数据库中的知识。&lt;/p&gt;
&lt;h3 id="微调技术路线"&gt;微调技术路线&lt;/h3&gt;
&lt;p&gt;20年之前大家都不知道怎么去做微调，OpenAI发表了一篇论文提出调整prompt，让模型能更好的理解输入也能有很好的效果，再加上几年之后的文生图让prompt被大家熟知。&lt;/p&gt;
&lt;p&gt;但是prompt有个缺点就是相同的prompt换一个模型或者换一个语言描述效果就会差很多，不管是在LangChain里或者在应用的对话框中都有这个问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;全量微调（FFT）：所有系数都进行调整，原来的VC相关的模型用的多一点，训练成本高，容易造成灾难性遗忘。&lt;/li&gt;
&lt;li&gt;高效微调（PEFT）：分为有监督微调（SFT）、基于人类反馈的强化学习（RLHF）、基于AI反馈的强化学习（RLAIF）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id="peft"&gt;PEFT&lt;/h4&gt;
&lt;p&gt;高效微调技术：Adapter Tuning(2019 Google) -&amp;gt; Prefix Tuning(2021 Stanford) -&amp;gt; Prompt Tuning(2021 Google) -&amp;gt; P-Tuning V1(2021 TsingHua, MIT) -&amp;gt; P-Tuning V2(2022 TsingHua, BAAI )&lt;/p&gt;
&lt;p&gt;传统的模型微调是很容易的，比如分类的卷积网络中可以直接选择冻结卷积层，训练softmax层直接增加类别，2018年google的bert出来之后模型就已经不是CNN那种神经网络了，都是在叠加transformer的层数，整个模型看起来又宽又高，包括到今天的大语言模型中，哪部分参数干了哪些事也是未知的。&lt;/p&gt;</description></item></channel></rss>