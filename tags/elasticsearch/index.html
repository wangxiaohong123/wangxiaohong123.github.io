<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Elasticsearch | 王小红的笔记</title><meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/tags/elasticsearch/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangxiaohong123.github.io/tags/elasticsearch/index.xml><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/tags/elasticsearch/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://wangxiaohong123.github.io/tags/elasticsearch/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="Elasticsearch"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Elasticsearch"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Elasticsearch</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>1.概念</h2></header><div class=entry-content><p>什么是搜索 当我们在百度里搜索关键词的时候就是一个搜索的过程，但是搜索不光是百度，还有一些垂直搜索（站内搜索）比如淘宝里搜一下商品关键字，比如OA系统搜个打卡统计之类的。简单来说就是在任何场景下输入关键字会返回一些想要的信息。
倒排索引 就是把数据拆成词，每个词对应着一条数据的id之类的东西。 比如有3条数据：1 生化危机电影，2 生化危机海报， 3 生化危机新闻，这3条数据生成的倒排索引就类似下面这样：
关键词 ids 生化 1,2,3 危机 1,2,3 生化危机 1,2,3 海报 2 新闻 3 电影 1 如果不考虑搜索优化，假设我们使用es或者lucene进行所有的时候，倒排索引的结构也要比MySQL全表扫描的模糊查询要快很多，因为这里相当于对关键词进行equals比较，而模糊搜索要检查是否包含。
全文检索 全文检索包括把数据插入倒排索引，然后把搜索条件拆词，每个词都去倒排索引中查找数据。
Lucene 就是一个jar包，里面封装好了很多建立倒排索引和全文检索的算法。用lucene可以把现有的数据在磁盘上建立索引，并且Lucene会帮我们组织索引的数据结构，还可用Lucene提供的api对磁盘上的索引数据进行搜索。
elasticsearch Lucene可以实现全文检索功能，但是他有很大的弊端：比如它不支持分布式，api有点复杂。 当我们的数据量在一台机器上放不下的时候，每次查询需要我们自己去各个Lucene机器上搜索，插入数据时也要自己维护索引所在机器，当某一台机器宕机，那这台机器上的数据就全搜不出来了。
所以分布式的搜索引擎elasticsearch就诞生了，对比Lucene而言，他自动冗余数据备份，更高可用，分布式存储更多的数据，自动维护数据到多个节点的索引，还封装了更多高级的功能。
ES功能 数据分析：比如查看最近七天的牙膏的销量前十的商家，每个商品分类下有多少商品。 数据搜索：全文检索和结构化检索，结构化检索就是根据类型，比如搜索日用品类型的商品。 搜索推荐、自动补全这些。 他是一个分布式的海量数据的近实时搜索引擎。
核心概念 Near Realtime（NRT），近实时，有两个意思，第1个是从写入到可查询到是秒级的延迟，第2个是搜索和分析也是秒级的延迟。 Cluster和Node，集群和节点，集群和节点都可以设置名字的，集群的默认名字是elasticsearch，节点的默认名字随机分配，如果节点没有配置集群的名字就会默认加入到elasticsearch集群中。 Document：es里的最小数据单元，就是一条数据。 field：document中的数据字段。 Index：索引，一个index包含很多document，index中是所有类似或者相同的document。 type：index中的document的逻辑分类，比如说index中有10000个document，1到3000个document的field一样，3001到6000的filed一样，6001到10000的id一样，那么就可以定义index中有三个type，type更像是MySQL中的一样表，而index像是一类数据库，新版本中废弃了，因为在es中存储是不区分type的。 shard：一个index可以包含多个shard，这些shared会散落在多台服务器上，这样搜索可以在多个服务器上并行执行，提升吞吐量。扩容时新创建一个更多的shard的index，把数据重新导入进去就可以了，他也叫primary shard，可以接受读写请求。 replica：就是shard的副本，也叫replica shard，每个shard可以有多个replica。replica也可以提供读的请求。 默认情况下每个index有5个shard，每个shard有一个replic，es规定了shard和replica不能在同一节点上，也就是说要部署在两台机器上。使用replica的第一个好处就是分摊查询的压力，提高吞吐，第2个好处就是保证高可用，shard宕机时进行切换。
es是面向文档的数据格式。
锁 es有三个粒度的锁，全局锁（加在索引上）；document锁；读写锁（共享锁和排它锁）；</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 1.概念" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/1.%E6%A6%82%E5%BF%B5/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>10.es-数据导入</h2></header><div class=entry-content><p>新建索引：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 PUT /stars_web_search_user_conditions_1 { "settings": { "number_of_shards": 1, "number_of_replicas": 0, // 索引刷盘间隔，默认1s，导入数据要求不高，先设置120s "index.refresh_interval":"120s", // 是否同步到replica和同步提交translog // 如果是request(默认)同步复制到replica和同步刷盘 // 如果是async则每次在index.translog.sync_interval的时候同步和刷盘 "index.translog.durability":"async", // translog的刷盘间隔 "index.translog.sync_interval":"120s", // 刷盘的translog大小，这个和index.translog.sync_interval满足一个条件时就会刷盘(默认512mb) "index.translog.flush_threshold_size":"2048mb" }, "mappings": { "_source": {"enabled": false}, "properties": { "_all": {"enabled": false}, "userId": { "type": "long" }, "nickname": { "type": "text", "analyzer": "ik_max_word", "search_analyzer": "ik_smart" }, "mobile": { "type": "text", "analyzer": "whitespace" }, "gender": { "type": "keyword" }, "idealGender": { "type": "keyword" }, "registrationTime": { "type": "long" }, "lastImChangeTime": { "type": "long" }, "pornLevel": { "type": "keyword" }, "sendAndReceiveExploreMsgNum": { "type": "integer" }, "momentsNum": { "type": "integer" }, "lastLoginPlatform": { "type": "keyword" }, "vipStatus": { "type": "keyword" }, "adChannel": { "type": "keyword" }, "downloadChannel": { "type": "keyword" }, "adId": { "type": "keyword" }, "frozen": { "type": "boolean" } } } } 查看设置是否生效：
...</p></div><footer class=entry-footer>2 min</footer><a class=entry-link aria-label="post link to 10.es-数据导入" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/10.%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>2.安装es</h2></header><div class=entry-content><p>1准备工作 首先准备3台虚拟机，三台机器上进行相同的操作
1.1修改系统参数 修改资源配置文件：vim /etc/security/limits.conf：
1 2 3 4 5 6 7 # *表示任何用户 # soft表示警告值，hard是真正限制的阈值 # nofile是文件描述符数量，nproc是开启进程数 * soft nofile 65535 * hard nofile 65535 * soft nproc 4096 * hard nproc 4096 修改这个配置要退出当前用户重新登录生效。
修改sysctl配置文件：vim /etc/sysctl.conf修改每个进程可以拥有的虚拟内存区域的数量
1 vm.max_map_count=262144 执行sysctl -p刷新配置
1.2创建es用户 执行命令useradd es添加名为es的用户，执行命令passwd es 然后根据提示输入要设置密码比如qiyuan1502，再次输入确认密码完成设置。
1.3创建目录 1 2 3 mkdir -p /app/elasticsearch mkdir -p /app/elasticsearch/data mkdir -p /app/elasticsearch/log 2安装es 到官网[https://www.elastic.co/cn/downloads/past-releases#elasticsearch ]下载es安装包，上传到服务器下的/app/elasticsearch文件夹中解压：
...</p></div><footer class=entry-footer>6 min</footer><a class=entry-link aria-label="post link to 2.安装es" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/2.%E5%AE%89%E8%A3%85/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>3.es-入门</h2></header><div class=entry-content><p>在7版本以后废弃了type类型，所以一些crud操作的命令会跟着改变
api cat api用来查看es中的各种数据，api结尾带上v表示结果带上列名。
查看基本的集群信息 1 GET _cat/health?v 这个请求完了会拿到一个结果，最主要的就是看status参数，他有3个值：
green：每个索引的primary shard和replica shard都是active状态； yellow：部分replica shard不是active状态，处于不可用状态，当单节点启动es，创建索引默认都是有一个replica shard的，但是replica不能喝primary在一台机器上，这样就会导致这个index的状态是yellow； red：部分索引的primary shard不是active状态，可能有部分数据已经丢失了； 查看集群中的索引。 1 GET _cat/indices?v 查看索引下文档个数 1 GET /_cat/count/{index}?h=count 查看文档个数、索引占用磁盘空间 1 GET /_cat/indices/{index}?v 创建一条索引 1 PUT /{index}?pretty 删除一个索引。 1 DELETE /{index} 添加文档 1 2 3 PUT /{index}/_doc/{id} PUT /{index}/_create/{id} 老版本使用/{index}/{type}/{id}添加文档，如果index和type不存在，es会自动创建，并且默认会把每个field都建立倒排索引，需要注意index下多个type的id也不能相同，否则会报illegal_argument_exception错误，但是要废弃了。
...</p></div><footer class=entry-footer>6 min</footer><a class=entry-link aria-label="post link to 3.es-入门" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/3.%E5%85%A5%E9%97%A8/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>5.索引</h2></header><div class=entry-content><p>mapping 有的时候查询的结果和我们想的不一样，可能会多查或者少查，这是因为添加document的时候es会自动帮我们创建type对应的mapping(dynamic mapping)，mapping中有分词规则、field类型等等，使用**GET /{index}/_mapping/**查看index下的type对应的mapping。
1.核心的数据类型 keyword、text byte、short、integer、long float、double date boolean multivalue：类似数组，要求元素类型必须相同 empty：null,[],[null]这种 object：jsonObject text、multivalue field会触发分词操作，可以指定分词器或者设置不分词，在旧版本中设置index: not_analyzer表示不分词，新版本中只需要把type设置成keyword就表示不分词。 手动建立mapping，不能修改已存在的field的mapping，下面的语句是创建index时指定mapping：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 PUT /website { "settings" : { // 1个primary shard "number_of_shards": 1, // 每个primary shard有0个replica shard "number_of_replicas": 0 }, "mappings": { "properties": { "content": { "type": "text", "analyzer": "english" // 指定特殊语言分词 }, "post_date": { "type": "date" }, "title": { "type": "text" }, "publisher_id": { "type": "keyword", // 不分词的的field "index": false // false表示这个字段不能被当作搜索条件 } } } } 如果想要新增field的mapping执行PUT /{index}/_mapping命令：
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 5.索引" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/5.%E7%B4%A2%E5%BC%95/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>6.搜索</h2></header><div class=entry-content><p>query string的语法 简单的查询可以把过滤条件直接放到url中，使用q表示过滤，比如查询test_field1字段等于test1：
1 2 3 4 5 6 ### 两中写法都是包含就可以，包含的意思是分词之后，存在相同单词 GET /test_index/_search?q=test_field1:test1 GET /test_index/_search?q=+test_field1:test1 ### 减号表示不等于 GET /test_index/_search?q=-test_field1:test1 当我们不指定field的时候比如下面这样就是搜索所有字段，只要有一个字段等于或者不等于(取决于是否使用减号)指定值就可以：
1 2 GET /test_index/_search?q=test1 GET /test_index/_search?q=-test1 在新建document的时候，会把所有的field拼到一个字符串里，并且定义为_all字段，分词后也会建立倒排索引，在搜索时，如果没指定字段，就会去查找_all字段中包含test的所有document。
搜索模式 精确匹配：exact value，全部匹配才算匹配； 全文检索：full text，缩写（比如china 和cn），格式转换(likes、like、liked)大小写，近义词都可以当成匹配； 在建立倒排索引之前会进行normalization处理(提升recall召回率)，把拆出来的词同义词转换、单复数转换等动作，然后在根据转换后的词建立倒排索引，查询的时候也是一样的，先拆词在normalization，在去检索。
不同类型的field，有的可能是exact value比如date，有的可能是full text，比如_all、text。
分词器 切分词语和normalization操作都是分词器的工作。主要是三步：
character filter：过滤文本的内容，比如把html标签和符号去掉； tokenizer：分词； token filter：normalization操作，转换之后可能就把没意义的词去掉了，比如a、the之类的； 1.内置分词器： standard analyzer：默认的分词器。可以大小写转换、去符号，但是没拆’_’； simple analyzer：大小写转换、去符号，也能去’_’； whitespace analyzer：什么都不干，大小写都不转，只按照空格拆； language analyzer：特定语言分词器，比如英语分词器，他可以把单词转成近义词、大小写、去符号、时态转换、去掉没意义的词； 2.测试分词 发送下面的请求会根据参数里analyzer指定的分词器拆分text内容并返回结果：
...</p></div><footer class=entry-footer>3 min</footer><a class=entry-link aria-label="post link to 6.搜索" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/6.%E6%90%9C%E7%B4%A2/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>es-4.原理</h2></header><div class=entry-content><p>1.读写原理 在写入数据的时候先记录translog到os cache同时把数据写到内存的indexing buffer中，这个时候数据是查不到的，内存的indexing buffer中的数据每隔一秒会刷到os cache中，刷到os cache之后才能查到数据。os cache中的数据每个5s(默认)或者达到512m(默认)会刷入磁盘，所以如果es的进程挂了最多会丢1s的数据，primary所在服务器宕机也只会丢失1s数据(副本中还有一份数据)，primary和replica所在服务器都宕机才会丢失5s数据(这种情况极少极少)。
1.1写优化 数据不丢：如果想要数据不丢就设置index.translog.durability: request，他会让translog同步刷盘，性能也会降低。 常规写优化：如果允许数据部分丢失可以设置index.translog.durability: async，只要translog写到os cache就算成功，还可以设置index.translog.sync_interval和index.translog.flush_threshold_size控制os cache刷盘的频率。 段合并优化：indices.memory.index_buffer_size参数控制indexing buffer的大小，如果写满了就会执行刷盘操作，默认是堆内存的10%，可以调大；每次从os cache将索引数据刷盘都会生成一个新的segment文件，segment文件数量到限制后会执行合并操作，数量限制通过index.merge.policy.segments_per_tier参数控制，默认是10，可以调大； 1.2查询优化 增加page cache：es的搜索时严重依赖内存的，如果内存没有需要从磁盘搜索，这个速度就慢了，所以要给es足够内存，一般都是jvm占一般，os cache占一半。 减少存储空间：保证没用的数据不写入es，减少数据的大小，_source、_all(6.x后默认禁用)能禁用就禁用，有一些字段不是查询条件比如业务id可以把index属性设置成false，有一些字段不需要持久化就把store属性设置成false。 容量和集群规划：搭建es时要考虑数据占用空间，并计算未来3年、5年数据的增长来选择机器配置，同时primary要比机器数量多一点，保证以后可以扩容(因为primary shad数量不能修改)。 冷热数据分离：识别出来索引中的冷数据，比如2年前的数据，这些数据可以持久化到Hadoop中。 pre-index：预索引，比如说价格是33.22，存储时额外加一个字段存储的是10-50，表示这个价格所在的区间，根据价格范围查找的时候要比直接根据价格字段快，但是也快不了太多。 提升缓存命中：比如把日期粗化到天，如果是精确到秒很难用到jvm的缓存，也快不了太多。 os cache预热：机器重启的时候可以设置index.store.preload，会把索引提前加载到os cache中。 2.数据路由原理 数据路由：因为一个document只能存在一个primary shard上，在创建数据的时候es需要决定这条文档应该放在哪个shard上。
路由算法：shard = hash(routing) % primary shard数量，当操作中有_id时，这个routing就是_id，然后算出hash值在和primary shard的数量求余。routing值可以手动指定，比如说PUT /test_index/_doc/1?routing=user_id。 这样就可以解释为什么primary shard的数量不可变了，一旦发生变化查找数据很容易就找不到。
3.deep paging 深度分页的意思就是说比如现在有3个shard上有index的数据，每个shard存100000条，然后我要查第10000到10010条数据，他就会把每个shard上的前10010条数据都拿出来，然后根据score排序在拿到第10000到10010条数据返回，deep paging很耗带宽、内存、CPU。
4.filter和其他搜索区别 filter只是根据条件过滤，其他搜索像must还需要计算相关度然后在排序，如果只是要筛选使用filter可以提高性能，filter还是用了cache保存最常用的filter。
5.相关度分数算法 TF/IDF(term frequency/inverse document frequency )算法：
term frequency：搜索的词条在文本里出现了多少次，次数越多越相关； inverse document frequency：搜索的此条在整个index中出现的次数越多就越不想关， 比如搜索词条中有两个词，一个词在整个index中出现5000次，一个词只出现100次，肯定出现100次的词更容易影响分数； field-length norm：field长度和相关度成反比； 在查询命令的url后面拼上explain参数表示打印出相关度计算的detail。
6.doc values(正排索引) 就是类似MySQL，按行存储，排序只能用doc values，如果内存足够的话doc values会存在os cache中，否则只会在磁盘上。</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to es-4.原理" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/4.%E5%8E%9F%E7%90%86/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>filter</h2></header><div class=entry-content><p>查看分词
1 2 3 4 5 6 // 查看forum索引下的field为articleID内容是XHDK-A-1293-#fJ3的分词 GET /forum/_analyze { "field": "articleID", "text": "XHDK-A-1293-#fJ3" } 5版本以后如果field的类型是text，会多建一个field，原field是分词的，es创建的field.keyword是不分词的，类型是keyword，默认保存256个字符。
term语法：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 GET /forum/article/_search { "query": { "constant_score": { // 使用filter需要把匹配度分数设置成1，必须要写constant_score "filter": { "term": { // term搜索，不会对term中的条件进行分词 "articleID" : "XHDK-A-1293-#fJ3" } } } } } // 如果条件的field是分词的，那么这个查询时查不出结果的，可以使用es自动创建的部分词field查询 { "query": { "constant_score": { "filter": { "term": { "articleID.keyword" : "XHDK-A-1293-#fJ3" } } } } } // term还可以写成terms，相当于SQL的in，类似于这样："term": {"articleID" : ["a","b","c"]} filter执行原理
...</p></div><footer class=entry-footer>2 min</footer><a class=entry-link aria-label="post link to filter" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/6.filter/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>全文检索</h2></header><div class=entry-content><p>一般match都是拆词，包含一个词就可以
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 查询title中包含java或者elasticsearch GET /forum/article/_search { "query": { "match": { "title": "java elasticsearch" } } } // 这么写的时候，es把他转换成should语法，像下面这样 GET /forum/article/_search { "query": { "bool": { "should": [ "match": { "title": "java" }, "match": { "title": "elasticsearch" } ] } } } 如果想要必须都包含，也就是并且关系
...</p></div><footer class=entry-footer>3 min</footer><a class=entry-link aria-label="post link to 全文检索" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/7.%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>参数</h2></header><div class=entry-content><p>如果是单台机器上启动多个es，他们会把自己绑定在127.0.0.1（回环地址）上，然后去扫描9300~9305端口，自己就可以维护集群了，生产环境不能这么玩，要想和其他服务器的几点通信需要绑定在非回环地址上，es是peer2peer的分布式系统架构，master负责维护集群信息和其他元数据，把变更的信息推送到其他node（data node）。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 # 集群名称，node的这个属性一样才是集群的基本条件，线上一定要修改，否则其他测试node可能会不小心加入这个集群 cluster.name: elasticsearch-prod # 节点名称 node.name: node-elasticsearch-01 # 绑定地址，多机器一定要配这个 network.host: 192.168.0.10 # 这个配置的是master eligible node，在master宕机的时候从eligible node中选出来一个master，默认就是true node.master: true # 这个是是不是存储数据的节点，如果集群很大的时候可以设置3个节点为专门的eligible node，不存存储数据，这个就设成false node.data: true # unicast的中间节点host列表，其他node会和这几个节点通信然后加入集群，一般写三个就够了，有eligible node优先把eligible node写进去 discovery.zen.ping.unicast.hosts: ["host1", "host2"] # ping的超时时间，可以防止网络问题导致的master选举过慢 discovery.zen.ping_timeout: 3s # 选举之后其他data节点发送一个join加入集群，配置超时时间，超时会重试 discovery.zen.join_timeout: 60s # 强制区分候选节点，避免node.master: false的节点发来请求参与master选举 discovery.zen.master_election.ignore_non_master_pings: true # 这些路径不嫩放在es目录下，方便以后升级 # 存放日志文件 path.logs: /var/log/elasticsearch # 存放数据文件 path.data: /var/data/elasticsearch # 选举的时候最少要求多少候选节点通过，设置为候选节点的quorum（num / 2 + 1）数量 # 三个节点的集群quorum就是2，如果只有两个节点，quorum还是2，有一台机器宕机的时候就不能完成选举 # 如果两个节点，参数设置成1，那么就会随便发生脑裂，因为一个机器一下就把自己变成master了 discovery.zen.minimum_master_nodes: 2 # shard recover操作：当有一些几点无法启动或者还没启动的时候，es检测到已经启动的节点上的shard不正常，比如没有primary， # 就会复制出primary shard，当剩下节点启动之后，发现自己的shard过期就会把shard删除， # 集群发现shard分配不均匀，因为有些机器上一个shard没有，这时候又会把别的节点上的shard转到新启动的节点上，这样是很坑的 # 这三个参数是一起的，意思是在2个node上线之后开始计时，如果1分钟内节点数达到3个就OK，没达到就执行shard recover操作 gateway.recover_after_nodes: 2 gateway.expected_nodes: 3 gateway.recover_after_time: 1m # 锁定jvm内存，防止swaping bootstrap.memory_lock: true # 慢查询日志 index.search.slowlog.threshold.query.warn: 10s index.search.slowlog.threshold.query.info: 5s index.search.slowlog.threshold.query.debug: 2s index.search.slowlog.threshold.query.trace: 500ms index.search.slowlog.threshold.fetch.warn: 1s index.search.slowlog.threshold.fetch.info: 800ms index.search.slowlog.threshold.fetch.debug: 500ms index.search.slowlog.threshold.fetch.trace: 200ms index.indexing.slowlog.threshold.index.warn: 10s index.indexing.slowlog.threshold.index.info: 5s index.indexing.slowlog.threshold.index.debug: 2s index.indexing.slowlog.threshold.index.trace: 500ms index.indexing.slowlog.level: info index.indexing.slowlog.source: 1000 在启动的时候指定配置文件地址，-d后台启动：
...</p></div><footer class=entry-footer>2 min</footer><a class=entry-link aria-label="post link to 参数" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/9.%E5%8F%82%E6%95%B0/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://wangxiaohong123.github.io/tags/elasticsearch/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>