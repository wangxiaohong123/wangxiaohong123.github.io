<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>机器学习 | 王小红的笔记</title><meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangxiaohong123.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script><meta property="og:url" content="https://wangxiaohong123.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="机器学习"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="机器学习"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>机器学习</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>1.机器学习介绍</h2></header><div class=entry-content><p>图灵在50年的时候提出机器思维：一个人在不知道对方是计算机的情况下进行很长时间的问答，如果无法判断对方是不是计算机就说明这个计算机有了人的思维。56年的时候麦卡锡提出了人工智能的术语。
柏拉图假说：不同的人工智能系统以不同的方式表示世界，视觉系统表示为形状和颜色，语言模型表示为语法和语义；但是随着参数规模、训练数据的不断扩大，不同模型对于现实的表征方式会越来越相似，所以现在的大语言模型或者文生视频这种其他模型都使用全模态(文本、视频、音频、深度图等)数据来训练，比单一模态数据性能提高20%。这就发展成现在很多模型都是在大语言模型上微调来的，比如qwen2-VL是基于qwen2的，CogVLM2机遇llama3 8b微调来的。
1 介绍 人工智能发展阶段
1.1 人工智能 三要素：数据，算法，计算力，CPU核心数较少，基于冯诺依曼架构(存储程序，顺序执行)，适合逻辑控制，处理复杂的指令集；GPU核心数较多，适合并行处理大量简单且重复的指令，比如矩阵、向量计算；TPU是Google专门为机器学习设计的芯片。
机器学习是人工智能的实现途径，而深度学习是机器学习发展而来，也就是神经网络。195x年最开始人工智能最多就是和人下个黑白棋，198x年开始使用机器学习分辨垃圾邮件，201x年开始深度学习让机器可以识别图片。
现在的模型分大模型和普通模型，普通模型就像专攻一样，训练的数据有10种类别，他就只能做这10种类别的事。大模型的不光是模型的架构大，也是数据集的大，大模型也可能自己创造训练数据，训练自己，比如segment anything。
1.1.1 当前人工智能目前主要应用领域 计算机视觉(CV)：机器感知环境的能力，比如物体检测和人脸识别。 自然语言处理(NLP)：自然语言处理又包括语音识别、机器翻译、文本挖掘和分类： 文本挖掘和分类：主要是对文字的情绪分析和垃圾检测，目前尤其是中文不同的词在不同的场景有不同的语义是一个难点。 机器翻译：方言、行话是难题。 语音：语音识别，语音合成什么的，音转文和文转音是一个领域，现在声纹识别和鸡尾酒会效应很难处理好。声纹和指纹差不多，每个人的声音都不一样，如果能提取出人的声纹那就可以实现声音支付了。鸡尾酒会是说人的大脑在和别人专心讨论的时候会自动降燥，专注和交流目标对话，目前计算机只能做到很多人说话，找不到应该重点听谁发出的声音。 1.2 机器学习算法分类 算法方向分为ML机器学习，DL深度学习，RL强化学习。
根据数据集组成可以将机器学习的算法分为监督学习、无监督学习、半监督学习和强化学习。如果输出是连续的成为回归，输出是有限个离散值叫分类。
监督学习：输入数据由特征值和目标值组成； 无监督学习：输入数据只有特征没有目标值； 半监督学习：输入数据部分没有目标值，适合数据难标记或者标记成本高的情况，先用少量标记初步训练，然后用未标记数据训练； 强化学习：强化学习是一个决策问题，可以做连续的自动决策，包含5个元素：agent(代理体)，action(行动)，reward(奖励)，environment(环境)和observation(观察情况)，比如让程序中的某个角色模拟走路，这个角色就是agent，他需要决定先迈左脚还是右脚，迈出一步还要不要在迈一步，迈步就是action，地面就是environment，走了几步可以给他reward。强化学习的目标是获得最多的累积奖励；他是不断跟环境交互获取经验，不断进步的过程。通过设计奖励惩罚机制，每正确n步会产生奖励，模型的本质就是获取更多奖励。ALPHAGo、机械手臂、deepseek R1模型都是强化学习实现的。强化学习更像有大脑在思考一样。 对比学习：相当于计算机视觉上的自监督学习，通过随机的图像增强让一张图片随机变成别的样子，但是还属于同一类，这样来代替打标签的操作，同类越相似的思想。如果数据增强变成了核心，数据越离谱学到的东西可能就越多，越花里胡哨效果越好。 监督学习输入的特征都是独立同分布的，独立说的是每次抽样之间相互独立，没有影响，比如掷2次骰子的和大于8，第二次的结果和第一次相关，就不是独立的；同分布说的是每次抽样的样本服从同一个分布，比如掷骰子，每次得到任意点数的概率都是1/6。
1.2.1 强化学习算法 1.2.1.1 Proximal Policy Optimization(PPO)算法 核心思想：PPO 主要改进了策略梯度方法（如 REINFORCE）和信赖域策略优化（Trust Region Policy Optimization, TRPO），使其更加稳定、高效，并且易于实现。其核心思想包括：
克服策略更新的不稳定性： 在策略梯度方法中，策略的更新可能会导致较大的变化，从而影响学习稳定性。 TRPO 通过优化约束（KL 散度约束）限制策略更新的幅度，但实现较为复杂。 PPO 采用了一种更简单且高效的方法，即 剪辑（Clipping）策略比率 来约束策略的更新幅度。 使用信赖区域（Trust Region）控制策略更新幅度： PPO 通过 目标函数中的剪辑项 限制策略的更新步长，从而避免策略发生剧烈变化，提高训练稳定性。 PPO 的两种变体：
PPO-Clip（剪辑版 PPO）： 直接对策略比率（ratio）进行剪辑，确保策略不会更新过大。 目标函数： $L^{clip}(θ)=E[min⁡(r_t(θ)A_t,clip(r_t(θ),1−ϵ,1+ϵ)A_t)]$ 其中： $r_t(θ)= \frac{\pi_{\theta}(a_t | s_t)}{\pi_{\theta_{\text{old}}}(a_t | s_t)}$（新的策略与旧的策略的比率） $A_t$ 为优势函数（Advantage Function） ϵ 是超参数（通常设为 0.1~0.2） PPO-Penalty（KL 散度惩罚版 PPO）： 在优化目标中添加 KL 散度（Kullback-Leibler Divergence）惩罚项，确保策略不会偏离过远： $L^{KL}(θ)=E[L^{clip}(θ)−βD_{KL}[π_{θold}∣∣π_θ]]$ 其中： $D_{\text{KL}}$ 表示旧策略与新策略之间的 KL 散度。 β 是一个超参数，用于调整 KL 惩罚的权重。 1.2.1.2 Q-learning和DQN Q-learing包括2部分，瞬时奖励(做了1个动作就能获得的奖励)和记忆经验奖励(按照训练时的记忆，之后怎么做才能获得更大的奖励)，DQN是对Q-learning的扩展，使用神经网络计算Q-learning函数的参数。
...</p></div><footer class=entry-footer>5 min</footer><a class=entry-link aria-label="post link to 1.机器学习介绍" href=https://wangxiaohong123.github.io/posts/ai/1.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>2.机器学习基础</h2></header><div class=entry-content><p>机器学习就是模仿人类处理问题，人类是先从经验归纳，机器学习也是自动从数据中获取模型，用模型对位置数据进行预测。白话讲就是从历史数据里找规律，有了规律之后根据输入的数据输出结果，这个规律就是模型。比如说某个样子的物体是猫，那下次看见类似的也可以把他当成猫。
机器学习不能解决的问题，跨域：机器学习学习的是历史数据的特征，新的数据不可能和历史数据有一样的特征分布
1. 计算机视觉 用摄像机、电脑或者其他设备模拟生物视觉，让计算机理解图片或者视频中的内容。可以分为三类：
图像分类：将图像结构化成类别信息，用实现确定好的类别来描述图片。 目标检测：关注特定的物体目标，要求获取这一目标的类别和位置信息，他和分类的区别是，分类将图片当做整体，目标检测可以在一张图片中获取多种目标及位置。 图像分割：分割是在检测的基础上还需要获取像素信息。 应用领域：人脸识别、视频监控、智能驾驶、图片识别（以图搜图，图片鉴黄），比如抖音送礼的眼镜特效属于人脸识别里的人脸关键点定位。
2. 自然语言处理 语言模型是用来计算下一个句子概率的模型。
3 时间序列 时间序列是一种 有序的、依赖时间的结构化数据，其核心任务是研究和预测数据随时间变化的规律。深度学习为时间序列任务提供了更强大的建模工具，尤其是在处理复杂非线性关系或长时间依赖时。他是一个跨领域的问题，还会涉及到统计学等。
3. 机器学习的工作流程： 获取数据->对数据进行基本处理->特征工程->机器学习(模型训练，也是算法应用的过程)->模型评估，如果模型评估没有达到要求需要从对数据进行基本处理重新进行一遍。
3.1 获取数据 拿到的数据类似于表格，一行就是一个样本，一列就是一个特征，涉及到判断的列不叫特征，叫目标值，不是所有数据都有目标值。数据分为训练数据和测试数据，一般比例为3/7或者2/8。
3.2 数据基本处理 修改数据的空值、异常值、类型转换等。
3.3 特征工程 对数据的进一步处理。包括特征提取(比如将文本或者图片转换成可以用于机器学习的数字)，特征预处理(通过一些函数将数据转换成适合算法模型的特征数据)和特征降维(降低特征个数)。
3.3.1 特征预处理 将数据转换成机器更好识别，更好处理的数据。当特征数据的单位或者大小相差较大，或者某个特征的方差相比其他的方差大出好几个数量级，这种情况可能这个特征对结果的影响比较大，使得算法无法学习到其他特征。
3.3.1.1 归一化 把原始数据映射到某个区间内，默认0~1。计算公式为： $$ X' = \frac {x - min}{max - min}\
X'' = X' * (mx - mi) + mi $$ 上面的公式中，X''就是归一化处理后的特征值，max和min表示初始特征值的最大值和最小值，mx和mi表示想要将特征值映射到区间的最大值和最小值。
归一化的时候如果出现一条特征统计不正确，比如有1条数据比其他的大了很多倍或者小了很多倍，这种情况对其他数据的影响很大，所以这种方法鲁棒性较差，只适合精确小数据场景。
1 2 3 4 5 6 7 8 9 import pandas as pd from sklearn.preprocessing import MinMaxScaler data = pd.read_csv('./data/dating.txt') # 实例化转化器 transfer = MinMaxScaler(featrue_range=(3, 5)) # 将目标列转换到指定区间，这里是3~5 ret_data = transfer.fit_transform(data[["列1名称", "列2名称"]]) print("转化后的数据:\n", ret_data) 3.3.1.2 标准化 1 2 3 4 5 6 7 8 9 10 11 import pandas as pd from sklearn.preprocessing import StandardScaler data = pd.read_csv('./data/dating.txt') # 实例化转化器 transfer = StandardScaler() # 将目标列转标准化 ret_data = transfer.fit_transform(data[["列1名称", "列2名称"]]) print("转化后的数据:\n", ret_data) print("每一列的方差为:\n", transfer.var_) print("每一列的平均值为:\n", transfer.mean_) 第一步就是去均值，将平均值变成0，然后在比上标准差，这样能让所有维度的数相差不大：$X' = \frac{x - avg}{\sigma}$。
...</p></div><footer class=entry-footer>5 min</footer><a class=entry-link aria-label="post link to 2.机器学习基础" href=https://wangxiaohong123.github.io/posts/ai/2.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>3.机器学习算法</h2></header><div class=entry-content><p>距离度量 一些算法会需要距离度量，比如K近邻、SVM、聚类等，距离有4个特性：
非负性：两点的距离不能小于0； 同一性：两点的距离=0说明时同1个点； 对称性：x到y的距离时0时，y到x的距离也是0； 直递性：dist(i,j)&lt;=dist(i,k) + dist(k,j); 常见的距离公式：
欧式距离：两个点就是勾股定理，n个点就开根号n； 曼哈顿距离：曼哈顿距离是当两个点不能练成直线时的距离，计算公式：$\sum_{k=1}^n\vert X_{k}-X_{k-1} \vert$； 切比雪夫距离：类比于国际象棋中的国王走棋的方式，国王可以在一个步长内向任何方向移动，两点的距离公式为$D(P,Q)=max(\vert x_1−x_2\vert,\vert y_1−y_2\vert,...,\vert x_n−x_{n+1}\vert)$​； 闵氏距离：闵氏距离是将上面3个变成了1个公式，当p=1的时候是曼哈顿距离，p=2的时候是欧式距离，p>=3的时候是切比雪夫距离 1 K近邻算法 根据最近的距离判断类别，最近的样本数据是什么类别，你就是什么类别，这里的样本数量可以取n个。也叫KNN算法。
求两个坐标的距离使用勾股定理，多维也是一样的。
比如现有数据：
电影名 搞笑镜头 拥抱镜头 打斗镜头 电影类型 功夫熊猫 39 0 31 喜剧片 叶问3 3 2 65 动作片 二次曝光 2 3 55 爱情片 代理情人 9 38 2 爱情片 步步惊心 8 34 17 爱情片 谍影重重 5 3 57 动作片 美人鱼 21 17 5 喜剧片 小鬼当家 45 2 9 喜剧片 唐人街探案 23 3 17 唐人街探案时测试数据，上面的事样本数据，需要判断唐人街探案是什么类型的电影时，就要先求出唐人街探案距离每个电影的距离：
...</p></div><footer class=entry-footer>8 min</footer><a class=entry-link aria-label="post link to 3.机器学习算法" href=https://wangxiaohong123.github.io/posts/ai/3.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>