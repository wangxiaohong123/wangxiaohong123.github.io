<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>大数据 | 王小红的笔记</title><meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangxiaohong123.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/index.xml><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script><meta property="og:url" content="https://wangxiaohong123.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="大数据"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="大数据"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>大数据</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>13.kafka源码-集群管理</h2></header><div class=entry-content><p>在KafkaServer中有一个组件是KafkaController，这个组件就是管理集群的核心组件，每个broker都会有一个controller，但是多个broker中只会有一个controller能够选举成功，其他broker也需要监听controller的状态，controller自己也需要自己检查健康状态，所以还有两个组件也是跟集群相关的，一个是zkUtils还有一个是KafkaHealthcheck线程。
选举controller 先看KafkaController的startup()方法：
1 2 3 4 5 6 7 8 9 def startup() = { inLock(controllerContext.controllerLock) { // 注册一个跟zk会话断开的监听器 registerSessionExpirationListener() isRunning = true // 竞争 controllerElector.startup } } 然后进到ZookeeperLeaderElector的startup()方法：
1 2 3 4 5 6 7 8 9 10 def startup { inLock(controllerContext.controllerLock) { // 在/controller这个znode上，注册一个监听器 // 如果有人竞争成为controller，他会感知到 // 如果有人已经成为了controller，然后自己挂掉了，不再是controller，也会感知到 controllerContext.zkUtils.zkClient.subscribeDataChanges(electionPath, leaderChangeListener) // 发起选举 elect } } 上面的leaderChangeListener是ZookeeperLeaderElector的内部类，它里面有两个方法，一个handleDataChange，一个handleDataDeleted，就是节点变更和删除的回调。
...</p></div><footer class=entry-footer><span title='2021-09-27 06:27:35 +0000 UTC'>September 27, 2021</span>&nbsp;·&nbsp;4 min</footer><a class=entry-link aria-label="post link to 13.kafka源码-集群管理" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/13.%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>14.kafka源码-consumer</h2></header><div class=entry-content><p>先看看consumer是怎么初始化的，进到KafkaConsumer的构造方法里，里面初始化了一堆东西，retryBackoffMs、metadata、NetworkClient这些之前都看过了，然后又实例化一个ConsumerCoordinator，最后是一个Fetcher。在我们自己的代码中使用consumer的poll方法拉取消息，所以猜测主要功能都在这个方法中实现，比如自动提交offset，进到ConsumerCoordinator的构造方法里看一下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // 父类的构造方法 super(client, groupId, sessionTimeoutMs, heartbeatIntervalMs, metrics, metricGrpPrefix, time, retryBackoffMs); // 元数据 this.metadata = metadata; this.metadata.requestUpdate(); this.metadataSnapshot = new MetadataSnapshot(subscriptions, metadata.fetch()); // 我们代码里consumer负责的topic this.subscriptions = subscriptions; this.defaultOffsetCommitCallback = defaultOffsetCommitCallback; this.autoCommitEnabled = autoCommitEnabled; this.assignors = assignors; addMetadataListener(); if (autoCommitEnabled) { // 自动提交任务 this.autoCommitTask = new AutoCommitTask(autoCommitIntervalMs); this.autoCommitTask.reschedule(); } else { this.autoCommitTask = null; } this.sensors = new ConsumerCoordinatorMetrics(metrics, metricGrpPrefix); this.interceptors = interceptors; this.excludeInternalTopics = excludeInternalTopics; 但是没看到把consumer加入group的代码，其实加入group的代码在KafkaConsumer的pollOnce()方法中，这个方法被poll调用，在这个方法里有一行代码
...</p></div><footer class=entry-footer><span title='2021-09-27 06:27:35 +0000 UTC'>September 27, 2021</span>&nbsp;·&nbsp;5 min</footer><a class=entry-link aria-label="post link to 14.kafka源码-consumer" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/14.consumer/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>12.kafka源码-副本同步机制</h2></header><div class=entry-content><p>大致流程 之前在看刷盘的源码的时候看到初始化ReplicaManager的时候创建了一些组件，其中就有一个replicaFetcherManager，看名字就知道这个是负责副本同步的，他实例化了一个ReplicaFetcherManager对象，这个类只有两个方法，createFetcherThread()和shutdown()，再进父类AbstractFetcherManager中看一下，发现父类中多了两个方法：addFetcherForPartitions和removeFetcherForPartitions，add方法就是为一部分分区创建同步的线程，回到ReplicaManager中找一下在哪用到了add方法，然后就找到了方法：makeFollowers()，思路大概就懂了，在broker感知到自己负责了某个partition的副本后，就调用这个方法，然后创建线程，不断地拉取和更新数据，首先看下方法注释：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /* * 说得是让这个broker负责的一批partition变成follower都有哪些步骤 * Make the current broker to become follower for a given set of partitions by: * * 把这些分区的leader从leader的set中移除 * 1. Remove these partitions from the leader partitions set. * 把这些partition标记成follower，这样任何producer都不能往这写分区中写数据 * 2. Mark the replicas as followers so that no more data can be added from the producer clients. * 对这些分区停止已有的replica fetcher线程 * 3. Stop fetchers for these partitions so that no more data can be added by the replica fetcher threads. * 把这些分区的日志阶段，记录offset * 4. Truncate the log and checkpoint offsets for these partitions. * 清理掉分区的延迟调度 * 5. Clear the produce and fetch requests in the purgatory * 给新的副本分区添加fetcher * 6. If the broker is not shutting down, add the fetcher to the new leaders. * * 保证不会有脏数据 */ 进到AbstractFetcherManager的addFetcherForPartitions()方法，循环创建fetcherThread：
...</p></div><footer class=entry-footer><span title='2021-09-25 06:27:35 +0000 UTC'>September 25, 2021</span>&nbsp;·&nbsp;4 min</footer><a class=entry-link aria-label="post link to 12.kafka源码-副本同步机制" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/12.%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>11.kafka源码-磁盘操作</h2></header><div class=entry-content><p>之前启动的时候看到了跟磁盘有关的两个组件，一个是LogManager，还有一个是ReplicaManager，而且在初始化ReplicaManager的时候LogManager是被当做参数传进去的，先看一下ReplicaManager都实例化了那些东西：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 // 配置的brokerId private val localBrokerId = config.brokerId // 所有的partition信息 private val allPartitions = new Pool[(String, Int), Partition](valueFactory = Some { case (t, p) => new Partition(t, p, time, this) }) // 这个就是一把锁 private val replicaStateChangeLock = new Object val replicaFetcherManager = new ReplicaFetcherManager(config, this, metrics, jTime, threadNamePrefix) // 高水位的检查，只有当所有的副本都保存了消息，高水位才会指向最新的消息 // 消费者只能消费到高水位之前的消息 private val highWatermarkCheckPointThreadStarted = new AtomicBoolean(false) val highWatermarkCheckpoints = config.logDirs.map(dir => (new File(dir).getAbsolutePath, new OffsetCheckpoint(new File(dir, ReplicaManager.HighWatermarkFilename)))).toMap private var hwThreadInitialized = false val stateChangeLogger = KafkaController.stateChangeLogger // isr列表相关 // 当follower没有落后太多的时候才会出现在isr列表 private val isrChangeSet: mutable.Set[TopicAndPartition] = new mutable.HashSet[TopicAndPartition]() private val lastIsrChangeMs = new AtomicLong(System.currentTimeMillis()) private val lastIsrPropagationMs = new AtomicLong(System.currentTimeMillis()) // 延迟调度机制，实践论的算法 val delayedProducePurgatory = DelayedOperationPurgatory[DelayedProduce]( purgatoryName = "Produce", config.brokerId, config.producerPurgatoryPurgeIntervalRequests) val delayedFetchPurgatory = DelayedOperationPurgatory[DelayedFetch]( purgatoryName = "Fetch", config.brokerId, config.fetchPurgatoryPurgeIntervalRequests) // 本地存储的leader数 val leaderCount = newGauge("LeaderCount", new Gauge[Int] { def value = { getLeaderPartitions().size } }) // 本地的分区数 val partitionCount = newGauge("PartitionCount", new Gauge[Int] { def value = allPartitions.size }) // 副本数量不充足的partition val underReplicatedPartitions = newGauge("UnderReplicatedPartitions", new Gauge[Int] { def value = underReplicatedPartitionCount() }) // isr列表扩张和伸缩的速率 val isrExpandRate = newMeter("IsrExpandsPerSec", "expands", TimeUnit.SECONDS) val isrShrinkRate = newMeter("IsrShrinksPerSec", "shrinks", TimeUnit.SECONDS) // 下面还有一些函数和线程之类的 初始化完ReplicaManager之后执行startup方法，启动两个关于isr的定时调度线程：
...</p></div><footer class=entry-footer><span title='2021-09-21 06:27:35 +0000 UTC'>September 21, 2021</span>&nbsp;·&nbsp;9 min</footer><a class=entry-link aria-label="post link to 11.kafka源码-磁盘操作" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/11.%E7%A3%81%E7%9B%98%E6%93%8D%E4%BD%9C%E6%BA%90%E7%A0%81/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>10.kafka源码-服务端网络通信</h2></header><div class=entry-content><p>在本地安装scala2.10.7、gradle3.1、和zk。
到kafka官网下载0.10.01的源码，然后进入kafka-0.10.0.1-src目录执行下面目录为idea构建：
1 gradle idea 构建的时候出现如下错误：
打开build.gradle文件，在import和build script中间加上以下代码重新构建即可：
ScalaCompileOptions.metaClass.daemonServer = true ScalaCompileOptions.metaClass.fork = true ScalaCompileOptions.metaClass.useAnt = false ScalaCompileOptions.metaClass.useCompileDaemon = false 然后打开idea安装scala插件，导入kafka源码。
结构 bin：一些执行脚本 checkstyle：静态代码的检查配置 clients：客户端代码，用java写的 config：配置文件 connect：这个是kafka一个新的项目，把数据源的数据引入进来，比如说把数据交给clients项目 core：消息系统，使用scala写的 streams：kafka提供的流式计算的项目，java写的 修改server.properties的log.dirs路径，然后在edit configurations做如下配置：
运行core下的kafka文件启动测试。
进入core模块，在最下面有一个kafka的类，这个就是启动类，里面有一个main方法：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def main(args: Array[String]): Unit = { try { // 读取配置 val serverProps = getPropsFromArgs(args) // 创建KafkaServerStartable对象 val kafkaServerStartable = KafkaServerStartable.fromProps(serverProps) // 处理control + c杀掉进程用的 Runtime.getRuntime().addShutdownHook(new Thread() { override def run() = { kafkaServerStartable.shutdown } }) // kafkaServerStartable启动，其实里面调用的就是server包下的KafkaServer的startup()方法 kafkaServerStartable.startup // 关闭事件 kafkaServerStartable.awaitShutdown } catch { case e: Throwable => fatal(e) System.exit(1) } System.exit(0) } 在KafkaServer的startUp()中初始化了所有组件，核心的是下面这些：
...</p></div><footer class=entry-footer><span title='2021-09-20 06:27:35 +0000 UTC'>September 20, 2021</span>&nbsp;·&nbsp;5 min</footer><a class=entry-link aria-label="post link to 10.kafka源码-服务端网络通信" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/10.%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>2.集群搭建</h2></header><div class=entry-content><p>首先安装3台虚拟机，需要密码登录。在/etc/hosts配置本机的hostname到ip地址的映射，然后配置yum：
1 2 3 yum clean all yum makecache yum install -y wget 因为集群内部需要通信，所以需要关闭防火墙或者设置开放端口：
1 2 systemctl stop firewalld.service systemctl disable firewalld.service 安装jdk，把rpm包上传到虚拟机，安装：
1 rpm -ivh jdk-8u181-linux-x64.rpm 在~/ .bashrc中配置jdk的环境变量：
1 2 export JAVA_HOME=/usr/java/latest export PATH=$PATH:$JAVA_HOME/bin 每台虚拟机的hosts文件配置其他两台机器的ip映射，类似这样：
1 2 172.24.5.218 cluster01 172.24.5.217 cluster03 设置虚拟机互相免密登陆
...</p></div><footer class=entry-footer><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;2 min</footer><a class=entry-link aria-label="post link to 2.集群搭建" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/2.%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>3.kafka集群管理</h2></header><div class=entry-content><p>删除topic： 删除topic需要先设置delete.topic.enable为true，执行命令删除：
1 2 # 删除是异步的，可能需要删除很长时间 ./kafka-topics.sh --delete --zookeeper cluster01:2181,cluster02:2181,cluster03:2181 --topic test-topic topic管理平台： 一般的小公司是不需要这个topic管理的，因为小公司可能就1个人或者几个人来维护kafka，像实时计算团队或者业务团队可能就跟你说一声要使用哪个topic，平时是没人管这个topic的，所以维护的人可以直接在命令行看一看就可以了。
查看消息数量： 查看消息数量需要先查看当前的消息索引，然后在查看其实的消息索引，他俩一减就是消息数量，为什么要减呢，因为kafka的消息不止一只保留的，可能只是最近7天的：
1 2 3 4 # 查看每个分区最大的消息位移 ./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list cluster01:9092,cluster02:9092,cluster03:9092 --topic test01 --time -1 # 查看每个分区最小的消息位移 ./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list cluster01:9092,cluster02:9092,cluster03:9092 --topic test01 --time -2 扩容partition 1 2 # 把partition数量调整到10，kafka的分区只能增不能减 ./kafka-topics.sh --alter --zookeeper cluster01:2181 --partitions 10 --topic test-topic 自研监控平台 其实就是在代码里执行一些命令或者api，或者直接掉kafka的脚本，可以每天凌晨扫描topic的数据量，如果发现topic数据量增长的很快，就可以自动扩容分区。
...</p></div><footer class=entry-footer><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 3.kafka集群管理" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/3.kafka%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>4.producer</h2></header><div class=entry-content><p>发送消息过程 首先每个producer会从配置的broker上拉取topic、分区、broker等信息，在producer收到消息之后会先封装成一个producerRecord对象，然后把对象交给序列化组件，然后经过partitioner组件分配发送到那个broker上，如果发消息时没指定key，也没指定分区算法，默认会轮询，然后把消息发送给缓冲区，通过sender组件从缓冲区读取数据，打包成batch发送给broler。
常见异常 LeaderNotAvailableException：leader不可用，这个时候可能是leader挂了，正在选举；
NotControllerException：如果controller所在的broker挂了就会出现这个异常；
NetworkException：网络异常；
这些异常一般重试就可以解决。
TimeOutException：默认连接broker的超时时间是30s，如果30s没连上kafka可能集群都挂了。
参数配置 buffer.memory：缓冲的大小，默认是33554432，就是32M，如果说发送消息速度特别快，等到senderer线程封装batch在发送出去会慢一点，慢慢缓冲区满了发送消息就会卡住，刚开始可能是够用的，可以在发送消息前后加时间戳，看到发送消息大于10mx的时候可能就是缓冲区满了。 compression.type：发送消息时压缩算法，默认是none，开启后会增加CPU的开销，但是可以提升吞吐量，效率最好的就是lz4。 batch.size：打包发送的数据的字节数，默认是16k，这个在高并发的时候是偏小的，可以统计每100ms的消息的发送数量，然后适当调大这个值，看看吞吐量是不是有提升，16k是偏小的，一般是64k或者128k。 linger.ms：默认是0，可以设置成50或者100，意思是在50ms还没凑到batch大小，也把消息发送出去。 max.request.size：默认是1048576，就是1M，表示单条消息的最大值，1M是偏小的，可以设置成10M。 request.timeout.ms：超时时间，默认30s，够用。 retries：发送失败的重试次数，3到5次就可以cover住一般的异常了，不放心的话可以重试10次，但是重试可能导致消息的重复后者消息的乱序，因为在你重试的时候可能别的消息已经发出去了。 retry.backoff.ms：每次重试的毫秒数。 max.in.flight.request.per.connection：同时间发送消息的条数，如果设置成1表示同时间只能发同一条消息，就是在消息重试的时候其他消息需要等待这个法成功。 acks：他有3个选项，0：表示只要发出去就算成功，不管leader写没写成功；1：leader写成功才算成功；-1或者all：leader和所有follower写成功才算成功； max.block.ms：默认60s，当缓冲区慢了的时候，会阻塞住60s，超过时间会抛出异常。 自定义分区 一般情况不需要顺序消费的话发送消息时连key都不需要指定，默认的轮询就好了，如果想要顺序比支付和退款，这种需要先付钱在退款的可以把key设置成订单的id，这样就会发送到固定的partition上，broker的写一定是有序的，所以这个分区器一般用不到，如果非要用可以实现Partitioner接口：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class HotDataPartitioner implements Partitioner { private Random random; @Override public void configure(Map&lt;String, ?> configs) { random = new Random(); } @Override public int partition(String topic, Object keyObj, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) { String key = (String)keyObj; List&lt;PartitionInfo> partitionInfoList = cluster.availablePartitionsForTopic(topic); int partitionCount = partitionInfoList.size(); int hotDataPartition = partitionCount - 1; return !key.contains(“hot_data”) ? random.nextInt(partitionCount - 1) : hotDataPartition; } } 然后把配置partitioner就可以了：
...</p></div><footer class=entry-footer><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 4.producer" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/4.producer/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>5.consumer</h2></header><div class=entry-content><p>参数 heartbeat.interval.ms：心跳的时间间隔。 session.timeout.ms：默认10s，如果broker10s内感知不到consumer的心跳就会认为consumer宕机，进行rebalance。 max.poll.interval.ms：两次pool的间隔超时，比如说虽然你一直在发心跳，但是poll一次消息之后，很长时间都没消费完，那broker就会认为你不靠谱，也会把你踢出去。 fetch.max.bytes：消费消息的最大值，一般可以设置成10M（10485760），要不然来一条大消息就消费不了了。 max.poll.records：每次最多拉多少条数据，默认500，如果消费的吞吐量特别大，这个参数可以调大。 connection.max.idle.ms：这个是说如果socket连接空闲得话会不会回收，可以设置成-1，不要回收。 enable.auto.commit：开启自动提交，开启之后消息消费完会有consumer自己去定时提交offset，这样会出现一个问题，就是每次重启都会重复消费一批数据。 auto.commit.ineterval.ms：自动提交的间隔。 auto.offset.reset：重启后发现offet在broker中找不到，怎么处理，可以设置成earliest，从最早的开始消费。 原理 每个consumer都要有一个组，并且每个分区只能被一个consumer消费，但是一个consumer可以消费多个分区，所以如果只有3个分区，创建10个consumer是没用的。consumer收到消息之后默认定时自动提交offset，就是把offset发送到_consumer_offsets队列。
coordinator coordinator是负责consumer的心跳、宕机判断以及rebalance的，当consumer group启动的时候，会对consumer group id的hash取模，然后根据_consumer_offsets的分区数，默认是50进行取余，拿到的分区的leader所在的broker就是这个group的coordinator。
每个consumer都发送JoinGroup请求到Coordinator，然后Coordinator从一个consumer group中选择一个consumer作为leader，把consumer group情况发送给这个leader，接着这个leader会负责制定分区方案，通过SyncGroup发给Coordinator，接着Coordinator就把分区方案下发给各个consumer，他们会从指定的分区的leader broker开始进行socket连接以及消费消息。
rebalance策略：
range：按照区间给，比如0-2的分区给第一个consumer，3-5分区给第二个consumer。 round-robin：轮询，第一个消费者消费0分区，第二个消费1分区……。 sticky：强两个分区方式问题很大，比如第二个consumer死了，可能所有的consumer被新分配的分区和之前的都不一样，为了解决上面的问题sticky把宕机的consumer的分区在均匀的分配给现有的consumer。 自定义消费分区 1 2 3 4 List&lt;PartitionInfo> partitions = consumer.partitionsFor(“order-topic”); new TopicPartition(partitionInfo.topic(), partitionInfo.partition()); // 指定每个consumer要消费哪些分区，你就不是依靠consumer的自动的分区分配方案来做了 consumer.assign(partitions);</p></div><footer class=entry-footer><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 5.consumer" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/5.consumer/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>6.常见问题</h2></header><div class=entry-content><p>消息丢失 数据重复 消息乱序 消息积压 配合分布式事务实现消息事务支持 消息的过期时间TTL 延迟队列 多优先级队列 私信队列 重试队列 下游数据计算错误如何回溯 当下游的代码有bug时，产生了一些错误数据，这个时候应该删掉错误数据然后在判断是不是应该数据的回溯。
消息路由 消息流转链路进行轨迹监控 消息质量监控 就是每天流转了多少条数据，链路完整、流转完整占比多少，流转不完整的占比多少，处理错误的占比多少。</p></div><footer class=entry-footer><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 6.常见问题" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/6.%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://wangxiaohong123.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>