<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.150.0"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>王小红的笔记</title><meta name=description content><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangxiaohong123.github.io/index.xml><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script><meta property="og:url" content="https://wangxiaohong123.github.io/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="王小红的笔记"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="王小红的笔记"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"王小红的笔记","url":"https://wangxiaohong123.github.io/","description":"","logo":"https://wangxiaohong123.github.io/favicon.ico","sameAs":[]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>0.参数</h2></header><div class=entry-content><p>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # flower落后几条消息会被踢出ISR列表，默认4000（0.9之前） replica.lag.max.messages # 超过多长时间没保证消息同步会被踢出ISR列表，默认10s（代替上一个） replica.lag.time.max.ms # 日志文件的大小上限（默认1G） log.segment.bytes # 日志达到所少会创建索引数据（默认4k） log.index.interval.bytes # 日志文件保存时间（默认7天） log.retention.hours # processor线程数 num.network.threads # 全局队列长度 queued.max.requests # handler线程池大小 num.io.threads # 达到多少数量从os cache刷盘 log.flush.interval.messages=10000 # 每隔多久刷一次盘 log.flush.interval.ms=1000 # 定时重新选举leader，默认300s auto.leader.rebalance.enable=true # 发送缓冲区的大小，-1是默认 send.buffer.bytes # 接收缓冲区的大小，-1是默认 receive.buffer.bytes</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 0.参数" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/0.%E5%8F%82%E6%95%B0/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.activiti-核心组件</h2></header><div class=entry-content><p>1.核心类 1.1 Deployment 添加资源文件，获取部署信息、部署时间。
通过Deployment类部署流程：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Resource private RepositoryService repositoryService; public void initDeployment() { // 部署流程，其实就是持久化流程图到数据库 Deployment deployment = repositoryService.createDeployment() .addClassPathResource("bpmn文件路径") .name("流程部署") .deploy(); // 查询所有流程 List&lt;Deployment> allDeployment = repositoryService.createDeploymentQuery().list(); // 删除流程，true表示删除该流程的历史之类的 repositoryService.deleteDeployment("deploymentId", true); } 1.2 ProcessDefinition 他和Deployment类都是记录资源信息，ProcessDefinition记录版本号、资源名称、部署id(用来关联Deployment表)。
...</p></div><footer class=entry-footer>2 min</footer><a class=entry-link aria-label="post link to 1.activiti-核心组件" href=https://wangxiaohong123.github.io/posts/activiti/1.%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.dubbo-源码环境</h2></header><div class=entry-content><p>先在github上找到dubbo：https://github.com/apache/dubbo，然后把3.0的源码下载到本地。之前dubbo使用的最普及的是2.7，但是现在3.0用的也很多，而且3.0的源码变化有点大。
接着进入到下载的源码目录执行mvn安装：
1 2 3 mvn install -Dmaven.test.skip=true # 为idea准备dubbo的工程目录 mvn idea:idea 然后用idea打开项目，然后我们就可以通过dubbo自带的demo：dubbo-demo作为入口，跟着功能进行断点，一点一点分析源码。dubbbo-demo下面有很多demo模块，是不同的使用方式，我只看dubbo-demo-api就可以，dubbo-demo-api下面又有两个模块，一个请求消费，一个请求发送。
因为dubbo-demo-api-consumer和dubbo-demo-api-provider都有两种模式，我使用经典模式，需要设置启动参数是classic：
1 2 3 4 5 6 7 8 9 10 11 public static void main(String[] args) throws Exception { if (isClassic(args)) { startWithExport(); } else { startWithBootstrap(); } } // 参数中有classic就是经典模式 private static boolean isClassic(String[] args) { return args.length > 0 && "classic".equalsIgnoreCase(args[0]); } ...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 1.dubbo-源码环境" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/spring/cloud-alibaba/dubbo/1.%E6%BA%90%E7%A0%81%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.kafka原理</h2></header><div class=entry-content><p>数据写入，如何保证单机每秒几十万 微批处理技术：spark streaming这种流式计算的时候会使用这种思想，收集数据后统一处理，提高吞吐量，比如9ms可以收到1000条数据，然后花1ms写入磁盘，这样只花10ms就可以处理完1000条数据，要比收到一条就花1ms写一条快100倍（1000条 * 1ms = 1s）。
使用微批处理提高吞吐还是会有一定的延迟，但是kafka可以保证高吞吐，低延迟，kafka通过os cache + 磁盘顺序写实现高吞吐低延迟，写os cache和磁盘顺序写的性能基本上和写入内存差不多，假设0.01ms写一条数据，那么1s就可以处理10万条数据。
零拷贝实现高性能读取 正常从把消息发送给客户端需要先从os cache中读取数据，如果os cache中没有就去从磁盘里读取，这步是需要从用户态切换到内核态的，然后把数据拷贝到应用进程的内存，在从内核态切换回用户态，把数据拷贝到socket cache中，在发送给网卡把数据发射出去，多余的是两次用户态和内核态之间的切换，和两次拷贝：
kafka使用linux的sendfile，直接把数据从os cache发送给网卡，非常高效：
消息存储 kefka使用NIO的ByteBuffer一二进制的方式保存消息，比java对象保存方式节约40%的空间，每条消息时封装在log entry中，可以理解成一个消息条目，首先会有一个消息集合（record batch）的概念，里面包含多个日志，每个消息集合会记录自己的offect和总消息大小、创建时间戳等信息，具体的消息格式：
消息总长度 时间戳增量：相对于所属的record batch的增量 offset增量：相对于所属的record batch的增量 key长度 key：用来做消息负载均衡使用 value长度 value header个数 header：自定义的消息元数据，key-value格式 时间戳和offset都是采用增量的方式存储，可以减少磁盘空间的占用。每个topic会把消息均匀的存储到每个partition上，每个partition也会有一个冗余副本。
每个分区会在自盘上有一个对应的目录，格式是topic-分区号，例如：order-topic-0。每个分区的日志会被拆成多个，并且每个日志文件有自己的索引文件：
00000000000005367851.index
00000000000005367851.log
00000000000005367851.timeindex
.log是存放数据的，文件名是起始的offset，.index是位移索引，另一个是时间戳索引。每个文件的大小可以通过log.segment.bytes（默认1G）配置，达到参数大小会重新创建一个文件，这个过程叫log rolling，正在被写入的文件叫active log segment，其他的日志文件叫log segment file。当日志写入达到一定大小的时候会在索引文件写入一条索引，通过log.index.interval.bytes（默认4k）配置，索引是按照位移和时间戳升序，这样可以使用2分查找快速定位数据。
数据默认保存7天，通过log.retention.hours设置。
ISR（in-sync replica）机制 靠partition的多副本机制可以保证高可用，但是不能保证消息不丢失，kafka会维护一张ISR列表，只有和leader的消息是同步的flower才会出现在这个列表中，如果leader宕机，会从ISR列表中的flower选举一个leader，ISR要求最少有一个flower和leader的消息同步，并且消息要同时在leader和flower都写成功才算成功。
在0.9版本之前，通过replica.lag.max.messages（默认4000）设置那些flower会被踢出去，但是这样会有一个问题，就是在高并发的时候，如果1s内并发上完，所有flower都不满足这个条件就会被踢出去，等到flower同步之后又来一万，所有flower就又会被踢出去，一直这样反反复复。在0.9之后使用replica.lag.time.max.ms（默认10秒）替代之前的配置，表示超过多少秒flower还没完成同步就把他踢出ISR列表。
LEO（log end offset）和HW（high watermark） 不管是leader还是flower都是副本，每个副本都有一个leo和hw，leo表示当前消息的结束偏移量，也就是下一新条消息的偏移量，hw表示能被消费到的消息的偏移量，每个leader会存储所有flower的leo值，当flower来fetch消息的时候会带上自己的leo，leader更新维护的flower的leo，返回自己的hw，flower拿到返回的leo和自己的取小，更新本地的hw。
leader切换时的数据丢失1：高水位（非常极端的场景）：
比如说broker往leader里写入一条数据，flower进行同步成功，但是第一次拉取数据leader返回的HW是0，所以flower的HW还是0:
等到下一次去fetch数据的时候，leader判断flower的LEO和自己的一样就会更新HW，然后返回，当flower收到响应还没更新的时候宕机重启了，此时会根据HW调整LEO，LEO变成了0，刚要从leader哪里fetch数据，结果leader宕机了，此时flower被选举成新的leader，然后旧leader重启，fetch数据后发现leader没有数据，就会把自己的消息也删掉。
leader切换导致数据丢失2：数量巧合
假设flower比leader落后10条消息，此时leader宕机，flower被选举成新leader，在收到10条消息后，leader重启变成flower，fetch数据的时候发现HW相同，就会以为数据是同步的。。。这样不止会丢掉10条消息，leader的新10条消息还没有同步，这样消息时错乱的。
0.11.x的leader epoch机制
0.11.x新增了一个epoch，里面是自己当leader时的版本号和消息的offset，比如刚启动的时候是[epoch:0,offset:0]，如果flower重启看到自己没有epoch是不会截断数据的，直接去更新，只有当发现自己的offset比leader大的时候才会删除数据，这样可以解决高水位的消息丢失问题，对于第二种情况，他会leader重启之后变成flower，发现自己的offset是1，但是新的leader是从1开始写的，所以判定自己多了一条数据，就会截断这条数据，并不能解决数据丢失，但是最起码数据不是乱的。
broker 生产者/消费者和broker使用基于nio的长连接通信，broker和broker之间使用自定义的tcp协议通信。每个broker上都有一个acceptor线程和多个processor线程（默认3个），processor通过nio的selector轮询多个连接，收到请求后发送到一个全局队列，队列大小是500，可以通过queued.max.requests设置，队列由KafkaRequestHandler线程池消费，处理完结果会放到processor自己的响应队列中，通过processor返回响应。
controller controller负责broker的宕机感知、新节点、选举、负载均衡迁移等等，broker启动的时候回向zk发送注册临时节点的请求，zk可以保证只有一个broker能成功，谁先注册成功谁就是controller，然后controller监听zk上的broker信息变更，他会把zk上的信息拉取到本地，取出第一个作为leader，然后分配每个partion在那台机器上，然后在把所有的flower写到ISR列表里，最后把所有信息推送给所有broker。
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 1.kafka原理" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/1.%E5%8E%9F%E7%90%86/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.netty-demo</h2></header><div class=entry-content><p>新建工程，引入依赖：
1 2 3 4 5 &lt;dependency> &lt;groupId>io.netty&lt;/groupId> &lt;artifactId>netty-all&lt;/artifactId> &lt;version>4.1.82.Final&lt;/version> &lt;/dependency> server端： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 public class NettySever { public static void main(String[] args) { // 声明两个EventLoopGroup EventLoopGroup parentGroup = new NioEventLoopGroup(); EventLoopGroup childGroup = new NioEventLoopGroup(); // netty的服务器声明 ServerBootstrap serverBootstrap = new ServerBootstrap(); try { serverBootstrap.group(parentGroup, childGroup) // 监听端口的serverChannel .channel(NioServerSocketChannel.class) // 用来存放等待处理的客户端请求的队列大小 .option(ChannelOption.SO_BACKLOG, 1024) // 处理客户端请求的handler .childHandler(new ChildChannelHandler()); // 尝试启动服务，绑定端口并同步等待启动服务器的结果 ChannelFutrue channelFutrue = serverBootstrap.bind(50070).sync(); // 同步等待关闭服务器的结果 channelFutrue.channel().closeFutrue().sync(); } catch (InterruptedException e) { e.printStackTrace(); } finally { parentGroup.shutdownGracefully(); childGroup.shutdownGracefully(); } } /** * 处理每个客户端连接的socketChannel的逻辑 */ private static class ChildChannelHandler extends ChannelInitializer&lt;SocketChannel> { @Override protected void initChannel(SocketChannel socketChannel) { // 针对网络请求的处理逻辑 socketChannel.pipeline().addLast(new NettyServerHandler()); } } } server端handler：
...</p></div><footer class=entry-footer>3 min</footer><a class=entry-link aria-label="post link to 1.netty-demo" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C/nio/netty/1.demo/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.NIO-buffer</h2></header><div class=entry-content><p>一 创建缓冲区 创建缓冲区有3种方式：
1.创建空缓冲区 创建空缓冲区适合用在从磁盘文件读取数据或者从网络里读取数据
1 ByteBuffer buffer = ByteBuffer.allocate(10); 2.创建有数据的缓冲区 把现有数据写入磁盘或者网络
1 2 byte[] data = new byte[] {1, 2, 3}; ByteBuffer buffer = ByteBuffer.wrap(data); 3.direct缓冲区 正常的缓冲区前面还有一个jvm的缓冲区(堆外内存)，读取和写入都是要经过jvm的缓冲区，使用direct模式创建缓冲区，就没有jvm的缓冲区，性能会高一点
1 ByteBuffer buffer = ByteBuffer.allocateDirect(10); 不管是把jvm内存中的数据刷到磁盘、socket或者从磁盘读取数据到jvm，都是要先经过一个buffer。
二 buffer demo capacity：缓冲区的大小； limit：limit是用来卡死一个界限，比如buffer中有5个数据（1到5），limit指向3，就只能操作第3位之前的数据1、2、3这三个个数，默认limit和capacity是一样的； position：下一个读取数据的位置； mark：就是一个标记，调用reset()方法时，position会回到mark的位置； remaining：当前position距离limit还有多少位； 一般常用的byteBuffer、charBuffer，像什么longBuffer之类的没用过；
1 2 3 4 5 6 7 8 9 10 11 12 // 操作缓冲区 byte[] data = new byte[] {1, 2, 3}; ByteBuffer buffer = ByteBuffer.wrap(data); System.out.println(buffer.capacity()); System.out.println(buffer.position()); // 设置position的位置 buffer.position(1); System.out.println(buffer.limit()); // 从buffer中读取一位 System.out.println(buffer.get()); // 设置mark buffer.mark(); 三 常见方法 clear()：把position变成0，limit变成capacity，废弃mark，并不是删除数据了，这样再写的时候可以覆盖旧的数据； flip()：把limit变成position，然后position变成0，这样的话在读取数据就只能从0读取到之前的position了； rewind()：limit不变，position变成0，比如说刚读完一遍数据，还想在读一遍，用这个方法就可以了； reset()：让position回到mark位置，但是需要先调用mark()方法，否则会报错； get()：读取数据，可以直接把数据读到数组中； put()：插入或覆盖数据，可以直接写入数组；</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 1.NIO-buffer" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C/nio/1.buffer/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.shiro入门</h2></header><div class=entry-content><p>功能 1.主要功能 Authentication：身份认证/登录，验证用户是否是所声明的用户。 Authorization：授权验证，验证某个用户是否拥有某个权限。 Session Management：会话管理，用户信息也是保存在会话当中。 Cryptography：加密，保护数据的安全性。 2.扩展功能 web support：很容易集成到web环境。 caching：缓存，避免每次查询数据库。 concurrency：多线程并发验证。 testing：很方便的测试验证。 run as：允许一个用户假装成另外一个用户身份。 remember me：记住我那个选中框。 使用 使用流程：创建realm(安全数据源)->构建框架核心类SecurityManager->将realm绑定到SecurityManager->获取token凭证(用户名|密码)->调用Subject API完成登录校验。
创建好一个springboot的项目，引入MySQL，编辑好配置文件，增加shiro的配置：
1 2 3 4 5 6 &lt;!-- 我这里使用的是1.8.0 --> &lt;dependency> &lt;groupId>org.apache.shiro&lt;/groupId> &lt;artifactId>shiro-spring-boot-web-starter&lt;/artifactId> &lt;version>${shiro.version}&lt;/version> &lt;/dependency> 1.登录： 一）测试在代码里写死用户名和密码：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Test public void login() { SimpleAccountRealm realm = new SimpleAccountRealm(); realm.addAccount("xx", "123456"); DefaultSecurityManager defaultSecurityManager = new DefaultSecurityManager(); defaultSecurityManager.setRealm(realm); // 全局设置安全管理器 SecurityUtils.setSecurityManager(defaultSecurityManager); UsernamePasswordToken token = new UsernamePasswordToken("xx", "123456"); // 创建Subject Subject subject = SecurityUtils.getSubject(); // 登录 subject.login(token); Assert.isTrue(subject.isAuthenticated()); // 登出 subject.logout(); Assert.isTrue(!subject.isAuthenticated()); } 二）测试通过文件获取用户
...</p></div><footer class=entry-footer>5 min</footer><a class=entry-link aria-label="post link to 1.shiro入门" href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E5%AE%89%E5%85%A8%E8%AE%A4%E8%AF%81/shiro/1.%E5%85%A5%E9%97%A8/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.union find</h2></header><div class=entry-content><p>union find的定义是有一系列的整数对，每队整数表示互相相连，这些整数对有以下特性：
如果整数对p和q是相连的，那么q和p也是相连的； p和p是相连的； 如果p和q相连，q和r相连，那么p和r也是相连的； union find如果整数对表示网卡之类的东西可以实现在网络中快速判断两台计算机是否可以通信，我们把节点之间的连接叫做分量，首先需要设计一份API封装所需要的操作，比如初始化，两个节点新建连接、判断两个节点是否可以连接等：
1 2 3 4 5 6 7 8 9 10 // 初始化N个节点，每个节点的值为N UF(int N); // 在p和q之间建立连接 void union(int p, int q); // p所在分量的标识符 int find(int p); // 判断p和q是否在同一个分量中 boolean connected(int p, int q); // 拿到分量数 int count(); 基本思路就是把同一个分量内的节点的分量值都设置成一样的，这样在判断两个节点是否互通就可以通过比较两个节点的分量值来实现，所以每个节点都需要有一个存储位保存分量值，基础的数据就可以满足这种需求，数组的索引就是节点值，数组值表示分量值，比如id[1]=4，表示节点1的分量值是4，id[3]=9，表示节点3的分量值是9，这样1和3就不是互通的，因为节点值不同。
...</p></div><footer class=entry-footer>4 min</footer><a class=entry-link aria-label="post link to 1.union find" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/1union-find/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.zk原理</h2></header><div class=entry-content><p>一般用zk来干什么 分布式锁，用在分布式的业务系统 元数据管理 分布式协调，如果有人对zk的数据做变更，zk会反过来通知其他监听这个节点的人，数据变更了，通过这个可以实现Master选举HA高可用 封装了分布式架构中核心和主流的需求和功能。在分布式java业务系统用的比较少，最多就是分布式锁；开源的分布式系统比如Dubbo、HBase、Kafka、Canal都会大量使用zk；自研的分布式系统也会使用zk。
特点 他的数据模型是树形结构，纯内存保存，znode就是他的一个节点，跟文件系统类似，有层级关系，比如：/usr/local/uid，uid中可以写入一些数据的值，纯内存保证性能。
集群部署，高可用； 顺序一致性，所有写请求按顺序执行：集群中只有1台机器可以写，但是所有机器都可以读，zk收到请求的时候会给请求分配一个自增的zxid，leader会把数据放到queue里，follower去消费这个队列，通过这个保证有序； 原子性，所有机器上都执行成功才算成功； 数据一致性，因为有原子性，所以在那台机器上看到的数据都是一样的； 实时性，数据发生变更的时候其他客户端要很快就感知到； 角色 zk中有三种角色，leader，follower、observer
leader是通过选举选出来的，没有选举成功的节点就是follower，leader可读可写，follower只能读，如果follower收到了写请求，会把写请求转发给leader，如果把节点标记成observer，那么这个节点就不会参加选举也不会参与过半写的判断，但是还是可以处理读请求的。每个客户端和节点之间通信使用的是TCP长连接，每个长连接在zk中叫session，通过心跳维护会话状态，有一个关键参数叫sessionTimeout。
znode 持久节点：一直存在的节点，不管客户端还在不在，一般就是元数据存储。
临时节点：比如链接断开了，sessionTimeout时间内还没链接，这个节点就会被删除，分布式协调和通知之类的在用。
顺序节点：在创建节点的时候会增加一个全局自增的序号，一般zk的分布式锁都是使用临时顺序节点。
每个znode还有一个Stat用来存放数据版本，version（znode的版本），cversion（znode子节点的版本），aversion（znode的ACL权限控制版本）
watcher监听回调机制 基本上所有的功能都需要用这个机制来实现，通过这个机制来监听znode数据，当节点数据发生变化的时候会触发回调函数。
ZAB协议（zookeeper atomic broadcast zk原子广播协议） zk的架构就是一个读写分离的主从架构，通过ZAB协议保证数据的强一致，zk通过这个协议完成角色划分、数据同步、故障转移。
启动：
在集群启动的时候会进入恢复模式，然后开始选举，只要有一半的机器认可一台机器是leader，这台机器就被选举成leader，所以zk的集群允许不超过半数的机器宕机，比如说3台机器的集群，3的一半的1.5，只要有2台机器认可就可以选举出来，宕1台机器的时候，还剩两台，只要这两台机器都选同一台机器，就可以选举出来，如果只剩1台机器始终都是小于1.5的，没办法选举，选举的超过半数针对的是对于最开始的机器数，而不是剩余存活的机器数。然后leader会把数据同步到所有follower。
然后就会进入广播模式。
接收消息：
leader收到写请求后把请求转换为Proposal（提议）写到本地的磁盘里，然后在同步给所有follower，当follower收到了Proposal之后会先把Proposal写到磁盘的日志文件中，然后返回一个ack回去，如果超过了一半的follower都返回了ack，leader就会把Proposal写到内存中再给所有的follower发送commit消息，follower收到了commit消息再把这个Proposal的数据写到内存里。这是一种2PC（两阶段提交）机制的事务+过半写机制实现的数据一致。
zk不是强一致，也不属于最终一致，官方说的是顺序一致性的。这种机制就决定了zk节点不可能太多，如果太多了写是非常慢的，一般1主2从就差不多了，但是如果读请求很多可以通过observer减轻读的压力。
zk解决数据不一致问题 zk的这种同步机制会导致两种情况下数据不一致：
超过半数的follower返回ack，leader提交之后没有向follower发送commit或者值向部分follower发送了commit消息，这个时候leader宕机了，但是客户端会认为提交成功，这个时候重新选举，当follower发现自己本地有一条proposal是没提交的，但是其他follower已经提交了，那就把自己的也提交，如果发现都没提交，但是超过半数follower返回了ack，那就在发送一次commit消息。 如果leader还没发送proposal消息就宕机了，但是已经持久化到磁盘了，这个时候写入肯定是失败的，重新选举之后客户端会重新发送写入请求，然后旧leader重启变成follower，发现本地多了一条proposal，这条数据是需要丢弃的，他会拿到proposal的zxid，zxid的高32位是leader信息，低32位才是自增的id，如果他拿到高32位发现信息是自己，那么就知道了是宕机之前没处理完的消息，这条消息已经在别的leader上处理完了，然后就会删掉这条消息，最后去leader同步数据。</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 1.zk原理" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/zookeeper/1.%E5%8E%9F%E7%90%86/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.两数之和</h2></header><div class=entry-content><p>题目： 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值target的那两个整数，并返回它们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。你可以按任意顺序返回答案。
根据题目可以得到的结论：
不管存在多少解，找到一个就可以返回，这是一个剪枝条件； 数组中的每个元素只能使用一次； 下标返回可以无序，无序的结果对算法的限制更小； 首先想到的暴力算法有两种，一种是随机，一种是循环：
1：随机算法
随机算法就是随机取一个数，然后在随机取一个数，当两个数的索引不相等时判断两数之和，这个思路简单，关键就是要计算随机多少次
首先先看抛硬币的概率问题，当假设硬币只有正反两种结果的时候，连续抛出两次，最少有一次为正面的概率并不是100%，因为正面的概率是0.5，至少有一次为正面的概率并不是0.5+0.5，而是1-(1-0.5)^2^，意思是1-连续两次都是不好的结果的概率，所以当我随机取一个数的时候正确的概率是1/n，那么循环n(n是数组长度)次时，全部未命中的概率是(1-1/n)^n^，然后在带入e的极限公式得到： $$ (1-\frac 1 n)^n \ =(1+\frac 1 {-n})^n \ =[(1+\frac 1 {-n})^{-n}]^{-1} \ 因为e=(1+\frac 1 n)^n \ 所以，命中概率=e^{-1} \approx 1/3 $$ 所以至少命中一次的概率约等于2/3，也就是说遍历2n次至少会有一次命中，那么连续两次都命中需要遍历(2n)^2^次，代码如下，leecode已通过：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public int[] twoSumRandom(int[] nums, int target) { int[] ret = new int[2]; Random r = new Random(); int length = nums.length; int i,j; for (int count = 0; count &lt; Math.pow(2 * length, 2); count++) { i = r.nextInt(length); do { j = r.nextInt(length); } while (i == j); if (nums[i] + nums[j] == target) { return new int[]{i,j}; } } return ret; } 时间复杂度的话最外层就已经是(2n)^2^的了，然后里层还有一个while循环，但是可以忽略，复杂度的话就是n^2^
...</p></div><footer class=entry-footer>3 min</footer><a class=entry-link aria-label="post link to 1.两数之和" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/leecode/1.%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://wangxiaohong123.github.io/page/5/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://wangxiaohong123.github.io/page/7/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>