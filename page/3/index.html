<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.150.0"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>王小红的笔记</title><meta name=description content><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangxiaohong123.github.io/index.xml><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://wangxiaohong123.github.io/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="王小红的笔记"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="王小红的笔记"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"王小红的笔记","url":"https://wangxiaohong123.github.io/","description":"","logo":"https://wangxiaohong123.github.io/favicon.ico","sameAs":[]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>9.kafka源码-读取响应</h2></header><div class=entry-content><p>之前看到过producer的连接、发送、读取消息都是在Selector的poll方法中，跟进去之后看到读取消息在attemptRead()方法中：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 private void attemptRead(SelectionKey key, KafkaChannel channel) throws IOException { // 如果channel连接正常，并且关注了读事件或者有缓冲池中有消息可以读取 // hasStagedReceive(channel)，这个是一个暂存队列，没搞懂，可能防止重复读取 // explicitlyMutedChannels.contains(channel)这个会判断一个list中是否有这个channel，但是没看到插入的动作，所以这个判断一直是true if (channel.ready() && (key.isReadable() || channel.hasBytesBuffered()) && !hasStagedReceive(channel) && !explicitlyMutedChannels.contains(channel)) { NetworkReceive networkReceive; // 开始读取 while ((networkReceive = channel.read()) != null) { madeReadProgressLastPoll = true; // 往上面的暂存队列里插入这个channel // 在poll方法的最后一行会把channel从stage里移出 addToStagedReceives(channel, networkReceive); } if (channel.isMute()) { outOfMemory = true; //channel has muted itself due to memory pressure. } else { madeReadProgressLastPoll = true; } } } 进到kafkaChannel的read()方法里：
...</p></div><footer class=entry-footer><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;5 min</footer><a class=entry-link aria-label="post link to 9.kafka源码-读取响应" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/9.%E8%AF%BB%E5%8F%96%E5%93%8D%E5%BA%94/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>秒杀架构</h2></header><div class=entry-content><p>整体思路 前端页面 前端页面静态化：秒杀的商品变化的频率很低，基本上在设置成功后到秒杀结束不会发生改变，这是纯静态的页面，所以秒杀的页面或者数据可以存在nginx中，或者说在nginx中都会浪费带宽，可以放到CDN缓存中，当秒杀的商品发生变更的时候让CDN失效就可以了。同时CDN数量不能太多，太多失效的时间会变长，而且有些地区的用户数很少就没必要使用CDN了，只需要在用户数量较多的地方集中设置几个CDN就够用，可以提升整体的缓存命中率。 时钟同步问题：秒杀的倒计时需要和后台的时间同步，否则可能前端的时间到了但是服务器的还没开始，或者前端的时间到了，但是秒杀在上一秒已经开始了，可以搞一个时钟同步服务器， 所有和秒杀有关的服务器都需要和这台服务器保持时间同步，还要有一台单独的时钟授时系统，前端每分钟或者半分钟同步一下时间。 秒杀接口的隐藏：在秒杀开始之前，不应该把秒杀的url暴露出来，防止黄牛和黑客提前写好脚本，开始前1分钟由前端请求后台获取秒杀的url。 防刷单和限流：如果秒杀的瞬时QPS非常高或者有被刷单的风险可以引入行为验证这种商业验证码，腾讯、网易、极验这些都不错，就是小贵，但是这个验证码真是好东西，一般后台都需要进行二次验证，参与秒杀的都是注册用户，二次验证通过后可以和用户id进行绑定，当秒杀请求过来时判断是否通过过验证，当然行为验证的结果只能使用一次，而且放到nginx中就可以了，使用lua和验证三方交互和在redis中存放二次验证通过的用户。 负载均衡 LVS+keepalive架构+高带宽，单机抗下数十万并发。
是否需要网关：如果服务少的话，是不需要的，在nginx中配几个反向代理，前端多配置几个基础路径，但是大量的服务是需要网关，频繁的增减服务不可能每次都要重启nginx。
独立的二级域名：秒杀的服务的域名需要和正常业务分开，要不然容易影响正常业务。
防DDoS攻击：使用云厂商的DDoS高防产品，就是有点贵。
后台架构 nginx的限流方案：上线之前会进行全链路压测，然后根据也测结果调优之后需要在nginx中做整体的限流，滑动窗口、令牌桶、漏斗算法等，同时还需要一个业务限流，因为每个商品的秒杀数量都不相同，当商品秒杀库存为空的时候可以通知nginx，再有这个商品的秒杀请求直接返回商品被抢光啦。
商品超卖：商品的数量等信息都是放在redis中的，这样才可以抗下并发，超卖问题就是当一个线程扣减库存的时候，一个线程去查询，发现库存充足，还会继续走下单逻辑，这样会出现库存负数的情况。
最普通的解决方案就是分布式锁，可以解决问题，但是秒杀就变成串行得了，很慢； 还有一种方案是乐观锁（可以是redis 的watch机制），在更新库存的时候先去查询版本号，这样会变快，但是会产生很多空轮训，牺牲CPU； 一般大厂是把商品的数量分片放到redis集群中，然后把查询是否可以抢购+修改信息+返回结果封装到lua中，redis是可以保证lua的执行时原子的，这样上万的并发会被分到多台redis集群中的master节点上，每个节点就是执行几百上千个lua脚本，同时需要记录那个节点的库存为0，会转移到有库存的节点上； 网上一些课程说可以把商品信息放到redis的队列中，比如list，然后一个一个出队，这方案听起来就很怪，如果秒杀的商品有1000个，每个商品500个，需要全都放到redis中吗？ 黄金支付链路：秒杀系统在收到请求之后就要去redis集群中进行库存扣减，扣减成功之后发送消息到mq，这个时候需要有一个秒杀成功的下单服务，他需要使用线程池进行流控，为什么要流控呢，因为订单服务不只是在秒杀的时候才会用到，大部分的时间都是服务于正常业务的，服务可接受的tps是有上限的。订单系统就可以消费这条秒杀消息了，前端在支付时，调用三放支付平台，后台需要等待三方回调，如果超时没收到回调需要还原库存，修改订单状态是已超时。这些都不是秒杀系统该做的，电商平台自己的一套东西。
tomcat调优：
前端感知订单状态：前端在收到秒杀成功的响应后，就可以定时轮询秒杀状态服务，在订单创建成功后，秒杀状态服务感知到订单创建好了，就可以返回给前端，前端正常走支付流程。
秒杀成功的mq消息领丢失方案：
秒杀成功消息重复消费方案：
秒杀成功消息延迟问题：如果订单系统消费的很慢，此时mq的消息积压到了数十万条，这个时候如果还是慢慢消费，可能客户端要等10分钟或者更久才能刷出来这个订单，这样用户就会很疑惑，当消费的时候可以比较消息的发送时间和当前时间，如果超过了1分钟，那么就还原库存，然后把这个消息状态改成秒杀失败，让用户在抢一次，这样数十万的消息会变成几分钟，平均打过来。
redis+mq的一致性回滚方案：在秒杀的时候需要使用redis的事务+mq的事务消息，防止发送秒杀成功消息的时候失败了，库存还是扣减的。
高可用架构 正常服务只要保证多机器的冗余部署就可以保证基本的高可用了。
redis集群挂掉：如果集群全部挂掉了，秒杀也就不能正常进行了，这个时候可以把用户的秒杀行为以日志的形式存到本地磁盘里，然后返回给用户秒杀抢购中，等到redis回复了，在把磁盘的日志顺序读取出来执行一遍。 redis主从切换导致的超卖：这个其实发生的概率很低，如果真的要防止这种情况，可以去掉redis集群，不让他有主从切换的机会，使用twemproxy或者codis对多个redis做分布式存储，如果有一台宕机，还是写日志、等待修复。还有一个方案就是下订单的时候订单系统检查冻结的库存是不是负数，这个需要订单系统做一些操作，感觉不是太好。 与秒杀下单系统的直连降级：如果mq挂掉，消息一直发不出去，不能走之前的降级逻辑，因为这个时候返回秒杀失败，用户会一直点秒杀，一直失败，这个时候可以用抢购服务直连秒杀下单服务，控制好速度就行，就是以很慢的速度下单。 秒杀下单系统异常：这个时候可以进行重试，重试很多次也不行就需要进入死信队列。 多机房部署：</p></div><footer class=entry-footer><span title='2021-07-18 06:27:35 +0000 UTC'>July 18, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 秒杀架构" href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E7%A7%92%E6%9D%80/%E6%9E%B6%E6%9E%84%E5%92%8C%E6%80%9D%E8%B7%AF/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>LVS</h2></header><div class=entry-content><p>在我第一个压测的nginx是使用的4c8g的服务器+openresty搭建的nginx代理服务器，nginx使用4个worker绑核，返回的一段静态页面，发现在QPS达到2k后CPU都跑到了2000+，100M的带宽也被占满，开始以为想要接收高并发，nginx是第一个瓶颈，没想到是带宽，但是反过来推算4c8g的nginx也是扛不住200M的带宽的，所以要想抗住高并发，高带宽和高配置的nginx是必须的，但是配置再高也会有上限，还不如搞一个nginx集群，这样就可以无限的横向扩容了。
LVS（Linux Virtual Server）：Linux虚拟机服务器，就是一种负载均衡的技术，负载均衡的缩写是SLB（server load balance），它运行在linux内核层面，4c8g的服务器+LVS每秒处理几十万的请求不是问题，他是建立在4层网络协议基础上的，像nginx就是基于7层网络协议的负载均衡服务器。目前主流的负载均衡架构都是LVS+keepalive+nginx。
原理 首先当LVS收到客户端的报文（建立连接、断开连接、请求数据都是报文）之后，会在本地的hash表中查看是否有这个链接对应的后台服务器，如果没有就从后端的服务器地址中通过负载均衡算法拿到一台服务器，然后通过NAT（Network Address Translation，网络地址转换）技术把报文的请求地址换成后端服务器的地址，把请求发送到后端服务器，在hash表中记录这个链接对应的后端服务器，收到后台服务器的报文之后也会通过NAT技术把报文重新定位到客户端，在LVS中是没有HTTP协议这种说法的。
可以想一下，因为大部分的请求都是请求报文比响应报文小很多，如果响应也通过LVS的话会占用很多带宽，严重降低LVS的吞吐量，所以可以使用ip隧道把响应直接从nginx返回给客户端。</p></div><footer class=entry-footer><span title='2021-07-12 06:27:35 +0000 UTC'>July 12, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to LVS" href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E7%A7%92%E6%9D%80/lvs/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.敏捷开发</h2></header><div class=entry-content><p>传统的瀑布流就是产品经理定义了一个功能非常多，非常完善的产品，然后一堆后端、前端、UI等等进行排期开发，如果这些人包括产品对项目非常了解，每个人都有10年这种类似的产品的开发经验，闭关开发半年或者一年，产出一个成型的完善的产品其实是可能的，一旦对这个产品没有相关经验，开发周期变得很长就会出现一个问题，开发时发现产品的不完善，需要delay，测试时每天会出现几百个bug，需要delay，各种delay原来半年的项目可能变成了1年，还是有一堆bug。
敏捷开发就是解决传统瀑布流的问题，出现这种问题的原因是工期很长，不可控的因素太多，如果把目标该小并就可以稳定产出，说白了就是拆版本。敏捷开发定义了一套流程和规范，他是一种方法论。主流的框架就是scrum，这个是一种理论框架/方法框架。
不管是瀑布流还是敏捷开发都需要product backlog（产品功能列表），在国外是项目负责人维护，国内一般没有负责人这种说法，因为国内开发一个软件，一般都是从各个组里抽出几个人组成一个团队，没有真正的leader一说，一般是项目经理维护。
敏捷教练 如果想发挥出来敏捷开发的优势，可能需要配合TDD（测试驱动）、持续集成、持续交付、XP（极限编程）、结对编程等等。一般没玩过敏捷开发的公司可能最开始是玩不转的，有可能会玩崩，所以可以从外部的咨询公司，反正要找一个有经验的人过来指导，这个人就叫敏捷教练。
sprint 冲刺！一般在敏捷开发里，每个月或者几周会有一个大版本，比如每个月要更新一个新功能，前三周可能都是开发这个功能+修复一些bug，每周更新修复的bug，第四周上一个新功能，第四周就叫每个月的冲刺，每个月都叫一个版本冲刺。
sprint计划会议，就是在最开始产品拿出来需求文档和product backlog之后开评审会议，把backlog拆分成一个一个小版本，这个就叫sprint计划会议，每个冲刺任务还有自己的backlog，然后针对每次冲刺的backlog，预估工期（包括框架搭建、库表设计、coding耗时、单元测试耗时），QA并行的写测试用例，一般会把工期放到燃尽图中，并且时间要精确到小时。
站立会和测试驱动 站立会就是随便找个地方，然后每个人汇报一下昨天都干了什么，今天计划干什么，是否遇到了什么问题，有什么风险，应该如何处理，是否会导致预计之外的变化，是否有新的需求或者缺陷插入，对目前的计划是否有变动。
测试驱动要求每个发开都需要对开发的每个类的每个方法都需要有最少一个单元测试，有的方法可能需要不能的参数测试不同的边界需要很多个测试用例，还要有一个人专门写集成测试，就是用代码访问之前定义好的接口，查看流程是否可以走通。一般上了测试驱动开发任务最少会多一倍。
持续集成和持续交付 敏捷开发要求一天最少提交一次代码，提交代码之后会有一个类似jenkins的持续集成系统拉取代码，然后通过maven运行里面的单元测试，还有代码的覆盖率，一般要求覆盖率要达到95%以上，所有人都提交了代码之后就会跑一个集成测试的脚本看看controller的返回值是否都符合期望，然后通过持续交付把项目自动化打包、部署到测试环境里去。
第二天QA会运行写好的测试脚本进行测试，然后把bug提到jira这种缺陷管理系统里去，然后第三天站立会的时候要说明昨天提的bug今天能否修复，是否需要延期。
sprint验收 开发+测试+修复bug并行进行可以减少长期项目的不确定性，最终交付一个sprint版本到测试环境，由产品经理验收，如果发现需要改进的地方可以提到下一个sprint中去，然后会开一个会议，包括客户、产品、所有开发进行sprint交付，然后再开一个回顾会议，讨论这次sprint有没有需要改进的地方。
三大角色 产品负责人：就是产品经理，上跟领导对接，中跟用户对接，下跟开发对接，负责定义产品的sprint和backlog，编写原型图、需求文档（PRD）。
项目负责人：或者是敏捷教练，scrumMaster，一般就是高P，这个可以选出来，也可以直接由高层指定，hold场子的。
团队成员：前端，web，后端，UI什么的。
user story 用户故事就是面向用户或者其他系统或者后台的一个功能，可以理解成一个完整的系统功能。每个冲刺包含一些user story，每个user story可以包含一些backlog。
开发流程 开始之前需要确定一批技术专家，针对项目里用到的技术，防止开发或者线上突然出现源码或者原理级的bug，比如消息丢失，需要有一些这样的人到时候能够指导或者解决，可以是本团队，或者其他团队，或者中间件团队或者别的公司的朋友，或者花钱。
还需要确定项目负责人需不需要写代码？
项目负责人每天需要通过站立会盯进度、检查和验收代码，覆盖率是否达标、bug是否达标、预发布环境里的压测、可用性、监控等是否达标，做完了这些基本上没啥时间写代码了，基本上项目负责人80%的时间都是做这个，20%的时间可以写代码，或者做架构设计、方案设计、流程规范设计。
开发之前所有人会进行需求评审，进行sprint拆分，一般可以拆成1周到一个月，如果产品只确定的大功能，很多细节模糊不清，这个时候最好是1周一个冲刺，方便调整和改动。 确定本次冲刺的需求之后项目负责人需要制定技术层面的sprint和backlog，比如，开发功能、开发测试用例、code review、继承测试、完善文档、完善监控项、stating环境压测等等。 测试驱动开发， 自动化集成测试， QA环境进行功能测试、性能测试、可用性测试。 自动交付到staging环境，进行压测。 没有结对编程，人走了代码就没人接手了，通过结对编程+code review提高代码质量，不怕有人走代码没人接手。
概念的关系：
一般一个发布计划就是一个版本，一个发布计划对应多个sprint，一个sprint包含多个用户故事，一个用户故事包含多个backlog。
每个print结束之后都要有一个总结会，每个人都可以提意见，比如说单侧不标准之类的，这个东西是越来越完善的。</p></div><footer class=entry-footer><span title='2021-06-24 06:27:35 +0000 UTC'>June 24, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 1.敏捷开发" href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/ddd/1.%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>3.DDD框架之cola</h2></header><div class=entry-content><p>COLA是一个应用架构，作者对应用架构的解释是处理模块（Module）、组件（Component）、包（Package）和类（Class）之间的关系，让系统有章法，有结构。提倡以业务为核心，解耦外部依赖，分离业务复杂度和技术复杂度。
COLA架构 适配层（Adapter Layer）：负责对前端展示（web，wireless，wap）的路由和适配，相当于MVC中的controller，主要用来解释用户指令； 应用层（Application Layer）：主要负责获取输入，组装上下文，参数校验，调用领域层做业务处理，如果需要的话，发送消息通知等，其实就是对业务编排。层次是开放的，应用层也可以绕过领域层，直接访问基础实施层； 领域层（Domain Layer）：主要是封装了核心业务逻辑，并通过领域服务（Domain Service）和领域对象（Domain Entity）的方法对App层提供业务实体和业务逻辑计算。领域是应用的核心，不依赖任何其他层次； 基础实施层（Infrastructrue Layer）：主要负责技术细节问题的处理，比如数据库的CRUD、搜索引擎、文件系统、分布式服务的RPC等。此外，领域防腐的重任也落在这里，外部依赖需要通过gateway的转义处理，才能被上面的App层和Domain层使用。 可以看出来COLA和DDD的分层是一模一样的，只不过对于一些组件比如防腐层什么的所在的层级做了一些改动，这三种架构的普适性都是针对前端需求的变和领域模型的不变。
COLA的包结构 Adapter层 mobile：文档上写的是wireless，但是生成的代码里叫mobile，就是app端对应的controller接口； web：电脑端页面对应的controller； wap：移动端页面对应的controller； App层 executor：处理request，包括command和query； consumer：处理外部message，就是对应的事件消费者； scheduler：处理定时任务； Domain层 model：领域模型，就是实体、聚合这些东西； ability：领域能力，就是领域服务； gateway：领域网关， Infra层 gatewayimpl：网关实现； mapper：ibatis数据库映射； config：配置信息； Client层 api：服务对外暴露的api接口； dto：服务对外的DTO； Start层 里面只有服务的配置和启动类；
其实不管我们用不用DDD的模型设计都可以用这一套包架构，只不过就是model里有没有东西的事儿。
对于领域层和基础层的gateway包说明： 这里的gateway并不是微服务的网关，而是代表DDD中的防腐层或者仓储，操作数据库时，通过仓储+po和实体的转换实现解耦，rpc调用其他服务或者三方的时候通过防腐层进行实体转换，给我的感觉都是一样的，只要有依赖就有耦合，这几个做法都是为了降低耦合的可接受成都，主要的思想也都是一样的。cola中的gatewayImpl就是他的防腐层，他把数据库、es这些也定义成了外部依赖，这样做不管是应用层还是领域层都可以调用三方服务了。
基于DDD+cola改造开发 分析方法 DDD的分析方法有三种，事件风暴、领域故事陈述和4色建模：
事件风暴：类似于大家在一起的头脑风暴，每个人针对业务都想说什么说什么，然后有一个人专门根据大家的发言提炼出业务流、事件和命令，然后在根据事件的语义划分出实体、聚合、子域以及限界上下文。 领域故事陈述：梳理出每个业务的流程图 COLA相关修改 COLA中每一层就是一个模块，每一个子域对应一个工程，这样对人少的团队会增加维护成本，我们还是一个项目对应一个工程对应多个子域，每个子域只有两个服务，业务服务和api服务，api专门堆外暴露接口，其他层使用包的方式存在业务服务中。 在COLA中client层除了对外的接口和dto还有命令和事件，我们把client层去掉后，把命令放到了app层，事件放到了领域层，事件的处理(publisher、subscriber)也在app层，还有一种方式是对于事件的publisher组件放到了gateway中，这么做是考虑下层不应该调用上层，publisher组件放到了gateway中方便在domain层调用。 COLA的应用服务接口也放到了Client层，我觉得没必要，也没必要设计成依赖倒置的，所以我们直接在app层创建一个应用服务用来编排命令，app的executor包下有cmd和qry的包对应查询和命令的处理逻辑。 COLA中并没有出现工厂的概念，我们需要，也放在app层，同时infra层需要convertor实现实体和其他dto或者do转换。</p></div><footer class=entry-footer><span title='2021-06-24 06:27:35 +0000 UTC'>June 24, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 3.DDD框架之cola" href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/ddd/4.cola/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>5.底层原理</h2></header><div class=entry-content><p>HLog 每个HRegionServer都有一个HLog，也可以配置多个，所有region共享这个HLog，每次操作数据都会产生一个log，很像MySQL的redoLog，这条log的key就是表名+region名+写入时间+sequenceid+clusterid，内容就是对那个列改了什么value。
在hdfs上有两个专门的目录存放HLog："/hbase/WALs"和"/hbase/oldWALs"，WALs里存放的是还没过期的数据，就说还在memStore里，没有刷到hdfs中的，在这个目录下面对于每个HRegionServer都有一个自己的目录，类似这样：
/hbase/WALs/hbase12.df.zszs.org,60020,1304970381600
hbase12.df.zszs.org是HRegionServer的机器域名，60020是统一的端口号，最后面试创建的时间戳，在HRegionServer文件夹里就是一堆HLog文件了。有多个HLog文件是为了方便删除，因为大部分的数据都会刷到hdfs中，已经落盘的数据对应的HLog就没有存在的必要了。
什么时候创建一个新的HWAL日志文件呢？通过配置hbase.regionserver.logroll.period，这个默认是1小时，每个小时HBase后台的一个线程就会去创建一个新的日志文件。当数据被持久化到了hdfs中后，对应的日志文件就会被放到oldWALs中，然后HBase的后台还有一个线程根据参数hbase.master.cleaner.interval(默认1分钟)来检查文件在oldWALs文件夹里待的时间超过了hbase.master.logcleaner.ttl(默认10分钟)，就会把这个日志删掉了。为什么还要再等10分钟呢？据说是主要用于调试。
memStore的写入 memStore使用的是双跳表机制来实现key的有序性，直接使用的java的ConcurrentSkipListMap，把rowkey+列族+列+timestamp当做跳表的key，当一个跳表满了的时候新进来的数据都会写入到另一个跳表中，这个跳表的数据慢慢刷到hdfs里，数据的value存储在chunk数组里。
HFile 逻辑组成 HFile逻辑上包含4部分：
Scanned block：Data Block（key-value数据），Leaf Index Block（索引树的叶子节点），Bloom Block（布隆过滤器）； Non-scanned Block：Meta Block、Intermediate Level Data Index Blocks； Load-on-open Block：这部分会在RegionServer打开HFile的时候直接加载到内存里去，包括FileInfo、布隆过滤器的MetaBlock、Root Index Block和Meta IndexBlock（在查找元素的时候都要从根节点开始）、Bloom Index Block（这个是布隆过滤器的索引，因为一个HFile可能会有很多布隆过滤器）； Trailer Block：HFile版本和其他几个部分的偏移量以及寻址信息，寻址信息就包括Load-on-open Block的地址； 当HRegionServer打开HFile的时候会先读取文件的信息，这个时候就知道了文件有多少字节，然后就可以从末尾把Trailer Block读取出来，Trailer中有Load-on-open Block的位置信息，就可以把Load-on-open Block读取到内存中。
查询 当从HFile里查找文件的时候，会现根据Load-on-open Block中的布隆过滤器索引拿到所有的过滤器，然后判断要查找的数据是否在这个文件中，如果在就根据LSM树来查找数据，也就是根据Scanned block中的Leaf Index Block最终拿到Data Block，data block中就是一个一个的key-vakue对，key由rowkey、列族、列、操作时间戳、keyType（keyType就是Put、Delete、DeleteColumn、DeleteFamily这些）组成。
LSM树和MySQL的聚簇索引差不多，当数据量少的时候只有一层，Load-on-open Block直接指向Data Block，当数据量变多后，会出现叶子节点，再多就会出现Non-scanned Block的Intermediate Level Data Index Blocks。
不管是get还是scan，底层都是scan，在查询时，首先会有3层scan（RegionScanner、StoreScanner、MemStoreScanner和StoreFileScanner），第一层先找到对应的region，第二层找到store，第三层在memStore找到具体的数据和通过布隆找对具体的HFile。
找到数据之后会在内存中进行合并筛选。
block cache 因为每次查找数据会涉及到几次磁盘IO，读取intermediate level index block发生一次IO，读取leaf index block发生一次IO，读取data block发生一次IO，最多就3次IO，但是如果是批量get并且只有每次只有3个IO，查询速度也会达到秒级，所以hbase有一个和MySQL的缓冲池类似的东西，block cache，它是以我们存储数据的block为单位存储，其实就是3个ConcurrentHashMap，map的key就是block的key，value可能就是一个地址的指向：
single-access：数据刚被读取的时候会在这个map里 multi-access：当数据被第二次使用的时候会从single-access移动到multi-access里 in-memory：比如在创建列族的时候指定了n_memory=true，这个列族的block就会存在在这个map中 这3个map都是LRU map，内存占用比是25%:50%:25%。
...</p></div><footer class=entry-footer><span title='2021-06-24 06:27:35 +0000 UTC'>June 24, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 5.底层原理" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/hbase/05%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>DDD-2.入门</h2></header><div class=entry-content><p>DDD是一套软件/系统的设计思想，目前没有一套完整的方法论。他建议用现实的场景映射我们的代码设计，传统的MVC主要是快，但是代码会全部堆积在service层，在拿到需求后，开始建库表，然后所有的代码都是面向数据库的，这样service的代码会越来越多，并且在面对复杂业务会很无力，DDD就是为了解决复杂场景下的代码设计。但是目前使用DDD做代码设计的非常少，因为资料少，实践困难，如果是一个微型团队，每个人负责几个子系统，每个人都需要定义自己子系统的通用语言，这样沟通很容易产生误会，最好是一个二三十人的团队，负责十几个系统，每个小团队负责一个系统（一个系统里可能包含很多服务），这样小团队之间用自己的自定语言，项目leader先划分好领域，然后建模，每个团队的leader在把自己的系统建模，这样才可以。
为什么要用DDD？ 首先DDD的思想是面向对象的，更接近真实场景，其次在复杂系统的设计上DDD更优于传统三层架构，但如果三层架构把服务拆的足够微，我不觉得他比DDD弱，其实现在的DDD和十几年前的三层架构一样，当时三层架构刚刚开始流行，大部分公司没有接触过，就感觉很厉害，很难，几年之后，三层架构变成标配，在这种分层的思想已经固化的时候，出来了一个DDD，思想和三层架构有些差别，使用的少或者没使用就会感觉DDD很深奥，可能再过几年DDD普及之后就和现在的MVC一样了。DDD的价值是让开发和产品对业务有相同的理解，DDD的流程差不多是这样：
需求评审->和产品、运营、用户定义通用语言->业务建模->架构设计(业务架构+技术架构)->团队成员开始建模(实体、值对象、互动的流程)->搭建工程、定义接口、代码落地(根据通用语言)
可以看到和产品的沟通变多了，和产品一起定义的名词和业务挂钩，沟通无障碍，新人在看完需求文档，在看代码也很轻松。
其实传统的service+controller+dao+domain除了开发快，还有一个优点，就是门槛低，随便一个培训出来的人都能开发。但是DDD更适合大型的复杂的业务系统，而且他更贴合显示，业务模型和业务代码特别清晰，代码非常好看，如果一直维护面向数据库的代码肯定会越来乱。
如果一个大团队没搞DDD，小团队自己能不能搞？能，只要把只要把团队负责的几个系统定义一套通用语言就可以，小团队不搞，自己负责的几个服务能不能搞？能，自己负责的每个服务都是一个子域，使用一个通用语言也可以。
基础概念 1.限界上下文 他是一个独立的业务领域，可以是一个或多个子域，一般就是一个子域，也建议这么划分，建议每个限界上下文最好是一个独立的子系统，拥有独立的git仓库，独立的数据仓库，独立的测试环境，独立的团队。
2.通用语言 针对同一限界上下文需要定义一套自己的名词，比如同样的orderNumber，在订单域里是充值、消费的订单号，在匹配域里，是发起一次群聊请求的订单号/房间号。
3.子域（domain） 其实说的就是限界上下文，主要有3种子域，一般一个子域最好对应唯一一个限界上下文。
核心域：核心业务系统，比如订单、钱包、动态。
支撑子域：非核心系统，但是有了锦上添花或者是辅助性的系统，比如BI系统、爬虫系统、社会化治理系统。
通用子域：一般具有普适性，全公司都可以用的类似OA系统、权限系统这种。
一个子域可以拆分成多个module，一般一个子域也是一个独立运行的大系统。
4.module 一般一个module就是一个服务。
5.上下文映射 就是子域进行集成，就是不同系统之间的接口调用，因为不同的系统可能会有通用语言的冲突，就需要在接口调用的时候把冲突的单词映射成另一个。
上下文映射的种类，U-D就是调用链的上下游，下游调用，上游提供，箭头是由上游指向下游，表示数据的流向：
合作关系（Partnership）：两个上下文强耦合在一起，多个服务完成一整个业务，一般都是一起需求评审，一起开发，一起上线。这种关系需求变更对应的服务也要改动。 共享内核（Shared Kernel）：两个系统共同维护一些模型，比如A系统的API里的一些类是B系统认可的，或者一个单独的公共的模块，他们共用并且共同维护这些实体，很少见。 客户方-供应方（Customer-Supplier Development）：就是系统B根据系统A的需求定制接口，返回值还是系统A（客户方说的算），一般都是和合作关系配合用，你需要接口，人家没有就一起商量一下。 发布订阅（Publish-Subscribe）：比如那种发mq消息的。 尊奉着/没商量（Conformist）：系统A调用系统B，但是A说得不算，B只暴露一些接口，你要是用就调一下，你想要修改人家也不配合你，一般就是中间件部门写的接口，或者其他独立的系统。 开放主机服务OHS（Open Host Service）和发布语言PL（Published Language）：相当于是开放的API了，一般指三方或者公司自己的平台，比如云片短信，定义一种协议，一般都是http。基于消息机制也是发布语言的实现方式。 防腐层ACL（Anticorruption Layer）：为了防止系统B接口改动频繁，把调用系统B的代码抽离出来，以后系统B再次改动，这需要改防腐层的代码即可，一般和尊奉着/开放主机服务一起使用。 大泥球（Big Ball of Mud）：上下文没有关系，各行其道，混乱的组织在一起，一般说得就是本该拆成几个子域，结果混在了一个服务里。 独立路线/隔离模式（SeparateWay）：没关系。 6.实体和值对象 实体：先理解成传统MVC的domain下的实体，但其实远不止，实体是有状态和行为的，也就是说实体的变量是可变的。 值对象：就是实体中包含的数据，比如订单中的值对象可以有订单详情，代表的是封装了一份数据，最经典的例子，前端返回的实体一般起名都以VO结尾，VO就是value object的缩写，翻译过来就是值对象，比如返回给前端的订单信息中有OrderInfo、OrderItem、Product、PurchaseCart。其实实体和值对象的区别可以理解成实体有id，值对象没有id。标准的DDD中规定值对象只能替换，不能修改。 聚合（Aggregate）：多个实体或者值对象的组合关系，一个订单实体中有多个订单明细实体，他们就是聚合关系，他可以看成是特殊的实体。 根实体：每个聚合关系里都有一个根实体，在订单里，大订单就是跟实体，也叫聚合根。 事务：说的是聚合实体的事务关系，比如说一起更新，要保证事务更新了这个聚合实体的整体或者部分的时候，实体内的数据是一致的。 聚合关系应尽量通过实体id引用，不要通过面向对象的引用，尽可能保证小型，主要就是通过事务规则，符合事务原则的实体，可以设计成聚合关系。
7.资源库(repository) 负责对实体对象进行持久化。
8.应用服务 负责对业务流程的编排，对应service接口。
9.领域服务 实体/值对象/资源库/工厂/聚合不适合放在里面的复杂性为的补充。里面的行为就是指挥多个实体/值对象完成业务逻辑。
10.领域事件 系统交互的核心事件，比如支付订单事件，一般用过去式命名。
11.业务组件 对领域事件的发布和处理。
12.用户界面 对应controller接口。
13.基础设施 MySQL、es、redis什么的，业务组件、领域服务、实体、资源库都可以用，根据业务决定。
14.命令 command和查询query 用来驱动领域服务的业务逻辑核方法的执行，一般就是人通过web或者app这种UI界面发起的指令，是从CQRS架构里延伸出来的，牵扯到了下面的类DDD和泛DDD。
15.战略设计/战略建模/领域对象建模 对子域划分、上下文映射、子域集成、实体、值对象和领域服务建模，完全没必要说得这么高大上，其实就是业务建模。一般一块业务就对应一个领域，一个领域又可以拆成多个子域，拆分域还是很容易的。
业务领域 -> 各个子域（module） -> 自己子域的通用语言（你应该跟子域里的其他人一起合作） -> 上下文映射（上下游关系）
...</p></div><footer class=entry-footer><span title='2021-06-24 06:27:35 +0000 UTC'>June 24, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to DDD-2.入门" href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/ddd/2.ddd/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>DDD-3.DDD的分层架构</h2></header><div class=entry-content><p>目前没有一套完整的DDD方法论，他仅仅提供了一些思想，所以每个公司可能都有自己的DDD目录结构，一般都是用到他的概念和分层，有的简单业务甚至只用到他的分层。
推进DDD是很难的，第1花时间还没有产出，第2就是没有完整的方法论，包结构数据怎么流转等等都没有统一的规定。而且完全按照DDD的规范来开发不适合互联网，DDD讲究的是把聚合、值对象这些东西分的很细还有对以后扩展的预留，完全用这个会把开发周期拖长，对业务不熟或者赶工的时候非常容易走样。
一些普适性架构 清洁架构 也叫洋葱架构，因为分层的图画出来很像洋葱：
越里层，越是核心能力，并且外圆只能依赖内圆，基础资源除外，或者说最外层除外。在DDD中4层架构的功能边界如下：
传统4层架构的调用方式看起来像下面这样：
就很怪，为什么接口可以直接调用基础层，数据库什么的都在这里？？？
六边形架构 也叫端口适配器架构，红框内是核心逻辑，核心逻辑不变采用适配器适配不同端，同理和基础架构的交互也是使用了依赖倒置，置于为什么叫6边型，是为了形容一套逻辑可以适配多个端口。
四层架构里的接口层虽然有web界面这些东西，但是他定义的不是传统3层架构的controller，6变形架构就是为了解决这个问题，并且他把基础设施也定义成了api的方式提供其他层调用。</p></div><footer class=entry-footer><span title='2021-06-24 06:27:35 +0000 UTC'>June 24, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to DDD-3.DDD的分层架构" href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/ddd/3.ddd%E7%9A%84%E5%88%86%E5%B1%82/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>云原生-1.概念</h2></header><div class=entry-content><p>云平台：可以说的是一些云上的开箱即用的产品，比说阿里云(SaaS/PaaS)。目前的趋势是基础设施产品化，云平台产品化，变成了基础设置即代码，平台即服务(IAC)。
云原生技术：支撑微服务架构的基础设施架构
云原生利用云原生技术让开发人员充分利用云平台的平台化能力和弹性资源能力，他把一些非业务行的代码和基础设施下沉到了云平台。 云原生是包括了微服务的。
云原生涉及到的技术： 一个新应用的特点应该包括：弹性收缩、可监控、高可用和容灾、可管理(具备版本机制，配置管理等)、灰度发布(机器分组、地域等维度)、微服务+容器、灵活选择语言、DevOps、认证和授权。
主流的云原生技术栈如下：
举个例子，开发出一个新应用应该具备的技术：
架构层面：微服务，解决应用高耦合和臃肿问题； 服务层面：Docker+Kubernetes，解决微服务环境统一和部署问题，Istio Mesh解决线上服务治理，ServerLess(Knative)自动收缩和冷启动； 项目交付：DecOps，持续集成和交付； 数据库存储：TiDB、ClickHouse、Redis等分布式关系/非关系型数据库； 云原生架构的7大原则 服务化原则：按业务边界将系统拆分成分布式应用，让业务之间不共享数据+提高扩展性； 弹性原则：系统部署可以随着业务量变化自动调整大小； 可观察原则：链路追踪； 韧性原则：说的是高可用，面向失败设计，考虑各种基础设施、其他服务异常导致的失败的处理方式； 所有过程自动化原则： 零信任原则： 架构持续演进原则：持续演进架构，但是要保证业务的平衡；</p></div><footer class=entry-footer><span title='2021-06-24 06:27:35 +0000 UTC'>June 24, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 云原生-1.概念" href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E4%BA%91%E5%8E%9F%E7%94%9F/1.%E6%A6%82%E5%BF%B5/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>云原生-2.容器理论</h2></header><div class=entry-content><p>为什么要用容器 简化环境部署:比如要安装一个管理系统可能需要安装MySQL、php、nginx，修改系统的DB配置；使用docker只需要配置docker-compose文件即可，这样还能保证多个服务的环境一致性。 持续集成：快速的镜像构建和部署，支持通过镜像回滚。
Docker是基于go语言开发的开源容器项目，他的构想是对应用的封装、分发、部署、运行生命周期进行管理，一次构建，到处运行。
1.安装 docker安装分成2部分，docker和docker compose。
Docker官方文档，没啥坑。
docker compose是用python开发客户端，所以需要安装python以及python-pip。
mac的话到python官网下载最新的pkg文件，他自动配置环境变量，装完执行命令查看安装结果：
1 python --version 重新打开终端后安装python-pip
1 2 curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py python3 get-pip.py 使用pip安装docker-compose：
1 pip install docker-compose 装完之后查看doccker-compose版本检查是否安装成功：
1 docker-compose -v 2.概念 2.1 镜像 docker的镜像可以是传统的操作系统镜像，也可以是应用级的镜像(比如开发的某一个服务的镜像)，镜像就是停止运行的容器，内部就是一个精简的操作系统+应用运行需要的文件和依赖。
镜像有很多层，每个层都是只读的，但是所有镜像层都起始于一个基础镜像层， 然后每次安装新环境
2.2 容器 容器是启动之后的镜像，一个镜像可以启动多个容器，每个容器相互独立。
2.2.1 容器生命周期 2.3 仓库 仓库是存放镜像的地方，分为公共仓库和私有仓库。存放仓库的地方叫注册服务器。
docker运行中使用的默认仓库是Docker Hub公共仓库。如果想要使用自己的私有仓库需要执行命令登录：
1 docker login 使用docker push 把test/nginx镜像推送到远程仓库：
...</p></div><footer class=entry-footer><span title='2021-06-24 06:27:35 +0000 UTC'>June 24, 2021</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 云原生-2.容器理论" href=https://wangxiaohong123.github.io/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E4%BA%91%E5%8E%9F%E7%94%9F/2.%E5%AE%B9%E5%99%A8%E7%90%86%E8%AE%BA/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://wangxiaohong123.github.io/page/2/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://wangxiaohong123.github.io/page/4/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>