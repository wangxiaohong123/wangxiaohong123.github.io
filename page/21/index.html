<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.150.0"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>王小红的笔记</title><meta name=description content><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangxiaohong123.github.io/index.xml><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://wangxiaohong123.github.io/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="王小红的笔记"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="王小红的笔记"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"王小红的笔记","url":"https://wangxiaohong123.github.io/","description":"","logo":"https://wangxiaohong123.github.io/favicon.ico","sameAs":[]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>MySQL-4.数据的物理模型</h2></header><div class=entry-content><p>一 表空间 表空间是用来存储表的结构和数据的，InnoDB中表空间分为以下几种：
系统表空间：system tablespace，也叫共享表空间，对应的物理文件是var/lib/mysql/ibdata，这个表空间存了很多东西会越来越大。
系统表空间内容：
数据字典：表结构、数据库名、表名、试图、索引等等元数据 change buffer doubleWrite buffer files：双写缓冲区，为了解决写失效问题，因为操作系统的os cache每页只有4k，默认情况下一个缓存页有16k，所以要把一个缓存页刷新到os cache后再刷到磁盘，需要再os cache中刷4次，如果刷到一半服务器挂了，这个时候这个数据页就是不完整的，这就是写丢失问题。为了解决这种极端情况，在把刷剧刷到磁盘之前innodb会把数据复制到一个2M的内存中，通过这个2M的内存向共享表空间的doubleWrite buffer顺序写，如果doubleWrite buffer顺序写成功，在进行正常的数据页刷新，如果写双写缓冲区的时候失败，其实就算刷盘失败了，但是不会产生坏掉的数据页，如果刷数据页失败在重启之后会使用双写缓冲区的数据页来恢复。 undo logs 独立表空间：file-per-table tablespaces，默认情况下表的数据文件存在独立表空间中，每个库都有自己对应的文件夹，独立表空间是在var/lib/mysql/库名/表名.idb文件，这个文件不能拆分，所以数据越大文件越大，表结构的信息除了存储到系统表空间之外也会在表空间统计的.frm文件中，8.0之后所有的表结构信息都在系统表空间中。
通用表空间：MySQL5.7之后支持，类似系统表空间，可以创建表的时候把表空间指定到通用表空间。
撤销表空间：undo tablespaces，用来保存undo log的，undo log默认存在系统表空间里，也就是存在ibdata文件中，5.7之后可以通过undo_log_truncate+innodb_undo_tablespaces参数设置让undo log保存到对应的撤销表空间。这样可以解决系统表空间越来越大的问题。8.0之后默认会把undo log放到撤销表空间里。
临时表空间：temporary tabespaces，5.7之后独立出来的，之前也在系统表空间里，存储的是临时表数据，对应的文件是MySQL数据文件夹里的ibtmpl文件，初始16M，也是自动扩容的，会越来越大，当内存里的临时表空间满了的时候会刷新到磁盘里，可以设置临时表空间的大小，重启时ibtmpl里的内容会被释放。
1）表空间的逻辑结构 一个表空间包括多个段(segement)，每个段包括多个区(extent)，每个区有多个页(page)，每个也有多条数据(row)。 表空间：相当于innodb存储引擎存储的最高层，用来存储多个idb文件，每个idb文件都是独立的表空间。 段：他是一个逻辑概念，用来申请空间和回收，一个段有256个区，常见的段有数据段、索引段、回滚段等等。 区：由连续的页组成的空间，一个区有64个页，默认情况下一个页16k，所以一个区就是1M。 页：存储多个连续row，常见的页类型有数据页、undo页、索引页等等。
2）page结构 innoDB的数据都是以页为单位存储的，每个数据页都有一个38字节的file header(描述信息) + 56字节的page header(存储页状态) + infimum + supermum records(26字节的最大最小行记录) + user records(存储的数据行记录) + free space(空闲空间大小) + page directory(页目录，存储数据记录的偏移量) + file trailer(8字节文件尾，用来校验页的完整性)。
file header中有上一页信息，file trailer有下一页的信息，这样数据页之间就组成了一个双向链表。
3）行数据结构 行格式有4种，可以在建表的时候指定row_format或者alter table修改，5.7之后默认使用dynamic。
数据库中有些类型的数据是不固定长度的，比如varchar(20)，但是你可能只存1个‘a’，所以需要一个标记来记录不定长的字段中的数据长度，标记使用的是16进制，还要有记录列名、类型的信息，然后你还有可以为null的列，需要记录可以为空的列到底有没有数据，compact格式的行数据大概是这个样子的：
1 2 3 4 5 # 前两个16进制存储的是地址1的长度、姓名1的长度（逆序存储） # 中间的8位bit数就是null值列表，存储的是可以为null的列 # 只要某一列可以为空就要在null值列表中有一个占位，当列为空时存0，不为空时存1 # null值列表一定是8的整数倍，不足时在头部补0，也是逆序存储 0x03 0x03 00000101 头字段 姓名1 地址1 40位的头字段详细信息：
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to MySQL-4.数据的物理模型" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/4.innodb%E7%9A%84%E7%A3%81%E7%9B%98%E7%BB%93%E6%9E%84/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>MySQL-5.三个log</h2></header><div class=entry-content><p>redo log WAL机制：预写日志机制，这是一种日志先行机制，意思是刷新数据的时候，先把数据对应的log刷新到磁盘上的对应的log file中，然后再根据log file刷新数据。针对redo log的WAL机制就是先将内存中的redo log buffer刷新到磁盘上的redo log file里，然后再根据redo log file刷新磁盘上的数据。这样有个好处是如果直接修改磁盘数据是随机写，但是WAL的话会顺序写日志，然后异步随机写。
1）基本概念 redo log叫重做日志，它包括两部分，一部分是内存中的redo log buffer，另一部分是磁盘上的redo log file。通过redo log可以实现数据的持久型。
2）数据刷盘 脏页落盘的chack point：
强制落盘：关闭数据库的时候把所有脏页落盘； 主线程定时将脏页写入磁盘； 当redo log快写满的时候：redo log在75%到90%之间会异步落盘，超过90%会同步落盘； lru链表中有脏页被淘汰的脏页会落盘； buffer pool中的脏页超过75%会落盘； 3）redo log刷盘策略 redo log持久化策略通过innodb_flush_log_at_trx_commit来配置，这个属性有3个选项，分别是0、1、2：
为0时：redo log buffer每秒会写入到os cache，并调用fsync操作进行刷盘，设置成0的话当系统崩溃的时候可能会丢失1s的数据。 为1时：事务提交时会直接写入os cache并调用fsync操作刷到磁盘，这种不会丢失数据，但是磁盘io会很频繁。 为2时：事务提交时会写入os cache，由后台线程每秒执行fsync操作，这种只要不是服务器宕机就不会丢失数据。 4）日志格式 redo log记录的是哪个数据页的哪个位置上的数据被修改，修改为多少。
type space id page number offset len data 日志类型 表空间的id 数据页号 数据页中的偏移量 修改的内容不确定长度时占用的字节数 redo log的具体内容 日志类型有很多种，在5.7里有五十多种，比如type=1的时候是MLOG_1BYTE，意思是某个偏移量处写入了1字节的数据，type=30的时候是MYLOG_WRITE_STRING，表示修改了字符串的值，这种不确定长度的值的修改会使用len进行标记。
5）刷盘时机 首先在MySQL关闭的时候是必须要刷盘的； 其次MySQL在后台有一个线程会每秒刷一次； 然后如果1s内产生的redo log超过了redo log buf的一半大小会马上进行刷盘； 最后事务提交的时候会进行刷盘； 默认情况下磁盘中的redo log只有两个文件，ib_logfile0和ib_logfile1，写满了就会覆盖。这两个文件组成了一个日志组。组里的日志文件组成立一个环，比如ib_logfile0写满了会去写ib_logfile1，ib_logfile1写满了之后又会去写ib_logfile0。其中write pos表示当前日志记录到的位置，check point表示将日志记录写进磁盘，然后会将日志擦除，write pos和check point是追逐关系，当write pos追上check point的时候不能写继续写redo log。
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to MySQL-5.三个log" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/5.%E4%B8%89%E4%B8%AAlog/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>MySQL-6.事务</h2></header><div class=entry-content><p>一）事务的4个特性 原子性：同一个事物内的SQL要么都成功要么都失败，innodb中使用undo log保证数据的回滚，在事务执行过程中如果宕机的话没有提交的事务不会被恢复，因为redo log中的日志是uncommit的。 一致性：原子性+隔离性+持久性是为一致性服务的，一致性说的是事务开始之前到结束不会破坏数据库的完整性，可以理解为其他3个特性加在一起就是一致性。一致性分为约束一致性和数据一致性： 约束一致性：针对表结构的外键、唯一索引等约束； 数据一致性：由原子性+隔离性+持久性共同保证的结果； 隔离性：一个事务执行过程中不能被其他事物干扰，针对隔离性SQL定义了4个隔离级别，分别通过锁和mvcc实现。 持久性：事务提交之后对数据的改变是永久性的，innodb通过bin log + redo log(两阶段提交) + 双写缓冲区实现持久性。 控制多个事务对数据的操作其实就是隔离性，通过锁+mvcc实现。
查看系统中事物的语句是：
1 2 # 查看持续时间超过60s的事物 select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60 二）数据库并发的问题 针对于隔离性SQL定义了四种隔离级别来解决4种并发问题：
脏写：比如两个事务，一个A，一个B，A先将一个null值修改为a，但是还没有提交事务，可能还有别的数据要处理，这时候B过来把a改成了b，然后提交数据，然后A处理别的数据失败执行回滚，此时数据又变成了null，这就是脏写。 脏读：比如两个事务，一个事务A，一个事务B，事务A读取数据为a，然后就去处理别的数据了，没有提交事务，这时候事务B过来把a改成null但是也没有提交事务，然后事务A处理完回来再去读取数据变成了null，一下就蒙了，这就是脏读。脏读和脏写都是因为一个事务去读了另一个事务还没有提交事务的更新操作。 不可重复读：不可重复读和脏读的区别是不可重复读不能读取没提交事务的数据，脏读是读到了其他事物没提交的数据，属于脏数据。出现不可重复读的原因是在一次事务中对同一条数据的读取可能被别的事务改值并且提交，这么一看不可重复读算不算并发问题都可以，要根据业务去定义。 幻读：幻读和不可重复读的区别是不可重读是修改，幻读是增加或者删除，导致一次事务中多次读取的数据条数不一样。 三）SQL标准事务隔离 这是SQL不是MySQL，SQL数据库都有隔离级别，事务的隔离级别就是锁+MVCC的封装。
read uncommitted：读未提交，不会发生脏写，但是会有其他三个并发读问题，不适用MVCC并且不加锁实现这个隔离级别。 read committed：读已提交，就是说不能读取没有提交事务的值，这种隔离级别不会发生脏写和脏读，但是会有可重复读和幻读，一般都说RC。 repeatable read：可重复读，在一次事务中不管别人有没有提交过修改这个值的事务，读出来的值都是一样的，这种隔离级别只可能产生幻读问题，一般叫他RR。 serializable：串行化了，没人用，都串行了肯定不会有并发问题，性能太低，所有操作都加锁。 在spring中使用@Transactional(isolation=Isolation.DEFAULT)来设置隔离级别，DEFAULT就是默认，由数据库决定。
查看当前数据库的隔离级别的语句是：
1 show variables like 'transaction_isolation'; 四）MVCC 这个是数据库为了实现高并发的数据访问，通过事务的可见性来保证事务能够看见应该看见的版本，他的优点是读可以不加锁，并且读写不冲突。通过undo log版本链 + read view机制实现。
1）undo log版本链 每条数据都有两个隐藏的字段，trx_id和roll_pointer，trx_id是最新修改数据的事务id，而roll_pointer指向的是最后一次更新之前的undo log，undo log是链表结构，每个undo log元素都有修改前的值、trx_id和roll_pointer，trx_id就是那次修改的id，roll_pointer指向前一次的undo log元素，也就是说具体的数据行和undo log之间通过roll_pointer组成单向链表。
通过undo log版本链可以实现事务没提交的时候其他事务可以去读版本链中的已经提交的最新版本的undo log上的最新数据。
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to MySQL-6.事务" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/6.%E4%BA%8B%E5%8A%A1/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>MySQL-7.锁</h2></header><div class=entry-content><p>从操作粒度上可以分成全局锁(主要做全库的逻辑备份)、表锁(每个引擎都支持)、页锁(BDB引擎)、行锁(InnoDB)。
从操作类型分为读锁和写锁，读锁也叫共享锁，写锁也叫排它锁，共享锁和共享锁不互斥，排他锁和排他锁、排他锁和共享锁互斥。除了读写锁还有意向共享锁和意向排它锁，这两个都是表级的锁。
从性能上可以分成乐观锁和悲观锁，乐观锁的实现是通过版本对比来决定是否可以更新，但是更新的时候仍然需要加悲观锁。
全局锁 通过命令flush tables with read lock;开启全局锁，MySQL异常时会自动断开。开启全局锁后DDL、DML和TCL都会阻塞住，让整个库处于一个只读的状态，使用unlock tables释放锁。通常用于整库备份，不常用，一般备份的话可以用MySQL自带的备份工具，自带的备份工具会开启事务，基于快照的方式备份。
表级锁 使用show open tables查看表状态，结果中的inUse列大于0表示有表锁。使用lock table 表名 read/write添加表级读写锁，还是使用unlock tables释放锁。我使用innodb添加表级锁时，不管读锁还是写锁show open tables结果中的inUse都是1。
行锁 InnoDB引擎独有的，只有rr隔离级别并且在索引上才能生效。当修改或者删除没有使用索引或者索引失效的时候或者条件再索引中重复率超过30%，InnoDB会把行锁升级成表锁。
行锁有3种模式：
记录锁(Records lock)：为某行数据加锁，加锁的列必须是唯一索引或者聚簇索引；查询语句必须是精准匹配，否则会变成间隙锁； 间隙锁(Gap lock)：锁定一个范围内的索引，查询的结果是个范围的时候会添加间隙锁，如果是根据聚簇索引或者唯一索引范围查询，范围的下一条数据也会被加锁；如果是根据聚簇索引或者唯一索引不是范围查询的情况(也就是说操作指定一条数据)，当这条数据不存在的时候会产生间隙锁； 临键锁(next-key lock)：它相当于一种特殊的间隙锁，当操作的条件是聚簇或者唯一索引的等值条件时使用记录锁，聚簇或者唯一索引的条件会退化成间隙锁，对于非唯一索引使用临键锁。 lock in share mode会对二级索引加锁而for update会对二级索引和聚簇索引都加锁。
1）临键锁解决幻读问题 MySQL的RR级别如果使用的是快照读，不会出现幻读问题，当使用当前读或者RC级别、RU级别时才会出现幻读。</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to MySQL-7.锁" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/7.%E9%94%81/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>MySQL-8.索引</h2></header><div class=entry-content><p>索引类型 索引是存储引擎用例快速查找数据的数据结构。innodb只支持B+树索引，但是内部有个自适应的hash索引用来提高查询速度。
1）hash索引 根据索引列计算出hash码，使用hash码+行指针组成hash结构来存储索引，当发生指hash冲突的时候会追加链表。
hash索引做等值查询的时候非常快，但是他不会有索引覆盖的情况，而且他不能范围查询也不能排序。
2）B+树索引 b+树的根节点在内存中，子节点和叶子节点在磁盘
B+树的优点：增加阶数减少树的高度，减少树的高度就是减少磁盘io次数，查询的io次数更稳定。
索引匹配规则 全值匹配：查询条件和索引的字段完全相同，如果是组合索引，顺序不同优化器也会优化成组合和索引相同的顺序。 最左侧列匹配：在组合索引中，正常排序只是按照左侧第一个，如果相同，就用左侧第二个排序，以此类推，最左侧列匹配就是查询条件中有索引包含的列的时候，查询条件必须包含这个列所在的索引的左面所有的列，查询才会走索引。 最左前缀匹配：就是左侧第一个列使用like%，一定只能是在右侧放%，比如class_name like ‘3’%。 范围查找：也是左侧第一个列的范围，比如 ‘3’ &lt; class_name and class_name &lt; ‘5’。 等值匹配加范围匹配：范围匹配最多只能有一个，因为等值匹配可以确定下一列是有序的，按照范围查找很容易，但是第一个范围查找结束后，数据对于下一索引列是无序得了，所以只能有一个范围匹配。 order by的索引使用 order by中有ASC也有DESC的时候是没办法走索引的；
order by后不是列，而是计算出来的字段也是不走索引的；
group by的索引 group by和order by一样，满足索引使用规则时会走索引，不满足就不会走；
回表问题 因为聚簇索引里存储的都是部分列，当使用查询的字段需要回表并且回表次数太多时，MySQL会觉得还不如全表扫描快，全表扫描只需要遍历一遍索引树，所以当我们需要的字段在索引中包含了的时候，就不应该写select *了，这样都不用回表，不得不回表时，最好限制一下条数，否则很可能全表扫描。
创建索引 一般在业务开发完成后，需要把所有的sql检查一遍，查询的条件顺序尽量一致，然后根据条件创建组合索引；
但是对于基数很小，比如说是有0或者1，这种体现不出来二分查找的效率，还不如不建索引；
如果字段的值很大，那么可以只是用前几个字符当做索引，不过这种索引在order by或者group by中就不生效了；
避免聚簇索引频繁页分裂，应该使用自增主键；
避免二级索引过多，因为在增删改查的时候是要维护索引的B+树的，索引太多会让增删改变慢，两三个组合索引能覆盖大部分查询就可以；
当where和order by和limit一起使用但是不能同时满足索引时，优先满足where的索引； 当我们使用复核索引查询时，可能有些字段没用上，这样的话还是不会走索引的，如果没用上的列时字典类型，那么可以用加一个in（字典的所有状态），比如一个复合索引，城市+性别+最近七天登录+年龄，当查询语句是where city=‘哈尔滨’ and 21 &lt; age &lt; 25时是不会走索引的，可以改成where city=‘哈尔滨’ and sex in(0, 1) and does_login_in_7_days in(0, 1) and 21 &lt; age &lt; 25，这样就可以正常走索引了；
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to MySQL-8.索引" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/8.%E7%B4%A2%E5%BC%95/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>MySQL优化</h2></header><div class=entry-content><p>参数优化： 1）buffer pool参数优化 查看缓冲池大小，一般可以调成服务器内存的70%。
1 2 3 4 5 6 7 8 9 10 11 12 13 mysql> show variables like '%innodb_buffer_pool_size%'; +-------------------------+-----------+ | Variable_name | Value | +-------------------------+-----------+ | innodb_buffer_pool_size | 134217728 | +-------------------------+-----------+ mysql> select 134217728 / 1024 / 1024; +-------------------------+ | 134217728 / 1024 / 1024 | +-------------------------+ | 128.00000000 | +-------------------------+ 在线调整InnoDB缓冲池大小
...</p></div><footer class=entry-footer>4 min</footer><a class=entry-link aria-label="post link to MySQL优化" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/10.%E4%BC%98%E5%8C%96/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>MySQL参数配置</h2></header><div class=entry-content><p>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # 冷数据经过多少ms后被访问变成热数据 innodb_old_blocks_time # 冷热数据比例 innodb_old_blocks_pct # 最大连接数 max_connections # 设置buffer pool大小为8g # buffer pool的大小=chunk大小 * buffer的数量* x，x是2的倍数否则会有内存浪费 # 1g以内只有一个buffer pool innodb_buffer_pool_size=8589934592 # 设置4个buffer pool # 因为在操作buffer pool中的数据时，需要加锁，多设置buffer pool可以提高并发 innodb_buffer_pool_instances=4 # 一个区的连续数据页被访问超过56个就会把下个区的数据预读到buffer pool中 innodb_read_ahead_threshold=56 # 设置chunk大小是128m innodb_buffer_pool_chunk_size=134217728 # 设置redo log buffer大小，默认就是16m，够用了 innodb_log_buffer_size=16777216 # redo log日志路径 innodb_log_group_home_dir # redo log文件大小，默认48m innodb_log_file_size=134217728 # redo log文件数量 innodb_log_files_in_group=2 # redo log刷盘方式 # 0 提交事物的时候不刷盘 # 1 刷到磁盘 # 2 刷到OS cache innodb_flush_log_at_trx_commit=1 # 设置刷盘时每秒最大的速率，应该设置成硬盘的随机写速率 innodb_io_capacity=300 # 设置刷盘时不把临近的缓存页一起刷盘 innodb_flush_neighbors=0 命令 1 2 3 4 5 6 7 # 查看InnoDB参数及使用情况 SHOW ENGINE INNODB STATUS # 查看存放数据的目录 show variables like 'datadir' # 修改隔离级别 # level可以是REPEATABLE READ，READ COMMITTED，READ UNCOMMITTED，SERIALIZABLE SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL level</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to MySQL参数配置" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E5%8F%82%E6%95%B0/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>MySQL查询计划</h2></header><div class=entry-content><p>真正的SQL优化是根据优化器给出的执行计划，改写SQL，改良索引，让SQL性能提升。
名词 system：表中只有1行数据。 const：直接通过聚簇索引或者索引覆盖或者二级索引加回表就能返回结果的语句，性能是常量级，但是二级索引必须是unique key，也就是说只能查出来一条； ref：普通二级索引，而且条件必须是全值匹配，有个例外，当查询条件是主键 is not null时，也是ref； res_or_null：这个是说查询使用二级索引的全值匹配，但是有个条件是 is not null； range：这个也是用了索引，但是是范围查询； index：这个意思是查询条件没用索引，但是遍历的是索引的B+树，比如有一个联合索引 x1 + x2 + x3，执行语句select x1, x2, x3 from table where name=‘大叔大’，查询的字段都在索引中，遍历索引的B+树要比遍历数据页快，不过他还是类似全表扫描； index_merge：单表查询时，使用了多个索引，然后把结果合并； all：全表扫描； 不管是内联还是外联，都叫循环嵌套关联，应该尽可能让查询都用上索引，否则查询次数是乘积关系。
执行计划成本 成本就是需要消耗的资源，MySQL定义把数据页加载到内存消耗IO成本是1.0，在内存中计算比如排序、分组、验证符合条件消耗CPU成本是0.2。
使用二级索引扫描的时候粗略的认为一个范围区间就是一个数据页
计算全表扫描的成本 使用show table status lie ‘表名’可以查看表的相关信息，比如rows：有多少行数据（innodb的估计值）；data_length：聚簇索引占的字节数，使用data_length/1024/16差不多是有多少个数据页，那么全表扫描的成本 = (data_length / 1024 / 16) * 1.0 + rows * 0.2
计算二级索引扫描成本 比如说使用25 &lt; name &lt; 100 or 150 &lt; name &lt; 200，name是个索引，这是两个区间，可以近似成两个数据页，IO成本就是2 * 1.0，比如查到了100条数据，这100条数据的CPU成本就是100 * 0.2，而且还需要回表，回表的时候暴力认为一条数据需要对应数据页，那回表把数据页加载到内存的IO成本就是100 * 1.0，内存的CPU成本是100 * 0.2，这个查询的成本就是2 + 20 + 100 + 20 = 142。
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to MySQL查询计划" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/9.%E6%9F%A5%E8%AF%A2%E8%AE%A1%E5%88%92/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>nacos-1.集群搭建</h2></header><div class=entry-content><p>官网推荐vip模式集群，VIP是指虚拟ip，单点故障的时候会自动漂移到可用节点。 三台机器分别安装keepalived和nacos：
先整个jdk；
安装keepalived：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 yum install -y gcc openssl-devel popt-devel yum install -y libnl libnl-devel yum install -y libnfnetlink-devel yum install -y curl gcc openssl-devel libnl3-devel net-snmp-devel libnfnetlink-devel # 解压安装 tar -xzvf keepalived-2.1.5.tar.gz cd keepalived-2.1.5/ ./configure --prefix=/usr/local/keepalived make && make install # 创建启动文件 cd /usr/local/ cp -a keepalived/etc/keepalived /etc/init.d/ cp -a keepalived/etc/sysconfig/keepalived /etc/sysconfig/ cp -a keepalived/sbin/keepalived /usr/sbin/ # 创建配置文件 mkdir /etc/keepalived cd /etc/keepalived ##复制配置文件 cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived 修改keeplived.conf
...</p></div><footer class=entry-footer>2 min</footer><a class=entry-link aria-label="post link to nacos-1.集群搭建" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/spring/cloud-alibaba/nacos/1.%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>nacos-2.基础</h2></header><div class=entry-content><p>一 概念 命名空间：用来区分不同的开发环境，生产(prod)、预发布(staging)、联调测试(test)、开发自测(beta)、开发(dev) 分开，防止配置、服务错乱。 分组：一个完整的大系统由很多服务组成，一般分组名称由系统名称命名。 健康探测机制：dubbo服务注册到nacos时，如果ephemeral是true表示临时节点(默认)： 临时节点：每个服务都会定时向nacos发送心跳，默认5s，如果15s没收到心跳就会把这个实例标记成不健康实例，30s没收到心跳会摘除这个服务实例。 持久节点：nacos每20s主动探测实例是否可用，如果不可用标记成不健康状态，不会摘除实例。 保护阈值：比如一个下游服务的实例中宕机了一半，这个时候剩下的一半也可能因为流量变大被打死，保护阈值的作用是健康实例的比例低于这个阈值就会让不健康的服务实例也参与被调用，可以防止服务雪崩，取值范围是0~1。触发保护阈值虽然可以保证可用性，但是会导致一致性问题，因为会有部分请求打到不可用的服务上，如果这个时候触发了熔断降级，拿到的数据就是不一致的。 二 元数据 每个服务、集群、实例都有自己的元数据，格式就是key=value。默认服务、集群的元数据是空，实例的元数据：
1 2 3 4 5 6 7 8 # dubbo服务url元数据 dubbo.metadata-service.urls=[ "dubbo://172.30.60.105:20886/com.alibaba.cloud.dubbo.service.DubboMetadataService?anyhost=true&amp;application=stars-report-service&amp;bind.ip=172.30.60.105&amp;bind.port=20886&amp;deprecated=false&amp;dubbo=2.0.2&amp;dynamic=true&amp;generic=false&amp;group=stars-report-service&amp;interface=com.alibaba.cloud.dubbo.service.DubboMetadataService&amp;metadata-type=remote&amp;methods=getAllServiceKeys,getServiceRestMetadata,getExportedURLs,getAllExportedURLs&amp;pid=8518&amp;qos.enable=false&amp;release=2.7.8&amp;revision=2.2.6.RELEASE&amp;service.filter=customerExceptionFilter&amp;side=provider&amp;timestamp=1664088868313&amp;version=1.0.0" ] dubbo.metadata.revision=722115F0F6F280A931188D6CEB16F05C dubbo.protocols.dubbo.port=20886 preserved.register.source=SPRING_CLOUD 三 distro协议（ap，保证最终一致） nacos集群需要维护服务实例的信息、状态等数据，但是服务实例找那个nacos节点发起注册？实例数据存储在哪个nacos节点上？服务发现的时候去找那个nacos节点？nacos自研的distro分布式一致性协议就是解决这3个问题的。
1.注册流程 服务在启动的时候会随机拿到一个nacos实例的地址发起注册请求，nacos收到注册请求之后根据服务实例的ip+port计算这个服务应该由哪个nacos节点负责，然后转发给对应的nacos实例。目标nacos会把服务实例信息缓存到内存里，然后返回响应给转发的nacos节点，转发的nacos节点在把响应返回给服务实例。
2.数据分片和订阅处理 按照注册的流程，每个nacos节点只会保存一部分服务实例的数据，这样的话会有两个问题，服务实例获取订阅节点信息怎么获取，怎么订阅；nacos节点宕机怎么办。
distro的实现是nacos节点会定时把自己的服务数据发送给其他节点，也会收到其他节点上的服务信息，相当于是推模式的全量保存实现了最终一致性。订阅时随机选择一个nacos节点，这里可能有个时间差：当服务刚注册的时候，其他nacos节点时没有这个服务的信息的，此时获取服务信息的请求会失败，然后添加一个监听，数据同步完之后会去回调监听。
3.数据补偿 nacos各个节点之间会定期发送心跳，当发现自己保存的其他节点上的数据和发心跳这个节点的数据不一致，会全量同步一下，这样可以解决网络分区导致的长时间定时同步失败的情况。
四 raft协议（弱cp，保证一致） raft协议下要求nacos集群选举一个leader，只能leader写入，但是当节点写完之后需要全量同步所有服务信息到其他节点，当过半节点都成功了之后才会返回注册成功，这样会大大降低nacos的吞吐。弱cp就是因为过半而不是全量。</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to nacos-2.基础" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/spring/cloud-alibaba/nacos/2.%E5%9F%BA%E7%A1%80/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://wangxiaohong123.github.io/page/20/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://wangxiaohong123.github.io/page/22/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>