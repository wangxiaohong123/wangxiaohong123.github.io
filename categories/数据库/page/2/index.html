<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>数据库 | 王小红的笔记</title><meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangxiaohong123.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/index.xml><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script><meta property="og:url" content="https://wangxiaohong123.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="数据库"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="数据库"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>数据库</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>3.es-入门</h2></header><div class=entry-content><p>在7版本以后废弃了type类型，所以一些crud操作的命令会跟着改变
api cat api用来查看es中的各种数据，api结尾带上v表示结果带上列名。
查看基本的集群信息 1 GET _cat/health?v 这个请求完了会拿到一个结果，最主要的就是看status参数，他有3个值：
green：每个索引的primary shard和replica shard都是active状态； yellow：部分replica shard不是active状态，处于不可用状态，当单节点启动es，创建索引默认都是有一个replica shard的，但是replica不能喝primary在一台机器上，这样就会导致这个index的状态是yellow； red：部分索引的primary shard不是active状态，可能有部分数据已经丢失了； 查看集群中的索引。 1 GET _cat/indices?v 查看索引下文档个数 1 GET /_cat/count/{index}?h=count 查看文档个数、索引占用磁盘空间 1 GET /_cat/indices/{index}?v 创建一条索引 1 PUT /{index}?pretty 删除一个索引。 1 DELETE /{index} 添加文档 1 2 3 PUT /{index}/_doc/{id} PUT /{index}/_create/{id} 老版本使用/{index}/{type}/{id}添加文档，如果index和type不存在，es会自动创建，并且默认会把每个field都建立倒排索引，需要注意index下多个type的id也不能相同，否则会报illegal_argument_exception错误，但是要废弃了。
...</p></div><footer class=entry-footer>6 min</footer><a class=entry-link aria-label="post link to 3.es-入门" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/3.%E5%85%A5%E9%97%A8/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>3.分库分表-经验</h2></header><div class=entry-content><p>shard key 分库分表后首先要考虑的就是分片key的设计，比如单号和用户关联，订单号使用类型(10表示正向下单，20表示退单)+flicker+用户id后3位，这样订单就和用户关联起来，查询用户的订单会路由到同一个库的同一张表中，查询订单明细也会路由到同一个库的同一张表中
主键id 分库分表后的id一般都会使用雪花算法生成，保证不同表的id也没有重复，但是一般shard key不会采用id，这个id其实是没有查询意义的。
默认策略 有的表不需要分库分表(比如seata)，有的表只要分库，有的表需要分库分表，不分库分表的会去走默认策略。有的业务需要一种每个库存储一样的数据，就要配置成广播表。
配合其他数据库 分库分表的原因是数据量过大，一帮分库分表之后只靠MySQL是无法满足业务的，高频率的复杂查询和复杂查询+分页需要es的配合，低频率的大量数据可以使用MongoDB，还有一些更大数据量的低频查询数据可以使用HBase，他和MongoDB的区别是他可以对保存的数据进行列扩展，还可以对MySQL的一些数据做降级，需要注意HBase的查询只有根据rowkey才快，所以在rowkey的设计上需要一些技巧。
数据迁移 分库分表或者多种库异构存储就要涉及到数据迁移，数据迁移方案由两步组成，全量同步和增量同步，两步就有同步执行和串行执行，在执行数据迁移之前要把新版本的服务环境和服务运行起来，此时流量0%打到新系统上，启动数据迁移系统，然后启动canal监听老版本和新版本数据库的binlog，开启数据全量同步。
全量和增量串行，如果是串行在全量同步的时候收到的增量变更只记录，不执行，等到全量同步完成后，遍历增量变更数据，根据变更时间和全量数据的查询时间，选择性刷新数据，在全量同步完成后，收到的增量变更不记录，直接刷新，然后修改分流方案，让流量全部打到新系统上，这个时候就服务就已经没用了，等到增量的topic全部消费完数据迁移服务也没用了。适合小数据量的数据迁移。 全量和增量并行，并行和串行类似，但是比串行快，同时迁移代码也更复杂，需要处理好并发问题。</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 3.分库分表-经验" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/3.%E7%BB%8F%E9%AA%8C/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>5.索引</h2></header><div class=entry-content><p>mapping 有的时候查询的结果和我们想的不一样，可能会多查或者少查，这是因为添加document的时候es会自动帮我们创建type对应的mapping(dynamic mapping)，mapping中有分词规则、field类型等等，使用**GET /{index}/_mapping/**查看index下的type对应的mapping。
1.核心的数据类型 keyword、text byte、short、integer、long float、double date boolean multivalue：类似数组，要求元素类型必须相同 empty：null,[],[null]这种 object：jsonObject text、multivalue field会触发分词操作，可以指定分词器或者设置不分词，在旧版本中设置index: not_analyzer表示不分词，新版本中只需要把type设置成keyword就表示不分词。 手动建立mapping，不能修改已存在的field的mapping，下面的语句是创建index时指定mapping：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 PUT /website { "settings" : { // 1个primary shard "number_of_shards": 1, // 每个primary shard有0个replica shard "number_of_replicas": 0 }, "mappings": { "properties": { "content": { "type": "text", "analyzer": "english" // 指定特殊语言分词 }, "post_date": { "type": "date" }, "title": { "type": "text" }, "publisher_id": { "type": "keyword", // 不分词的的field "index": false // false表示这个字段不能被当作搜索条件 } } } } 如果想要新增field的mapping执行PUT /{index}/_mapping命令：
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 5.索引" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/5.%E7%B4%A2%E5%BC%95/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>6.搜索</h2></header><div class=entry-content><p>query string的语法 简单的查询可以把过滤条件直接放到url中，使用q表示过滤，比如查询test_field1字段等于test1：
1 2 3 4 5 6 ### 两中写法都是包含就可以，包含的意思是分词之后，存在相同单词 GET /test_index/_search?q=test_field1:test1 GET /test_index/_search?q=+test_field1:test1 ### 减号表示不等于 GET /test_index/_search?q=-test_field1:test1 当我们不指定field的时候比如下面这样就是搜索所有字段，只要有一个字段等于或者不等于(取决于是否使用减号)指定值就可以：
1 2 GET /test_index/_search?q=test1 GET /test_index/_search?q=-test1 在新建document的时候，会把所有的field拼到一个字符串里，并且定义为_all字段，分词后也会建立倒排索引，在搜索时，如果没指定字段，就会去查找_all字段中包含test的所有document。
搜索模式 精确匹配：exact value，全部匹配才算匹配； 全文检索：full text，缩写（比如china 和cn），格式转换(likes、like、liked)大小写，近义词都可以当成匹配； 在建立倒排索引之前会进行normalization处理(提升recall召回率)，把拆出来的词同义词转换、单复数转换等动作，然后在根据转换后的词建立倒排索引，查询的时候也是一样的，先拆词在normalization，在去检索。
不同类型的field，有的可能是exact value比如date，有的可能是full text，比如_all、text。
分词器 切分词语和normalization操作都是分词器的工作。主要是三步：
character filter：过滤文本的内容，比如把html标签和符号去掉； tokenizer：分词； token filter：normalization操作，转换之后可能就把没意义的词去掉了，比如a、the之类的； 1.内置分词器： standard analyzer：默认的分词器。可以大小写转换、去符号，但是没拆'_'； simple analyzer：大小写转换、去符号，也能去'_'； whitespace analyzer：什么都不干，大小写都不转，只按照空格拆； language analyzer：特定语言分词器，比如英语分词器，他可以把单词转成近义词、大小写、去符号、时态转换、去掉没意义的词； 2.测试分词 发送下面的请求会根据参数里analyzer指定的分词器拆分text内容并返回结果：
...</p></div><footer class=entry-footer>3 min</footer><a class=entry-link aria-label="post link to 6.搜索" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/6.%E6%90%9C%E7%B4%A2/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>es-4.原理</h2></header><div class=entry-content><p>1.读写原理 在写入数据的时候先记录translog到os cache同时把数据写到内存的indexing buffer中，这个时候数据是查不到的，内存的indexing buffer中的数据每隔一秒会刷到os cache中，刷到os cache之后才能查到数据。os cache中的数据每个5s(默认)或者达到512m(默认)会刷入磁盘，所以如果es的进程挂了最多会丢1s的数据，primary所在服务器宕机也只会丢失1s数据(副本中还有一份数据)，primary和replica所在服务器都宕机才会丢失5s数据(这种情况极少极少)。
1.1写优化 数据不丢：如果想要数据不丢就设置index.translog.durability: request，他会让translog同步刷盘，性能也会降低。 常规写优化：如果允许数据部分丢失可以设置index.translog.durability: async，只要translog写到os cache就算成功，还可以设置index.translog.sync_interval和index.translog.flush_threshold_size控制os cache刷盘的频率。 段合并优化：indices.memory.index_buffer_size参数控制indexing buffer的大小，如果写满了就会执行刷盘操作，默认是堆内存的10%，可以调大；每次从os cache将索引数据刷盘都会生成一个新的segment文件，segment文件数量到限制后会执行合并操作，数量限制通过index.merge.policy.segments_per_tier参数控制，默认是10，可以调大； 1.2查询优化 增加page cache：es的搜索时严重依赖内存的，如果内存没有需要从磁盘搜索，这个速度就慢了，所以要给es足够内存，一般都是jvm占一般，os cache占一半。 减少存储空间：保证没用的数据不写入es，减少数据的大小，_source、_all(6.x后默认禁用)能禁用就禁用，有一些字段不是查询条件比如业务id可以把index属性设置成false，有一些字段不需要持久化就把store属性设置成false。 容量和集群规划：搭建es时要考虑数据占用空间，并计算未来3年、5年数据的增长来选择机器配置，同时primary要比机器数量多一点，保证以后可以扩容(因为primary shad数量不能修改)。 冷热数据分离：识别出来索引中的冷数据，比如2年前的数据，这些数据可以持久化到Hadoop中。 pre-index：预索引，比如说价格是33.22，存储时额外加一个字段存储的是10-50，表示这个价格所在的区间，根据价格范围查找的时候要比直接根据价格字段快，但是也快不了太多。 提升缓存命中：比如把日期粗化到天，如果是精确到秒很难用到jvm的缓存，也快不了太多。 os cache预热：机器重启的时候可以设置index.store.preload，会把索引提前加载到os cache中。 2.数据路由原理 数据路由：因为一个document只能存在一个primary shard上，在创建数据的时候es需要决定这条文档应该放在哪个shard上。
路由算法：shard = hash(routing) % primary shard数量，当操作中有_id时，这个routing就是_id，然后算出hash值在和primary shard的数量求余。routing值可以手动指定，比如说PUT /test_index/_doc/1?routing=user_id。 这样就可以解释为什么primary shard的数量不可变了，一旦发生变化查找数据很容易就找不到。
3.deep paging 深度分页的意思就是说比如现在有3个shard上有index的数据，每个shard存100000条，然后我要查第10000到10010条数据，他就会把每个shard上的前10010条数据都拿出来，然后根据score排序在拿到第10000到10010条数据返回，deep paging很耗带宽、内存、CPU。
4.filter和其他搜索区别 filter只是根据条件过滤，其他搜索像must还需要计算相关度然后在排序，如果只是要筛选使用filter可以提高性能，filter还是用了cache保存最常用的filter。
5.相关度分数算法 TF/IDF(term frequency/inverse document frequency )算法：
term frequency：搜索的词条在文本里出现了多少次，次数越多越相关； inverse document frequency：搜索的此条在整个index中出现的次数越多就越不想关， 比如搜索词条中有两个词，一个词在整个index中出现5000次，一个词只出现100次，肯定出现100次的词更容易影响分数； field-length norm：field长度和相关度成反比； 在查询命令的url后面拼上explain参数表示打印出相关度计算的detail。
6.doc values(正排索引) 就是类似MySQL，按行存储，排序只能用doc values，如果内存足够的话doc values会存在os cache中，否则只会在磁盘上。</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to es-4.原理" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/4.%E5%8E%9F%E7%90%86/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>filter</h2></header><div class=entry-content><p>查看分词
1 2 3 4 5 6 // 查看forum索引下的field为articleID内容是XHDK-A-1293-#fJ3的分词 GET /forum/_analyze { "field": "articleID", "text": "XHDK-A-1293-#fJ3" } 5版本以后如果field的类型是text，会多建一个field，原field是分词的，es创建的field.keyword是不分词的，类型是keyword，默认保存256个字符。
term语法：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 GET /forum/article/_search { "query": { "constant_score": { // 使用filter需要把匹配度分数设置成1，必须要写constant_score "filter": { "term": { // term搜索，不会对term中的条件进行分词 "articleID" : "XHDK-A-1293-#fJ3" } } } } } // 如果条件的field是分词的，那么这个查询时查不出结果的，可以使用es自动创建的部分词field查询 { "query": { "constant_score": { "filter": { "term": { "articleID.keyword" : "XHDK-A-1293-#fJ3" } } } } } // term还可以写成terms，相当于SQL的in，类似于这样："term": {"articleID" : ["a","b","c"]} filter执行原理
...</p></div><footer class=entry-footer>2 min</footer><a class=entry-link aria-label="post link to filter" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/6.filter/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>MySQL-0.主从搭建</h2></header><div class=entry-content><p>安装mysql5.7：https://www.cnblogs.com/hsbt2333/p/9915616.html
首先在主库上创建一个用于主从复制的账号：
1 2 3 create user 'backup_user'@'%' identified by 'qiyuan1502'; grant replication slave on *.* to 'backup_user'@'%'; flush privileges; 如果是新增从库需要让系统停机，对外不可用，然后全量备份一下主库：
1 2 3 4 5 # 先把主从库的的binlog打开，修改my.cnf，在mysqld下添加，一定要在这个下面，两个库的server-id=1不能一样 log-bin=mysql-bin server-id=1 # --master-data=2是记录binlog和position，主从需要 /usr/local/mysql/bin/mysqldump --single-transaction -uroot -proot --master-data=2 -A > /usr/local/mysql/backup.sql 然后在新的从库上执行sql文件。
从库上执行命令绑定主库
1 2 3 4 5 6 7 # MASTER_LOG_FILE和MASTER_LOG_POS在backup.sql中获取 CHANGE MASTER TO MASTER_HOST='59.110.156.68',MASTER_USER='backup_user',MASTER_PASSWORD='qiyuan1502',MASTER_LOG_FILE='mysql-bin.000001',MASTER_LOG_POS=154; # 开始主从 start slave; # 查看主从状态，看到slave io running和slave copy tunning就可以了 show slave status; 5.7默认是半同步方式。
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to MySQL-0.主从搭建" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/0.%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>MySQL-1.基础</h2></header><div class=entry-content><p>DDL：数据库定义语句，用来操作数据库中的表、索引、试图、存储过程等；
DML：增删改查；
DCL：控制语句，授权什么的；
TCL：事务控制语句；
常见的连接池 DBCP、C3P0、Druid
MySQL自己也有一个连接池；
日志 undo log：存储更新前的值，为了事务回滚和MVCC（版本并发控制）；
redo log：搜索引擎中存储的操作日志，防止数据库宕机，是InnoDB特有的，偏物理性质的重做日志，记录的是对那个数据页中的那条记录做了什么修改；redo log是固定文件数循环写。
binlog：MySQL server自己的日志文件，对表中那一条数据做了什么操作，结果是什么；binlog会不断产生新文件。
一条sql语句的执行步骤 当MySQL内部线程从网络连接解析出来一条sql语句的时候会提交SQL接口（MySQL提供的一个组件）去执行，SQL接口把sql语句交给SQl解析器，解析器将SQL按照SQL语法进行拆解，在到查询优化器找到最优查询路径最后通过执行器把优化后的最优路径方案一步一步提交给存储引擎执行。操作数据成功后，redo log中已经有了记录，这时候会添加binlog记录，binlog记录成功后会在redo log中写入这次更新数据的binlog文件名和文件中的位置，然后在redo log中写入commit标记，然后提交事务，到此，一条sql语句才算执行成功了。
innodb内存模型 io thread：处理读写操作，使用show engine innodb status可以查看io 现成信息，一般分成4类：
read thread：负责把数据页加载到内存； write thread：把脏页刷新到磁盘； log thread：把内存中的日志刷到磁盘； insert buffer thread：将change buffer内容刷到磁盘； purge thread：事务提交之后回收不需要的undo log，通过innodb_purge_threads配置数量；
page cleaner thread：通过innodb_page_cleaners配置数量，默认是1个，他是负责调用write thread的。
master thread：主线程，负责调用其他线程，他有每秒的操作，也有每10秒的操作。 每秒的操作：
脏页达到75%的时候刷新脏页到磁盘，每次刷新200个； 当1s的io次数小于5时合并写缓冲区数据； 刷新日志缓冲区，没有提交的事务涉及到的redo log也会刷新； 每10秒的操作：
刷新脏页到磁盘，每次刷200(innodb_io_capacity)个； 合并写缓冲区的数据，合并innodb_io_capacity * 5%个； 刷新日志缓冲区； 删掉没用的undo log；</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to MySQL-1.基础" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/1.%E5%9F%BA%E7%A1%80/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>MySQL-2.压测</h2></header><div class=entry-content><p>sysbench 执行以下命令安装sysbench：
1 2 3 4 curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash sudo yum install -y sysbench # 查看版本 sysbench --version 可以创建测试用户和测试库，我只创建个测试库，5.6创建用户烦得很。
构建测试表和测试数据
1 2 3 4 5 6 7 8 9 10 11 12 13 14 sysbench --db-driver=mysql --time=300 --threads=10 --report-interval=1 --mysql-host=192.168.0.6 --mysql-port=3306 --mysql-user=root --mysql-password=root --mysql-db=test_db --tables=20 --table_size=100000 oltp_read_write --db-ps-mode=disable prepare ####################参数说明#################### --db-driver=mysql 基于mysql驱动链接mysql --time=300 连续访问300秒 --threads=10 10个线程 --report-interval=1 每隔1秒输出一下压测情况 --mysql-host=192.168.0.6 --mysql-port=3306 --mysql-user=root --mysql-password=root 数据库连接参数 --mysql-db=test_db --tables=20 --table_size=100000 在test_db中创建20张表，每个表10万条数据 oltp_read_write 执行oltp数据库的读写测试，除了读写还有很多，比如删除、只读、只写、索引等等 --db-ps-mode=disable 禁止ps模式 prepare 准备，还有run运行、cleanup清除测试数据 在run之前先prepare，run之后cleanup 分析结果
...</p></div><footer class=entry-footer>2 min</footer><a class=entry-link aria-label="post link to MySQL-2.压测" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/2.%E5%8E%8B%E6%B5%8B/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>MySQL-3.InnoDB的内存结构</h2></header><div class=entry-content><p>一 buffer pool(缓冲池) 用来缓存表数据和索引数据。MySQL的增删改查都是在buffer pool中进行的，如果buffer pool中没有目标数据会从磁盘中加载到buffer pool中。默认是128M。
1）缓存页 直接操作磁盘会让MySQL的效率极低而且扛不住并发，通过在缓存中操作数据可以解决这个问题，从磁盘加载数据到缓存和从缓存写入磁盘都是以数据页的形式，被加载到内存里数据页就叫缓存页，磁盘中每个数据页都是16k，所以一个缓存页也是16k。不管是数据还是索引都是使用数据页方式存储，所以缓存页中可能存在数据页也可能存在索引页。
在缓存中除了缓存页还有缓存页描述信息(也叫控制块)，描述信息包括缓存页的所属表空间、缓存页的编号、缓存页在缓存中的地址以及各个控制块组成的链表信息等等。描述信息在缓存前面，大概相当于数据页的5%大小，缓存页在缓存后面，每个缓存页都有对应的描述信息。
2）数据时如何被加载到缓存中的？ 2.1）buffer pool的内存结构 Buffer pool中的缓存页使用链表来管理，缓存页有3种状态，每种状态对应一个链表，他的3种状态及对应链表：
free page：缓存页是空的，没有被使用，把所有没有使用的缓存页对应的控制块组成一个双向链表，叫做free链表。free链表的头结点叫做基础节点，这个节点不是一个控制块，他用来存储的是链表长度、首尾节点等描述信息； dirty page：脏页，缓存页被使用并且页中的数据被修改但是还没有刷新到磁盘，所有脏页的控制块会组成一个双向链表，叫flush链表。flush链表的头节点也不是控制块，和free链表一样，主要是记录脏页用来刷盘操作； clean page：缓存页被使用，但是数据没有被修改； 除了上面的两种链表，还有一个链表叫lru链表，用来管理被使用的缓存页，就是说dirty page和clean page的控制块会共同组成这个链表。他的基节点和其他节点一样，这个链表使用lru算法(最近最少使用)实现，当使用了缓存页之后，缓存页会被加载到链表的头部。他的优点是可以保证与最近经常使用的数据有关的SQL能够快速响应。
除了上面的3个链表，想要在内存中管理page页还需要一个hash表，内存中被使用的缓存页会在hash表中存在一条记录，表空间 + 数据页号作为key，缓存页的地址是value，通过hash表可以判断出来数据页是否在缓存中。
2.2）lru链表的改进 传统的lru链表如果应用到MySQL上有两个问题：
发生全表扫描的时候会把表里的数据页都加载到内存中，这个时候就刚加载进来的数据会在lru链表的前面，如果缓存页满了lru链表尾部的数据会被刷盘，就是说可能真正经常被使用的数据被刷到了磁盘。 MySQL存在预读机制，预读有两种情况，线性预读(当发现读取的数据页都在同一个区并且页数超过了56个就会把整个区都加载到buffer pool中)和随机预读(当buffer pool中出现同一个区的数据页数超过13，就会异步把这个区的所有数据页加载到内存中)，和上面一样可能会有很多预读页出现在lru链表的头部，其实他们可能没啥用，也可能导致真正热点数据被刷到磁盘上。 正对这两个可能覆盖真正的热数据问题MySQL对lru链表进行了优化：MySQL将lru链表分成冷热数据区，数据页刚被加载到内存中时会放到冷数据区，当冷数据区的缓存页存在超过1s并且被访问了，就会移动到热数据区的1/4的位置，再次被访问后移动到热数据区的头部。
2.3）加载数据的过程 数据库启动的时候会按照设置的buffer pool大小在加一点（因为有描述信息+链表基节点信息），然后去申请一块内存，申请下来了之后就会按照16k和800字节的描述信息划分出来一块一块的空间（800b就是描述信息），当我们执行crud时会先通过hash表判断buffer pool中是否有目标数据页，如果没有的话会将磁盘中的数据加载到缓存中来。然后修改对应的free链表和lru链表的指针。
3）数据是如何刷盘的 当缓存页满了的时候会使用LRU淘汰算法，当一个缓存页被使用时，就会在描述信息中添加两个节点信息，组成了LRU链表，每次缓存页被使用就会将描述信息放到LRU链表的头部，这样当缓存页满了的时候就会从链表的尾部取出一个描述信息，先将缓存页的数据刷入磁盘，然后在清掉对应的缓存页和描述信息加载新的数据页。
但是这样会有很大的问题，因为MySQL存在预读机制：
预读机制：当在同一区读取了很多（参数可配）连续的数据页的时候就会产生预读，一次读取很多数据页。 如果这些数据页并没有用到，但是新读出来的却放在了LRU链表的头部，这样发生淘汰时会将链表最后的缓存页刷盘，但是很有可能最后的缓存页是被频繁访问的，而预读出来的数据页是没用的，所以LRU链表有两部分，一部分是热数据，一部分是冷数据，预读出来的数据页都放在冷数据里，淘汰时也优先淘汰冷数据，当冷数据在1s（参数可配）后被使用时，就会把这个缓存页放到热数据里。
二 change buffer(写缓冲区) change buffer是针对二级索引的更新优化措施。change buffe是buffer pool划分出来的一块区域，占buffer pool的25%，对二级索引的增删改操作会被记录到change buffer中。
当执行增删改数据的时候，不会用到change buffer，正常加载数据修改就行，如果被修改的数据是非聚簇索引(因为聚簇索引的修改需要校验唯一性，这个没办法缓存，也会同步执行)会先判断数据对应的二级索引数据页是否在buffer pool中，如果在的话就直接修改然后添加redo log那一套，如果不在的话会在change buffer记录这个更新操作就结束了，等到非聚簇数据页被加载到内存中时，会去change buffer中查找对应的修改操作，如果有修改操作会merge到缓存页中。
1）change buffer的merge时机 当二级索引数据页被加载到内存时 后台线程定时merge 正常关闭数据库的时候 三 log buffer(日志缓冲区) log buffer分成两块，一块叫undo log buffer，另一块是redo log buffer，redo log buffer是用来优化每次更新都需要写入redo log的磁盘io问题。默认16M。</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to MySQL-3.InnoDB的内存结构" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/3.innodb%E7%9A%84%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://wangxiaohong123.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://wangxiaohong123.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/page/3/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>