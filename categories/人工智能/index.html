<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>人工智能 | 王小红的笔记</title><meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangxiaohong123.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/index.xml><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://wangxiaohong123.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="人工智能"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="人工智能"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>人工智能</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>1.机器学习介绍</h2></header><div class=entry-content><p>图灵在50年的时候提出机器思维：一个人在不知道对方是计算机的情况下进行很长时间的问答，如果无法判断对方是不是计算机就说明这个计算机有了人的思维。56年的时候麦卡锡提出了人工智能的术语。
柏拉图假说：不同的人工智能系统以不同的方式表示世界，视觉系统表示为形状和颜色，语言模型表示为语法和语义；但是随着参数规模、训练数据的不断扩大，不同模型对于现实的表征方式会越来越相似，所以现在的大语言模型或者文生视频这种其他模型都使用全模态(文本、视频、音频、深度图等)数据来训练，比单一模态数据性能提高20%。这就发展成现在很多模型都是在大语言模型上微调来的，比如qwen2-VL是基于qwen2的，CogVLM2机遇llama3 8b微调来的。
1 介绍 人工智能发展阶段
1.1 人工智能 三要素：数据，算法，计算力，CPU核心数较少，基于冯诺依曼架构(存储程序，顺序执行)，适合逻辑控制，处理复杂的指令集；GPU核心数较多，适合并行处理大量简单且重复的指令，比如矩阵、向量计算；TPU是Google专门为机器学习设计的芯片。
机器学习是人工智能的实现途径，而深度学习是机器学习发展而来，也就是神经网络。195x年最开始人工智能最多就是和人下个黑白棋，198x年开始使用机器学习分辨垃圾邮件，201x年开始深度学习让机器可以识别图片。
现在的模型分大模型和普通模型，普通模型就像专攻一样，训练的数据有10种类别，他就只能做这10种类别的事。大模型的不光是模型的架构大，也是数据集的大，大模型也可能自己创造训练数据，训练自己，比如segment anything。
1.1.1 当前人工智能目前主要应用领域 计算机视觉(CV)：机器感知环境的能力，比如物体检测和人脸识别。 自然语言处理(NLP)：自然语言处理又包括语音识别、机器翻译、文本挖掘和分类： 文本挖掘和分类：主要是对文字的情绪分析和垃圾检测，目前尤其是中文不同的词在不同的场景有不同的语义是一个难点。 机器翻译：方言、行话是难题。 语音：语音识别，语音合成什么的，音转文和文转音是一个领域，现在声纹识别和鸡尾酒会效应很难处理好。声纹和指纹差不多，每个人的声音都不一样，如果能提取出人的声纹那就可以实现声音支付了。鸡尾酒会是说人的大脑在和别人专心讨论的时候会自动降燥，专注和交流目标对话，目前计算机只能做到很多人说话，找不到应该重点听谁发出的声音。 1.2 机器学习算法分类 算法方向分为ML机器学习，DL深度学习，RL强化学习。
根据数据集组成可以将机器学习的算法分为监督学习、无监督学习、半监督学习和强化学习。如果输出是连续的成为回归，输出是有限个离散值叫分类。
监督学习：输入数据由特征值和目标值组成； 无监督学习：输入数据只有特征没有目标值； 半监督学习：输入数据部分没有目标值，适合数据难标记或者标记成本高的情况，先用少量标记初步训练，然后用未标记数据训练； 强化学习：强化学习是一个决策问题，可以做连续的自动决策，包含5个元素：agent(代理体)，action(行动)，reward(奖励)，environment(环境)和observation(观察情况)，比如让程序中的某个角色模拟走路，这个角色就是agent，他需要决定先迈左脚还是右脚，迈出一步还要不要在迈一步，迈步就是action，地面就是environment，走了几步可以给他reward。强化学习的目标是获得最多的累积奖励；他是不断跟环境交互获取经验，不断进步的过程。通过设计奖励惩罚机制，每正确n步会产生奖励，模型的本质就是获取更多奖励。ALPHAGo、机械手臂、deepseek R1模型都是强化学习实现的。强化学习更像有大脑在思考一样。 对比学习：相当于计算机视觉上的自监督学习，通过随机的图像增强让一张图片随机变成别的样子，但是还属于同一类，这样来代替打标签的操作，同类越相似的思想。如果数据增强变成了核心，数据越离谱学到的东西可能就越多，越花里胡哨效果越好。 监督学习输入的特征都是独立同分布的，独立说的是每次抽样之间相互独立，没有影响，比如掷2次骰子的和大于8，第二次的结果和第一次相关，就不是独立的；同分布说的是每次抽样的样本服从同一个分布，比如掷骰子，每次得到任意点数的概率都是1/6。
1.2.1 强化学习算法 1.2.1.1 Proximal Policy Optimization(PPO)算法 核心思想：PPO 主要改进了策略梯度方法（如 REINFORCE）和信赖域策略优化（Trust Region Policy Optimization, TRPO），使其更加稳定、高效，并且易于实现。其核心思想包括：
克服策略更新的不稳定性： 在策略梯度方法中，策略的更新可能会导致较大的变化，从而影响学习稳定性。 TRPO 通过优化约束（KL 散度约束）限制策略更新的幅度，但实现较为复杂。 PPO 采用了一种更简单且高效的方法，即 剪辑（Clipping）策略比率 来约束策略的更新幅度。 使用信赖区域（Trust Region）控制策略更新幅度： PPO 通过 目标函数中的剪辑项 限制策略的更新步长，从而避免策略发生剧烈变化，提高训练稳定性。 PPO 的两种变体：
PPO-Clip（剪辑版 PPO）： 直接对策略比率（ratio）进行剪辑，确保策略不会更新过大。 目标函数： $L^{clip}(θ)=E[min⁡(r_t(θ)A_t,clip(r_t(θ),1−ϵ,1+ϵ)A_t)]$ 其中： $r_t(θ)= \frac{\pi_{\theta}(a_t | s_t)}{\pi_{\theta_{\text{old}}}(a_t | s_t)}$（新的策略与旧的策略的比率） $A_t$ 为优势函数（Advantage Function） ϵ 是超参数（通常设为 0.1~0.2） PPO-Penalty（KL 散度惩罚版 PPO）： 在优化目标中添加 KL 散度（Kullback-Leibler Divergence）惩罚项，确保策略不会偏离过远： $L^{KL}(θ)=E[L^{clip}(θ)−βD_{KL}[π_{θold}∣∣π_θ]]$ 其中： $D_{\text{KL}}$ 表示旧策略与新策略之间的 KL 散度。 β 是一个超参数，用于调整 KL 惩罚的权重。 1.2.1.2 Q-learning和DQN Q-learing包括2部分，瞬时奖励(做了1个动作就能获得的奖励)和记忆经验奖励(按照训练时的记忆，之后怎么做才能获得更大的奖励)，DQN是对Q-learning的扩展，使用神经网络计算Q-learning函数的参数。
...</p></div><footer class=entry-footer>5 min</footer><a class=entry-link aria-label="post link to 1.机器学习介绍" href=https://wangxiaohong123.github.io/posts/ai/1.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>10.RAG</h2></header><div class=entry-content><p>LangChain LangChain是用来构建大模型应用的框架，相当于python的django、java的Spring。尤其是在RAG领域作用非常大。
RLHF（基于人类反馈的强化学习）</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 10.RAG" href=https://wangxiaohong123.github.io/posts/ai/10.rag/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>2.机器学习基础</h2></header><div class=entry-content><p>机器学习就是模仿人类处理问题，人类是先从经验归纳，机器学习也是自动从数据中获取模型，用模型对位置数据进行预测。白话讲就是从历史数据里找规律，有了规律之后根据输入的数据输出结果，这个规律就是模型。比如说某个样子的物体是猫，那下次看见类似的也可以把他当成猫。
机器学习不能解决的问题，跨域：机器学习学习的是历史数据的特征，新的数据不可能和历史数据有一样的特征分布
1. 计算机视觉 用摄像机、电脑或者其他设备模拟生物视觉，让计算机理解图片或者视频中的内容。可以分为三类：
图像分类：将图像结构化成类别信息，用实现确定好的类别来描述图片。 目标检测：关注特定的物体目标，要求获取这一目标的类别和位置信息，他和分类的区别是，分类将图片当做整体，目标检测可以在一张图片中获取多种目标及位置。 图像分割：分割是在检测的基础上还需要获取像素信息。 应用领域：人脸识别、视频监控、智能驾驶、图片识别（以图搜图，图片鉴黄），比如抖音送礼的眼镜特效属于人脸识别里的人脸关键点定位。
2. 自然语言处理 语言模型是用来计算下一个句子概率的模型。
3 时间序列 时间序列是一种 有序的、依赖时间的结构化数据，其核心任务是研究和预测数据随时间变化的规律。深度学习为时间序列任务提供了更强大的建模工具，尤其是在处理复杂非线性关系或长时间依赖时。他是一个跨领域的问题，还会涉及到统计学等。
3. 机器学习的工作流程： 获取数据->对数据进行基本处理->特征工程->机器学习(模型训练，也是算法应用的过程)->模型评估，如果模型评估没有达到要求需要从对数据进行基本处理重新进行一遍。
3.1 获取数据 拿到的数据类似于表格，一行就是一个样本，一列就是一个特征，涉及到判断的列不叫特征，叫目标值，不是所有数据都有目标值。数据分为训练数据和测试数据，一般比例为3/7或者2/8。
3.2 数据基本处理 修改数据的空值、异常值、类型转换等。
3.3 特征工程 对数据的进一步处理。包括特征提取(比如将文本或者图片转换成可以用于机器学习的数字)，特征预处理(通过一些函数将数据转换成适合算法模型的特征数据)和特征降维(降低特征个数)。
3.3.1 特征预处理 将数据转换成机器更好识别，更好处理的数据。当特征数据的单位或者大小相差较大，或者某个特征的方差相比其他的方差大出好几个数量级，这种情况可能这个特征对结果的影响比较大，使得算法无法学习到其他特征。
3.3.1.1 归一化 把原始数据映射到某个区间内，默认0~1。计算公式为： $$ X’ = \frac {x - min}{max - min}\
X’’ = X’ * (mx - mi) + mi $$ 上面的公式中，X’‘就是归一化处理后的特征值，max和min表示初始特征值的最大值和最小值，mx和mi表示想要将特征值映射到区间的最大值和最小值。
归一化的时候如果出现一条特征统计不正确，比如有1条数据比其他的大了很多倍或者小了很多倍，这种情况对其他数据的影响很大，所以这种方法鲁棒性较差，只适合精确小数据场景。
1 2 3 4 5 6 7 8 9 import pandas as pd from sklearn.preprocessing import MinMaxScaler data = pd.read_csv('./data/dating.txt') # 实例化转化器 transfer = MinMaxScaler(featrue_range=(3, 5)) # 将目标列转换到指定区间，这里是3~5 ret_data = transfer.fit_transform(data[["列1名称", "列2名称"]]) print("转化后的数据:\n", ret_data) 3.3.1.2 标准化 1 2 3 4 5 6 7 8 9 10 11 import pandas as pd from sklearn.preprocessing import StandardScaler data = pd.read_csv('./data/dating.txt') # 实例化转化器 transfer = StandardScaler() # 将目标列转标准化 ret_data = transfer.fit_transform(data[["列1名称", "列2名称"]]) print("转化后的数据:\n", ret_data) print("每一列的方差为:\n", transfer.var_) print("每一列的平均值为:\n", transfer.mean_) 第一步就是去均值，将平均值变成0，然后在比上标准差，这样能让所有维度的数相差不大：$X’ = \frac{x - avg}{\sigma}$。
...</p></div><footer class=entry-footer>5 min</footer><a class=entry-link aria-label="post link to 2.机器学习基础" href=https://wangxiaohong123.github.io/posts/ai/2.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>3.机器学习算法</h2></header><div class=entry-content><p>距离度量 一些算法会需要距离度量，比如K近邻、SVM、聚类等，距离有4个特性：
非负性：两点的距离不能小于0； 同一性：两点的距离=0说明时同1个点； 对称性：x到y的距离时0时，y到x的距离也是0； 直递性：dist(i,j)&lt;=dist(i,k) + dist(k,j); 常见的距离公式：
欧式距离：两个点就是勾股定理，n个点就开根号n； 曼哈顿距离：曼哈顿距离是当两个点不能练成直线时的距离，计算公式：$\sum_{k=1}^n\vert X_{k}-X_{k-1} \vert$； 切比雪夫距离：类比于国际象棋中的国王走棋的方式，国王可以在一个步长内向任何方向移动，两点的距离公式为$D(P,Q)=max(\vert x_1−x_2\vert,\vert y_1−y_2\vert,…,\vert x_n−x_{n+1}\vert)$​； 闵氏距离：闵氏距离是将上面3个变成了1个公式，当p=1的时候是曼哈顿距离，p=2的时候是欧式距离，p>=3的时候是切比雪夫距离 1 K近邻算法 根据最近的距离判断类别，最近的样本数据是什么类别，你就是什么类别，这里的样本数量可以取n个。也叫KNN算法。
求两个坐标的距离使用勾股定理，多维也是一样的。
比如现有数据：
电影名 搞笑镜头 拥抱镜头 打斗镜头 电影类型 功夫熊猫 39 0 31 喜剧片 叶问3 3 2 65 动作片 二次曝光 2 3 55 爱情片 代理情人 9 38 2 爱情片 步步惊心 8 34 17 爱情片 谍影重重 5 3 57 动作片 美人鱼 21 17 5 喜剧片 小鬼当家 45 2 9 喜剧片 唐人街探案 23 3 17 唐人街探案时测试数据，上面的事样本数据，需要判断唐人街探案是什么类型的电影时，就要先求出唐人街探案距离每个电影的距离：
...</p></div><footer class=entry-footer>8 min</footer><a class=entry-link aria-label="post link to 3.机器学习算法" href=https://wangxiaohong123.github.io/posts/ai/3.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>4.tensorFlow</h2></header><div class=entry-content><p>PyTorch和TensorFlow是深度学习框架，但它们也具备科学计算库的特性。
Tensorflow TensorFlow是谷歌的深度学习框架，可以用在计算机视觉、音频处理、推荐系统、自然语言处理等场景。向下支持做的很烂，现在用的少。
一、安装 mac(m1/m2)安装：
1 2 3 4 5 6 # 如果提示Could not find a version that satisfies the requirement tensorflow-macos (from versions: none)升级pip python3 -m pip install --upgrade pip pip3 install tensorflow-macos # 苹果为支持 M1/M2 芯片上的图形加速，提供的插件 pip3 install tensorflow-metal 其他版本安装：
1 2 3 4 # CPU版本 pip3 install tensorflow # GPU版本 pip3 install tensorflow-gpu 验证安装结果：
...</p></div><footer class=entry-footer>10 min</footer><a class=entry-link aria-label="post link to 4.tensorFlow" href=https://wangxiaohong123.github.io/posts/ai/4.%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>5.神经网络</h2></header><div class=entry-content><p>所有的神经网络都是为了提取特征。
神经网络就是把多个线性回归和逻辑回归组合到一起。由一个输入层、一个输出层和n个隐藏层组成，第n层的每个神经元和第n-1层的所有神经元相连，第n-1层的输出就是第n层的输入。每个隐藏层有n个神经元，每个神经元都有一个非线性激活函数。
神经网络的精度高，效果好；但是训练时间长，小数据集上表现不好。他的本质是摆脱人为干预的特征提取(黑盒)，我们只负责输入，查看输出，这就是端对端模型(end-to-end)，深度学习中只有极小值没有极大值。
正向传播：从输入层–>隐藏层–>输出层的过程，是根据数据损失函数和激活函数得到模型的输出结果和损失函数的值。 反向传播：从损失函数开始，逐层向后传播误差(链式法则)，并计算每个参数的梯度的过程，然后用优化器更新权重和偏置，让损失主键减小。 计算图：描述张量之间运算关系的有向无环图，节点是变量（输入、权重、偏置、激活函数、输出），边是数学运算（加法、乘法、激活函数等）。为了高效计算梯度的。 一、损失函数 也叫代价函数、目标函数、误差函数。默认作用在监督学习的输出层，但是在多任务训练、对抗训练等，损失函数也可以作用在隐藏层或中间层。
损失函数 = 数据损失 + 正则化惩罚，数据损失就是预测值和真实值的差异。损失函数中一般会带着偏执(常量)，偏置跟输出挂钩，一般几分类就会有几个偏置。
log函数可以表示预测值为1的时候损失为0，同事预测值越不准损失越大，所以一般数据损失函数都用log表示。
GPT-4的损失函数中有1.8万亿个权重参数，涉及到生活的很多方面。
1. 数据损失函数 1.1 分类任务损失函数 1.1.1 交叉熵损失函数 多分类的交叉熵：多分类的输出层使用softmax函数，损失公式：$ L = -\frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} y_{i,k} \cdot \log(\hat{y}{i,k})$，N是样本数量；K是类别数量；$y{i,k}$ 是第 i 个样本在第 k 个类别上的真实标签（1 表示属于该类别，0 表示不属于）； $\hat{y}_{i,k}$ 是第 i 个样本在第 k 个类别上的预测概率，就是模型输出的预测结果。
二分类的交叉熵：二分类的输出层使用sigmoid函数，损失公式：$L = -\frac{1}{N} \sum_{i=1}^{N} \Big(y_i \cdot \log(\hat{y}_i) + (1 - y_i) \cdot \log(1 - \hat{y}_i)\Big)$，参数和多酚类一样。sigmoid函数的趋势是近似平行x轴的，会导致梯度消失。
1.2 回归任务损失函数 1.2.1 MAE损失 也叫L1 Loss，以绝对误差作为距离。具有稀疏性，也可以作为正则化添加到其他loss中作为约束。他的梯度在0点不平滑，容易跳过最小值。公式：$L = \frac{1}{N} \sum_{i=1}^{N} \left| y_i - \hat{y}_i \right|$
...</p></div><footer class=entry-footer>3 min</footer><a class=entry-link aria-label="post link to 5.神经网络" href=https://wangxiaohong123.github.io/posts/ai/5.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>6.计算机视觉(CV)介绍</h2></header><div class=entry-content><p>图像是由长度、宽度、颜色通道组成的矩阵，一般是3个通道RGB，每个通道有多个像素点，像素点的值是0到255，这个数值表示的是亮度，比如0就是最暗-黑色，255是最亮-白色。
计算机视觉的挑战：部分遮掩(比如模型识别不出来被遮住头的猫)，背景混入(无法识别和背景颜色相似的目标)。
一、主要流程 1. 数据采集与预处理（Data Acquisition & Preprocessing） 获取高质量的视觉数据，并进行规范化处理。比如图像/视频采集、数据增强（如翻转、旋转、缩放）、数据标准化（如均值归一化、缩放到 [0,1]）、去噪、去模糊。常用工具OpenCV、Pillow（PIL）、Albumentations。
常用的开源基准数据集有2种，VOC和COCO，里面包含了一些人、动物、物品等带b标注图片。
2. 特征提取（Featrue Extraction / Backbone） 从原始图像中提取有代表性的特征，经典网络VGG、ResNet、MobileNet、Darknet。输出的是高维的特征图。
3. 特征表示与学习（Featrue Representation & Learning） 对特征进行降维或压缩、将特征输入到分类器或检测器中、学习特征与任务目标之间的映射关系。常见模型：
分类任务：Softmax 分类器 检测任务：RPN（Region Proposal Network） 分割任务：上采样模块（如 U-Net 中的 Decoder） 4. 任务特定头（Task-Specific Heads） 根据不同任务设计不同的网络头（Head）。常见任务头：
图像分类：全连接层 + Softmax 目标检测：边界框回归 + 分类头 语义分割：像素级分类头 实例分割：目标检测头 + 分割头（如 Mask R-CNN） 5. 推理与后处理（Inference & Post-processing） 将模型的输出转换为可解释的结果，常见后处理方法：
NMS（非极大值抑制）：去除冗余边界框 Softmax：转换为类别概率 阈值化：过滤低置信度的检测结果 CRF（条件随机场）：优化分割边界 5.1 NMS 非极大值抑制（Non-Maximum Suppression, NMS） 是一种常用于目标检测任务中的后处理技术，主要目的是从多个重叠的候选框（Bounding Boxes）中选择出最佳的框，减少冗余框，确保每个目标只保留一个检测框。流程：
对所有候选框按置信度分数进行降序排序。 选择当前置信度最高的框，将其加入保留框列表 Keep 中。 计算当前选择的框与所有剩余框之间的IoU。 对于与当前框 IoU 大于设定阈值（例如 0.5）的其他框，将它们从候选框列表中移除。因为这些高重叠的框很可能指向同一个目标，保留多个会导致冗余。 从剩余的候选框中，选择下一个置信度最高的框，重复步骤 2 → 3 → 4。 如果目标靠的太近可能造成误删，改进版有Soft-NMS(调整置信度而不是直接丢弃框)和Multi-Class NMS(针对不同类别分别进行 NMS)。
...</p></div><footer class=entry-footer>6 min</footer><a class=entry-link aria-label="post link to 6.计算机视觉(CV)介绍" href=https://wangxiaohong123.github.io/posts/ai/6.%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>7.目标检测</h2></header><div class=entry-content><p>目标检测首先需要有一个类型的集合，只能检测集合中的类型，并且他会检测出图片中所有属于集合中的类型和位置。坐标可以使用极坐标或者中心点坐标表示。
模型的评价指标有2种：
IoU(交并比)，检测结果和测试数据真实结果的交集/检测结果和真实结果的并集。 mAP：IoU没有衡量检测类型准确性的指标，他是用精确率和召回率组成的PR图的面积表示。 不管是单阶段提交算法还是两阶段提交算法都会产生多个候选框。
2. 两阶段提交算法 相比于单阶段多了一个预选操作，速度慢，效果好，适合离线检测。
2.1 overheat 使用固定宽高的矩形区域滑动窗口，将窗口扫描的结果送到神经网络分类和回归。这种类似于穷举，会消耗大量算力，并且他的窗口大小固定，结果不是很准确。
2.2 R-CNN 引入区域建议概念，将目标检测分为候选区域提取 → 特征提取 → 分类三步：
候选区域提取：使用Selective Search(SS)算法在图像上生成约 2000 个候选区域（Region Proposals）。 特征提取：将每个候选区域送入 CNN（如 AlexNet）中提取特征。 分类：将提取的特征送入**SVM（支持向量机）**进行分类。 边界框回归：使用回归器优化边界框的位置。 他的分类是传统机器学习而不是神经网络。缺点：每个候选区域都要单独经过CNN处理，速度慢；很多候选区域重叠，特征提取存在重复计算。
2.3 fast R-CNN 改进点：
使用全图卷积避免对每个候选框单独卷积，将候选区域映射到特征图上； 通过 ROI Pooling 将不同大小的候选区域转换为固定大小； 使用全连接层同时进行分类和边界框回归； 2.4 faster R-CNN 改进点：使用RPN代替SS生成候选框。他是一个端到端的寻量模型，我们只需要提供训练数据和对应的标签，调用预定义好的训练脚本即可，不关心模型的细节（如学习率、优化器、损失函数、中间特征层的设计等）。
2.5 Mask-Rcnn 3. 单阶段提交算法 单阶段检测的速度快，精度低，适合实时检测，比如自动驾驶、无人机目标检测等。YOLO和SSD都是端到端的模型。
3.1 YOLO 将输入的图片分成n个小格子，每个格子作为中心点，并且给2个尺寸的候选框，然后计算2个候选框的IOU和置信度，首先抛弃置信度过低的候选框，如果候选框没有被抛弃就选择IOU大的候选框进行微调，微调就是调整长宽，让他能够圈住检测的物体。微调的过程就是回归，所以YOLO的核心思想就是计算IOU+回归任务。如果最后的结果中1个点有很多预选框重叠了就采用NMS保留置信度最高的。
V1版本：有很多缺点，因为全连接层要求输入的特征树是固定的，所有V1版本的YOLO要求输入的图像大小是固定的；并且多个物体重叠或者物体过小时很难检测； V2版本：舍弃Dropout，每层卷积后增加了Batch Normalization。因为V1使用224 * 224的分辨率进行训练，比较小，V2版本在训练完之后使用448 * 448的图片进行10次微调。V2中先验框的大小使用聚类算法确定，而不是写死的，数量也从2个变成5个。 V3版本：改进了网络结构，更适合小目标检测，去掉了池化层，通过残差网络实现3种scale，分别对应大、中、小3种目标。 V4版本：训练数据上增加了一些随机处理，比如翻转，遮盖，马赛克，DropBlock等；使用标签平滑方式(类别不设置成1，比如虽然是狗但是也要设置成0.95的狗+0.05的猫)防止过拟合；使用CIOU代替IOU；增加注意力机制、特征金字塔等； 3.2 SSD 使用多尺度特征图进行预测，从不同尺度的特征图中检测不同大小的物体。在多个卷积层上进行预测，每层生成一组边界框和类别置信度。精度比YOLO高。
YOLO适合实时检测小物体，更适合视频分析、图像分类。
3.3 DETR 基于transformer的算法，没有NMS，没有预选框。但是训练很慢，而且对输入的特征有限制，不能很大。
3.4 DeformableDert 解决了DETR的输入特征限制和训练速度问题。
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 7.目标检测" href=https://wangxiaohong123.github.io/posts/ai/7.%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>8.自然语言处理-nlp</h2></header><div class=entry-content><p>标准数据集GLUE：由纽约大学、华盛顿大学和google联合推出的涵盖11个子任务的NLP数据集。
文本的标签太多，打不完；文本模型不是聚焦某个场景，更重要的是培养模型的学习能力，自监督更合适；有监督容易过拟合，不能做迁移学习，适合做一些针对性的事，自监督适合解决领域通用的问题。
一、文本预处理 1 基本方法 1.1 分词 精确模式：把句子精确的切开，适合文本分析。
1 2 3 4 5 6 7 import jieba content = "工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作" # cut_all是False表示精确模式 print(jieba.lcut(content, cut_all=False)) # ['工信处', '女干事', '每月', '经过', '下属', '科室', '都', '要', '亲口', '交代', '24', '口', '交换机', '等', '技术性', '器件', '的', '安装', '工作'] 全模式：把句子中所有可以成词的词语都扫出来，不能消除歧义
1 2 3 4 5 6 7 import jieba content = "工信处女干事每月经过下属科室都要亲口交代24口交换机等技术性器件的安装工作" # cut_all是False表示精确模式 print(jieba.lcut(content, cut_all=True)) # ['工信处', '处女', '女干事', '干事', '每月', '月经', '经过', '下属', '科室', '都', '要', '亲口', '口交', '交代', '24', '口交', '交换', '交换机', '换机', '等', '技术', '技术性', '性器', '器件', '的', '安装', '安装工', '装工', '工作'] 搜索引擎模式：在精确模式的基础上对长词再次进行切分，提高召回率。
...</p></div><footer class=entry-footer>4 min</footer><a class=entry-link aria-label="post link to 8.自然语言处理-nlp" href=https://wangxiaohong123.github.io/posts/ai/8.nlp/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>9.大模型微调</h2></header><div class=entry-content><p>大语言中的大型主要体现在参数规模和训练数据量，一般参数规模达到1B(10亿)量级才叫大模型，只有达到这个量级才会有机遇Scaling law的涌现现象，涌现现象是大模型的魅力，有点像初中物理学的液态变固态。
模型的参数数量跟显存占比的计算，以OPT-6.7B举例：OPT-6.7B就是6.7Billion个参数，假设参数的类型是Float16，即每个参数占用16位（2字节）的显存。总显存占用=参数总量×每个参数的显存占用。总内存 = 67亿 * 2 = 134亿字节。转换成GB就是134亿 / 1024 / 1024 / 1024 = 12.5GB的显存。
使用大显存的GPU加载整个模型可以加快训练速度，部署时也可以提高响应速度，但是可以只使用CPU+内存的方式训练或者部署，只不过这种方式的训练很慢，因为训练时需要大量的矩阵相乘操作。但是使用部署后的模型只是一个前向传播操作，CPU+内存的方式不会比GPU慢很多，除非是有并发量的批量推理，GPU的优势会很明显。
现在是一个信息过载的时代，搜什么都会出现一堆，大模型工具的使用可以帮助我们筛选出有用的信息
模型分类：自回归(CAUSAL_LM，文本生成任务，比如GPT)、序列分类(SEQ_CLS，情感分析、文本分类)、token级分类(TOKEN_CLS，命名实体识别NER)、问答任务(QUESTION_ANS)
大模型应用4个阶段 1提示词工程 面向的是终端用户，大模型时代的沟通手段，通过提示词从大模型挖掘知识。就是如何通过对话框跟大模型更好交流。大模型都是概率模型，很多能力他都没有，比如数学运算，但是我们可做到通过描述让他理解。这也是为什么基于注意力机制的模型很容易回答错误一个描述很复杂的小学数学应用题。
2AI智能体（AI Agent） 基于ReAct范式，就是大模型自主判断应该使用哪些工具，比如chatGPT+联网搜索。分为3类：
行动代理（Action agents）：自主决定使用工具，比如OpenAI的Function Call； 模拟代理（Simulation agents）：通常设计用于模拟角色扮演，在模拟的环境中运行，比如生成式智能体，CAMEL。以后可能会应用在游戏领域，类似于美剧西部世界； 自主智能体（Autonomous agents）：独立执行实现长期目标，比如Auto-GPT，manus（国产的，好像是Claude套壳）。 基于大模型开发应用的开发人员，比如自动客服，虚拟助手。
3大模型微调（Fine-tuning） 在预训练模型的基础上，使用较小的数据集进一步训练来调整模型参数。当有和目标相关的较小的数据集，并且希望模型在这个任务上表现更好的时候使用。
未来是面向基础模型编程。
4预训练技术（Pre-training） 使用大量的未标记数据（比如维基百科内容）来训练一个初步的模型，为后续的微调提供基础模型。适合有资源的大厂，有大量的数据集，数据清洗做的好，然后大力出奇迹。
能自己预训练模型的都是顶级大厂，因为需要的资源实在是太大了，比如LLaMA-65B就需要780G显存。
RAG 把我们从外部拿到的数据通过处理之后变成向量数据库中的知识。
微调技术路线 20年之前大家都不知道怎么去做微调，OpenAI发表了一篇论文提出调整prompt，让模型能更好的理解输入也能有很好的效果，再加上几年之后的文生图让prompt被大家熟知。
但是prompt有个缺点就是相同的prompt换一个模型或者换一个语言描述效果就会差很多，不管是在LangChain里或者在应用的对话框中都有这个问题。
全量微调（FFT）：所有系数都进行调整，原来的VC相关的模型用的多一点，训练成本高，容易造成灾难性遗忘。 高效微调（PEFT）：分为有监督微调（SFT）、基于人类反馈的强化学习（RLHF）、基于AI反馈的强化学习（RLAIF）。 PEFT 高效微调技术：Adapter Tuning(2019 Google) -> Prefix Tuning(2021 Stanford) -> Prompt Tuning(2021 Google) -> P-Tuning V1(2021 TsingHua, MIT) -> P-Tuning V2(2022 TsingHua, BAAI )
传统的模型微调是很容易的，比如分类的卷积网络中可以直接选择冻结卷积层，训练softmax层直接增加类别，2018年google的bert出来之后模型就已经不是CNN那种神经网络了，都是在叠加transformer的层数，整个模型看起来又宽又高，包括到今天的大语言模型中，哪部分参数干了哪些事也是未知的。
...</p></div><footer class=entry-footer>5 min</footer><a class=entry-link aria-label="post link to 9.大模型微调" href=https://wangxiaohong123.github.io/posts/ai/9.%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>