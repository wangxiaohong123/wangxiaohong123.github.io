<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Kafka | 王小红的笔记</title><meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/categories/kafka/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangxiaohong123.github.io/categories/kafka/index.xml><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/categories/kafka/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=/katex/katex.min.css><script defer src=/katex/katex.min.js></script><script defer src=/katex/auto-render.min.js onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script><meta property="og:url" content="https://wangxiaohong123.github.io/categories/kafka/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="Kafka"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Kafka"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Kafka</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>7.kafka源码-producer初始化</h2></header><div class=entry-content><p>producer初始化 初始化producer，直接new KafkaProducer就可以，初始化的代码都在这个类里：
1 KafkaProducer&lt;String, String> producer = new KafkaProducer&lt;>(Properties); 在这个构造方法里首先把我们配置的Properties转成ProducerConfig，kafka自己的配置文件，这个文件里有所有的Producer配置和默认值，还有一些属性的名字和注释在CommonClientConfigs里：
1 2 this(new ProducerConfig(ProducerConfig.addSerializerToConfig(properties, keySerializer, valueSerializer)), keySerializer, valueSerializer, null, null); 然后调用另一个构造方法初始化核心组件：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 KafkaProducer(ProducerConfig config, Serializer&lt;K> keySerializer, Serializer&lt;V> valueSerializer, Metadata metadata, KafkaClient kafkaClient) { try { // 我们自己的配置 Map&lt;String, Object> userProvidedConfigs = config.originals(); this.producerConfig = config; this.time = Time.SYSTEM; // 获取client.id属性，默认是空串 String clientId = config.getString(ProducerConfig.CLIENT_ID_CONFIG); if (clientId.length() &lt;= 0) // 空串的话会走到这里，producer-自增数字作为clientId，线程安全的 clientId = "producer-" + PRODUCER_CLIENT_ID_SEQUENCE.getAndIncrement(); this.clientId = clientId; // 核心组件，用来决定你的消息会发送到那个topic的那个分区里的 this.partitioner = config.getConfiguredInstance(ProducerConfig.PARTITIONER_CLASS_CONFIG, Partitioner.class); // retry.backoff.ms，重试间隔，默认100ms long retryBackoffMs = config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG); // 序列组件 if (keySerializer == null) { this.keySerializer = ensureExtended(config.getConfiguredInstance(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, Serializer.class)); this.keySerializer.configure(config.originals(), true); } else { config.ignore(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG); this.keySerializer = ensureExtended(keySerializer); } if (valueSerializer == null) { this.valueSerializer = ensureExtended(config.getConfiguredInstance(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, Serializer.class)); this.valueSerializer.configure(config.originals(), false); } else { config.ignore(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG); this.valueSerializer = ensureExtended(valueSerializer); } // 拦截器组件 userProvidedConfigs.put(ProducerConfig.CLIENT_ID_CONFIG, clientId); List&lt;ProducerInterceptor&lt;K, V>> interceptorList = (List) (new ProducerConfig(userProvidedConfigs, false)).getConfiguredInstances(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, ProducerInterceptor.class); this.interceptors = new ProducerInterceptors&lt;>(interceptorList); ClusterResourceListeners clusterResourceListeners = configureClusterResourceListeners(keySerializer, valueSerializer, interceptorList, reporters); // max.request.size，每个请求的最大大小，默认1M this.maxRequestSize = config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG); // buffer.memory，缓冲池大小，默认32M this.totalMemorySize = config.getLong(ProducerConfig.BUFFER_MEMORY_CONFIG); this.compressionType = CompressionType.forName(config.getString(ProducerConfig.COMPRESSION_TYPE_CONFIG)); // max.block.ms缓冲区满了的阻塞时间，默认一分钟，超过1分钟会抛出异常 this.maxBlockTimeMs = config.getLong(ProducerConfig.MAX_BLOCK_MS_CONFIG); // request.timeout.ms，请求超时时间，默认30s this.requestTimeoutMs = config.getInt(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG); this.transactionManager = configureTransactionState(config, logContext, log); // 这个应该是重试次数 int retries = configureRetries(config, transactionManager != null, log); int maxInflightRequests = configureInflightRequests(config, transactionManager != null); short acks = configureAcks(config, transactionManager != null, log); this.apiVersions = new ApiVersions(); // 核心组件，缓冲池 this.accumulator = new RecordAccumulator(logContext, config.getInt(ProducerConfig.BATCH_SIZE_CONFIG), this.totalMemorySize, this.compressionType, config.getLong(ProducerConfig.LINGER_MS_CONFIG), retryBackoffMs, metrics, time, apiVersions, transactionManager); // broker地址 List&lt;InetSocketAddress> addresses = ClientUtils.parseAndValidateAddresses(config.getList(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG)); // 核心组件，维护broker的元数据信息 if (metadata != null) { this.metadata = metadata; } else { this.metadata = new Metadata(retryBackoffMs, // metadata.max.age.ms，默认5分钟强制刷新一次 config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG), true, true, clusterResourceListeners); // 如果metadata是空需要拉取一下元数据 this.metadata.update(Cluster.bootstrap(addresses), Collections.&lt;String>emptySet(), time.milliseconds()); } ChannelBuilder channelBuilder = ClientUtils.createChannelBuilder(config); Sensor throttleTimeSensor = Sender.throttleTimeSensor(metricsRegistry.senderMetrics); // 核心组件，网络通信组件，这里初始化了一个selector KafkaClient client = kafkaClient != null ? kafkaClient : new NetworkClient( new Selector(config.getLong(ProducerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG), this.metrics, time, "producer", channelBuilder, logContext), // 这个是元数据的信息，负责元数据的增改，唤醒主线程 this.metadata, clientId, // max.in.flight.requests.per.connection，同时发送的消息数 // 这个最大就是5 maxInflightRequests, // reconnect.backoff.ms，重新建立连接的等待时长 config.getLong(ProducerConfig.RECONNECT_BACKOFF_MS_CONFIG), // reconnect.backoff.max.ms，建立连接的最大时长 // 连接失败的时候会重试，每次间隔reconnect.backoff.ms成倍增加，直到超过max.ms config.getLong(ProducerConfig.RECONNECT_BACKOFF_MAX_MS_CONFIG), // send.buffer.bytes，# 发送缓冲区的大小 config.getInt(ProducerConfig.SEND_BUFFER_CONFIG), // receive.buffer.bytes，接收缓冲区的大小 config.getInt(ProducerConfig.RECEIVE_BUFFER_CONFIG), // request.timeout.ms，发送的超时时间 this.requestTimeoutMs, time, true, apiVersions, throttleTimeSensor, logContext); // 核心组件，负责把缓冲池里的消息发送到broker上 this.sender = new Sender(logContext, client, // 这个是元数据的信息，负责元数据的增改，唤醒主线程 this.metadata, this.accumulator, maxInflightRequests == 1, // max.request.size单次请求的最大字节 config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG), acks, // 重试次数 retries, metricsRegistry.senderMetrics, Time.SYSTEM, // 发送的超时时间 this.requestTimeoutMs, // retry.backoff.ms，重试的最大时间 config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG), this.transactionManager, apiVersions); // 线程名：kafka-producer-network-thread|clientId String ioThreadName = NETWORK_THREAD_PREFIX + " | " + clientId; // 把sender放到线程里，启动 this.ioThread = new KafkaThread(ioThreadName, this.sender, true); this.ioThread.start(); } catch (Throwable t) { close(0, TimeUnit.MILLISECONDS, true); throw new KafkaException("Failed to construct kafka producer", t); } } 看拉取元数据的方法：
...</p></div><footer class=entry-footer><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;5 min</footer><a class=entry-link aria-label="post link to 7.kafka源码-producer初始化" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/7.producer%E5%88%9D%E5%A7%8B%E5%8C%96%E6%BA%90%E7%A0%81/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>8.kafka源码-producer发送消息</h2></header><div class=entry-content><p>初始化完成后就可以调用producer的send方法了，先看异步发送，传进一个ProducerRecord类型的消息体和一个回调函数，最终调用到KafkaProducer的doSend方法：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 // 调用doSend之前会使用拦截器在处理一下record private Futrue&lt;RecordMetadata> doSend(ProducerRecord&lt;K, V> record, Callback callback) { TopicPartition tp = null; try { // 这里要获取topic了，同步阻塞 ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs); long remainingWaitMs = Math.max(0, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs); Cluster cluster = clusterAndWaitTime.cluster; // 把key和value都进行序列化 byte[] serializedKey; try { serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key()); } catch (ClassCastException cce) { throw new SerializationException("Can't convert key of class " + record.key().getClass().getName() + " to class " + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() + " specified in key.serializer", cce); } // value就是消息的body byte[] serializedValue; try { serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value()); } catch (ClassCastException cce) { throw new SerializationException("Can't convert value of class " + record.value().getClass().getName() + " to class " + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() + " specified in value.serializer", cce); } // 根据topic信息获取对应的分区 int partition = partition(record, serializedKey, serializedValue, cluster); tp = new TopicPartition(record.topic(), partition); setReadOnly(record.headers()); Header[] headers = record.headers().toArray(); // 统计消息大小 int serializedSize = AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(), compressionType, serializedKey, serializedValue, headers); // 检查消息是否超过了设置的大小上限和是否超过了缓冲区的大小上限 ensureValidRecordSize(serializedSize); long timestamp = record.timestamp() == null ? time.milliseconds() : record.timestamp(); log.trace("Sending record {} with callback {} to topic {} partition {}", record, callback, record.topic(), partition); // producer callback will make sure to call both 'callback' and interceptor callback // 设置自定义回调和拦截器的回调 Callback interceptCallback = new InterceptorCallback&lt;>(callback, this.interceptors, tp); if (transactionManager != null && transactionManager.isTransactional()) transactionManager.maybeAddPartitionToTransaction(tp); // 把消息放到缓冲里 RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptCallback, remainingWaitMs); // 这里就是判断如果一个batch满了或者创建了一个新的batch，就要唤醒sender线程，发送消息 if (result.batchIsFull || result.newBatchCreated) { log.trace("Waking up the sender since topic {} partition {} is either full or getting a new batch", record.topic(), partition); this.sender.wakeup(); } // 返回futrue对象 return result.futrue; // 下面是一大堆异常处理，基本上每一个步骤都会自定义一个自己的异常，在这层捕获进行处理 // 一般中间件的异常捕获处理之后也会抛出去 // 如果是业务代码要在业务的最顶层进行捕获处理，根据异常返回给前端对应的提示 } catch (ApiException e) { log.debug("Exception occurred during message send:", e); if (callback != null) callback.onCompletion(null, e); this.errors.record(); this.interceptors.onSendError(record, tp, e); return new FutrueFailure(e); } catch (InterruptedException e) { this.errors.record(); this.interceptors.onSendError(record, tp, e); throw new InterruptException(e); } catch (BufferExhaustedException e) { this.errors.record(); this.metrics.sensor("buffer-exhausted-records").record(); this.interceptors.onSendError(record, tp, e); throw e; } catch (KafkaException e) { this.errors.record(); this.interceptors.onSendError(record, tp, e); throw e; } catch (Exception e) { // we notify interceptor about all exceptions, since onSend is called before anything else in this method this.interceptors.onSendError(record, tp, e); throw e; } } 同步阻塞获取topic KafkaProducer的waitOnMetadata方法有三个参数，topic、partition、maxWaitMs，topic和partition是在发消息时候设置的，maxWaitMs是初始化producer的时候配置的max.block.ms，最开始是简单配置一下然后判断缓存：
...</p></div><footer class=entry-footer><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;11 min</footer><a class=entry-link aria-label="post link to 8.kafka源码-producer发送消息" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/8.producer%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>9.kafka源码-读取响应</h2></header><div class=entry-content><p>之前看到过producer的连接、发送、读取消息都是在Selector的poll方法中，跟进去之后看到读取消息在attemptRead()方法中：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 private void attemptRead(SelectionKey key, KafkaChannel channel) throws IOException { // 如果channel连接正常，并且关注了读事件或者有缓冲池中有消息可以读取 // hasStagedReceive(channel)，这个是一个暂存队列，没搞懂，可能防止重复读取 // explicitlyMutedChannels.contains(channel)这个会判断一个list中是否有这个channel，但是没看到插入的动作，所以这个判断一直是true if (channel.ready() && (key.isReadable() || channel.hasBytesBuffered()) && !hasStagedReceive(channel) && !explicitlyMutedChannels.contains(channel)) { NetworkReceive networkReceive; // 开始读取 while ((networkReceive = channel.read()) != null) { madeReadProgressLastPoll = true; // 往上面的暂存队列里插入这个channel // 在poll方法的最后一行会把channel从stage里移出 addToStagedReceives(channel, networkReceive); } if (channel.isMute()) { outOfMemory = true; //channel has muted itself due to memory pressure. } else { madeReadProgressLastPoll = true; } } } 进到kafkaChannel的read()方法里：
...</p></div><footer class=entry-footer><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;5 min</footer><a class=entry-link aria-label="post link to 9.kafka源码-读取响应" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/9.%E8%AF%BB%E5%8F%96%E5%93%8D%E5%BA%94/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>0.参数</h2></header><div class=entry-content><p>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # flower落后几条消息会被踢出ISR列表，默认4000（0.9之前） replica.lag.max.messages # 超过多长时间没保证消息同步会被踢出ISR列表，默认10s（代替上一个） replica.lag.time.max.ms # 日志文件的大小上限（默认1G） log.segment.bytes # 日志达到所少会创建索引数据（默认4k） log.index.interval.bytes # 日志文件保存时间（默认7天） log.retention.hours # processor线程数 num.network.threads # 全局队列长度 queued.max.requests # handler线程池大小 num.io.threads # 达到多少数量从os cache刷盘 log.flush.interval.messages=10000 # 每隔多久刷一次盘 log.flush.interval.ms=1000 # 定时重新选举leader，默认300s auto.leader.rebalance.enable=true # 发送缓冲区的大小，-1是默认 send.buffer.bytes # 接收缓冲区的大小，-1是默认 receive.buffer.bytes</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 0.参数" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/0.%E5%8F%82%E6%95%B0/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>1.kafka原理</h2></header><div class=entry-content><p>数据写入，如何保证单机每秒几十万 微批处理技术：spark streaming这种流式计算的时候会使用这种思想，收集数据后统一处理，提高吞吐量，比如9ms可以收到1000条数据，然后花1ms写入磁盘，这样只花10ms就可以处理完1000条数据，要比收到一条就花1ms写一条快100倍（1000条 * 1ms = 1s）。
使用微批处理提高吞吐还是会有一定的延迟，但是kafka可以保证高吞吐，低延迟，kafka通过os cache + 磁盘顺序写实现高吞吐低延迟，写os cache和磁盘顺序写的性能基本上和写入内存差不多，假设0.01ms写一条数据，那么1s就可以处理10万条数据。
零拷贝实现高性能读取 正常从把消息发送给客户端需要先从os cache中读取数据，如果os cache中没有就去从磁盘里读取，这步是需要从用户态切换到内核态的，然后把数据拷贝到应用进程的内存，在从内核态切换回用户态，把数据拷贝到socket cache中，在发送给网卡把数据发射出去，多余的是两次用户态和内核态之间的切换，和两次拷贝：
kafka使用linux的sendfile，直接把数据从os cache发送给网卡，非常高效：
消息存储 kefka使用NIO的ByteBuffer一二进制的方式保存消息，比java对象保存方式节约40%的空间，每条消息时封装在log entry中，可以理解成一个消息条目，首先会有一个消息集合（record batch）的概念，里面包含多个日志，每个消息集合会记录自己的offect和总消息大小、创建时间戳等信息，具体的消息格式：
消息总长度 时间戳增量：相对于所属的record batch的增量 offset增量：相对于所属的record batch的增量 key长度 key：用来做消息负载均衡使用 value长度 value header个数 header：自定义的消息元数据，key-value格式 时间戳和offset都是采用增量的方式存储，可以减少磁盘空间的占用。每个topic会把消息均匀的存储到每个partition上，每个partition也会有一个冗余副本。
每个分区会在自盘上有一个对应的目录，格式是topic-分区号，例如：order-topic-0。每个分区的日志会被拆成多个，并且每个日志文件有自己的索引文件：
00000000000005367851.index
00000000000005367851.log
00000000000005367851.timeindex
.log是存放数据的，文件名是起始的offset，.index是位移索引，另一个是时间戳索引。每个文件的大小可以通过log.segment.bytes（默认1G）配置，达到参数大小会重新创建一个文件，这个过程叫log rolling，正在被写入的文件叫active log segment，其他的日志文件叫log segment file。当日志写入达到一定大小的时候会在索引文件写入一条索引，通过log.index.interval.bytes（默认4k）配置，索引是按照位移和时间戳升序，这样可以使用2分查找快速定位数据。
数据默认保存7天，通过log.retention.hours设置。
ISR（in-sync replica）机制 靠partition的多副本机制可以保证高可用，但是不能保证消息不丢失，kafka会维护一张ISR列表，只有和leader的消息是同步的flower才会出现在这个列表中，如果leader宕机，会从ISR列表中的flower选举一个leader，ISR要求最少有一个flower和leader的消息同步，并且消息要同时在leader和flower都写成功才算成功。
在0.9版本之前，通过replica.lag.max.messages（默认4000）设置那些flower会被踢出去，但是这样会有一个问题，就是在高并发的时候，如果1s内并发上完，所有flower都不满足这个条件就会被踢出去，等到flower同步之后又来一万，所有flower就又会被踢出去，一直这样反反复复。在0.9之后使用replica.lag.time.max.ms（默认10秒）替代之前的配置，表示超过多少秒flower还没完成同步就把他踢出ISR列表。
LEO（log end offset）和HW（high watermark） 不管是leader还是flower都是副本，每个副本都有一个leo和hw，leo表示当前消息的结束偏移量，也就是下一新条消息的偏移量，hw表示能被消费到的消息的偏移量，每个leader会存储所有flower的leo值，当flower来fetch消息的时候会带上自己的leo，leader更新维护的flower的leo，返回自己的hw，flower拿到返回的leo和自己的取小，更新本地的hw。
leader切换时的数据丢失1：高水位（非常极端的场景）：
比如说broker往leader里写入一条数据，flower进行同步成功，但是第一次拉取数据leader返回的HW是0，所以flower的HW还是0:
等到下一次去fetch数据的时候，leader判断flower的LEO和自己的一样就会更新HW，然后返回，当flower收到响应还没更新的时候宕机重启了，此时会根据HW调整LEO，LEO变成了0，刚要从leader哪里fetch数据，结果leader宕机了，此时flower被选举成新的leader，然后旧leader重启，fetch数据后发现leader没有数据，就会把自己的消息也删掉。
leader切换导致数据丢失2：数量巧合
假设flower比leader落后10条消息，此时leader宕机，flower被选举成新leader，在收到10条消息后，leader重启变成flower，fetch数据的时候发现HW相同，就会以为数据是同步的。。。这样不止会丢掉10条消息，leader的新10条消息还没有同步，这样消息时错乱的。
0.11.x的leader epoch机制
0.11.x新增了一个epoch，里面是自己当leader时的版本号和消息的offset，比如刚启动的时候是[epoch:0,offset:0]，如果flower重启看到自己没有epoch是不会截断数据的，直接去更新，只有当发现自己的offset比leader大的时候才会删除数据，这样可以解决高水位的消息丢失问题，对于第二种情况，他会leader重启之后变成flower，发现自己的offset是1，但是新的leader是从1开始写的，所以判定自己多了一条数据，就会截断这条数据，并不能解决数据丢失，但是最起码数据不是乱的。
broker 生产者/消费者和broker使用基于nio的长连接通信，broker和broker之间使用自定义的tcp协议通信。每个broker上都有一个acceptor线程和多个processor线程（默认3个），processor通过nio的selector轮询多个连接，收到请求后发送到一个全局队列，队列大小是500，可以通过queued.max.requests设置，队列由KafkaRequestHandler线程池消费，处理完结果会放到processor自己的响应队列中，通过processor返回响应。
controller controller负责broker的宕机感知、新节点、选举、负载均衡迁移等等，broker启动的时候回向zk发送注册临时节点的请求，zk可以保证只有一个broker能成功，谁先注册成功谁就是controller，然后controller监听zk上的broker信息变更，他会把zk上的信息拉取到本地，取出第一个作为leader，然后分配每个partion在那台机器上，然后在把所有的flower写到ISR列表里，最后把所有信息推送给所有broker。
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 1.kafka原理" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/mq/kafka/1.%E5%8E%9F%E7%90%86/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://wangxiaohong123.github.io/categories/kafka/>«&nbsp;Prev&nbsp;</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>