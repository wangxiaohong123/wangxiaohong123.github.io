<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>面试专题 | 王小红的笔记</title><meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/categories/%E9%9D%A2%E8%AF%95%E4%B8%93%E9%A2%98/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangxiaohong123.github.io/categories/%E9%9D%A2%E8%AF%95%E4%B8%93%E9%A2%98/index.xml><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/categories/%E9%9D%A2%E8%AF%95%E4%B8%93%E9%A2%98/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://wangxiaohong123.github.io/categories/%E9%9D%A2%E8%AF%95%E4%B8%93%E9%A2%98/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="面试专题"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="面试专题"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>面试专题</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>HBase</h2></header><div class=entry-content><p>他是一个基于HDFS的nosql。强一致性，适用于海量数据的简单增删改查。
hbase里每行数据都有一个rowkey，表里的数据按照rowkey排序。每列都有自己的列族，猎德命名就是列族:列名，比如order:base，每个数据的值都有自己的时间戳，一个时间戳下的一个单元格数据就是一个cell。他是列式存储，大概是这样：
rowkey timestamp 列 值
order_1_001 t1 order:base xxxx
order_1_001 t2 order:detail yyyy</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to HBase" href=https://wangxiaohong123.github.io/posts/%E9%9D%A2%E8%AF%95/hbase/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>分布式搜索引擎</h2></header><div class=entry-content><p>1.es原理(es是如何实现分布式的) 首先每个节点都有primary shard和replica shard，写数据只能写到primary shard上，读数据可以从primary和replica shard上读。
写数据的时候会随便选择一个协调节点，协调节点通过hash值把请求路由到具体的primary shard所在机器，然后primary shard把数据写到内存的indexing buffer，同时在OS cache中记录trans log，然后同步数据给replica shard，这个时候就可以返回成功了，但是数据还不能被查到。 每秒会有一个refresh操作：再OS cache中新建一个segement file，把indexing buffer刷到segement file中并建立好倒排索引，然后清空indexing buffer，这个时候数据才能被查询到，所以es是准实时的；OS cache中的trans log每5秒会被刷到硬盘中，所以默认情况下es可能会最多丢失5s的数据；当trans log太大或者每半个小时会执行一次flush操作，记录一个commit point然后把trans log清空。 删除的时候会把删除的数据写进del文件，当segement文件太多之后会进行merge操作，把segement文件合成一个大文件，这个时候会把del文件中的数据物理删除。
查询的时候也是根据id计算出数据在那个shard上，然后找对应shard查找，搜索的时候会查找所有shard把符合条件的document的id都返回到协调节点上，然后协调节点在根据doc id去查找对应document再进行筛选，最后返回结果。
2.在大数据量的情况下如何提高查询效率 es的查询优化是没有银弹的！
首先在查询数据的时候，会先去cache中找，如果没有再把磁盘的数据读到filesystem cache中，然后把结果返回，下次再来查找的时候会直接把cache中的数据返回，所以filesystem cache的大小对查询的速度影响是最大的。如果走磁盘的话基本就上秒了。所以要把更多的内存给cache，并且尽可能减少es的document的field大小，就把要用来检索的字段存到es中。检索出来的数据的id再去MySQL或者hbase中查完整的数据。
如果数据量还是很大，可以统计热数据，每隔一段时间主动查询一下热数据，让热数据一直在OS cache中。
在模型设计的时候要避免多次查询，一些join操作把涉及到的数据存到一个document中。
他的分页性能非常差，需要把数据都拿到协调节点上，然后排序，在分页操作，比如查询10000~10010的数据，他会从每个shard中都查询出来10010条数据进行排序然后找到10000~10010的数据，所以翻页越深，性能越差。如果是上拉加载更多那样的可以用scroll api。
3.生产环境的es部署架构？每个索引有多大？每个数据多少个分片？ 我们生产环境部署了3台16g机器，48g的总内存，es进程每个不到8g，OS cache差不多有20多个g。日增数据量差不多八十万条，日增的数据大约120多兆，每个月增量数据大概两千多万，2g左右，两个索引，每个索引6个shard。
4.分词器的二次开发 下载ik分词器源码，然后添加MySQL依赖，然后编写MySQL连接代码，还有查询分词、停用词代码，最后在Dictionary类中添加一个addStopWord()方法，不断查询MySQL调用Dictionary的addStopWord()和addWords()方法就可以了。</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 分布式搜索引擎" href=https://wangxiaohong123.github.io/posts/%E9%9D%A2%E8%AF%95/9.%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>消息队列</h2></header><div class=entry-content><p>1.用过消息队列吗？ 在项目里用的队列，大部分的场景是解耦和异步，比如充值完会员会发送一条消息，如果以后增加系统的币种，会员会有对币种的逻辑处理、会员积分这些东西直接消费会员的消息就可以了，不需要改接口。
我们系统里用户是有个收发瓶子次数的限制，很多场景都可以导致这个次数发生改变，比如开通会员、后台手动操作修改用户状态，这些对实时性要求不高的业务可以使用mq进行异步处理，减少接口响应时间。
如果有大量写但是对实时性要求不高的需求也可以使用mq来进行肖峰。
还有一些一些日志系统、数据同步系统也需要用到消息队列。
缺点 mq出问题这个功能就蹦了。需要多维护一个服务或者框架来处理mq挂掉之后的处理逻辑； 一致性问题，分布式系统的cap理论：高可用，强一致性，分区容错性（在时限内到一致性）只能满足两个，mq就舍弃的强一致性； 重复消费啊、顺序消费导致结果纠错了，丢消息，消费者挂掉会有大量的消息积压等等，解决这些问题还会让系统更复杂。 2.各个消息队列区别（如何选型？） activeMQ：我没用过，官方好像不维护了，要不就是很不活跃，如果用他的话有bug可能就要靠自己了，印象里吞吐量很低；
rabbitMQ：吞吐量比kafka和rocketmq低，可以在小项目里用，但是源码是erlang的，java程序员看不了，但是社区很活跃，不怕采坑的。集群不好扩展但是管理界面功能非常全；
kafka：吞吐量是最高的，但是功能不多，kafka持久化消息时异步写入，有人说会丢消息，其实配置成同步写入是不会丢消息的，只不过会严重影响性能，一般日志采集，大数据分析服务用的多，因为丢一条两条无所谓，如果kafka要保证消息不丢首先broker要设置acks=-1，然后insync.replicas > 副本数-1，最后关闭自动提交ack；
rocketMQ默认就是集群模式，配置简单，源码是java的，容易扩展，nameserver和broker通信用的是netty。
3.如何保证消息的高可用？ kafka：分布式集群，他会把topic分出多个partition，每个机器存储对应partition上的消息，如果要保证HA的话每个partition需要有多个副本，这些副本有一个leader和多个follower，只有leader进行读写，leader宕机之后会选举出新的leader。用他自己的controller模块加zk实现的选举。
rocketmq：默认就是集群模式，他通过message queue把消息均匀分在每个集群节点上，每个master都有slave，4.5版本之前如果master宕机那么只能手动切换master，4.5版本之后使用Dledger进行主备切换。
如果考虑mq集群可能全部不可用的情况还需要在mq上包装一层自己的代码，当发现集群都不可用的时候需要把消息存到本地或者redis里，然后有一个单独的线程定时轮询发送失败的消息尝试发送搭配mq中。
4.如何保证消息不被重复消费 很多操作都会导致重复消费，比如MQ设置消息最少发一次，有的时候没有提交偏移量就会导致消息重复消费，或者在rocketMQ里以消息组为单位消费，只要有一条消费失败，拉取的所有消息都被标记成失败，过一会会重新发过来，这里面的消息就有消费成功的，或者消费中突然宕机或者重启，一般就是使用redis的setnx或者zk的分布式锁或者数据库唯一索引。kafka是基于zk实现的offset。
5.怎么保证消息可靠性(消息丢失)？ 生产者去写消息的过程中，网络传输过程中可能会丢失、mq收到消息后还没持久化到磁盘就挂了、消费者没有处理完但是mq以为处理完了结果消费者挂了或者处理失败(关闭自动提交ack，rocketmq没有这种机制)。
5.1rocketmq全链路消息不丢失方案：
首先发送消息使用rocketmq的事务消息或者同步发送加重试检测，超过次数回滚业务逻辑；
然后broker采用同步刷盘(flushDiskType=SYNC_FLUSH)，主从同步复制(brokerRole=SYNC_MASTER)；
最后消费者同步消费业务逻辑，最后返回处理结果，需要注意重复消费问题；
6.顺序消费 7.消息积压 新建几十个消费者，把原来的消费者的消费逻辑改成重新发送到新partiotion中，让几十个消费者去消费，前提是数据库能承受住，消费完了在把消费者换回来。
8.设计一个消息中间件 首先在存储上要分片存储，队列的消息均匀分布在每个节点上，多个消费者平均的绑定n片，分片之间需要考虑主从选举、主从心跳等等。同时要实现两种刷盘方式，使用mmap顺序写磁盘，所以还需要一个队列存储consumer消费的offect，客户端和broker之间使用netty通信，客户端和broker之间也需要心跳。
rocketmq 发送消息机制 通过message queue把数据分片，均匀存储在broker上。相当于的kafka的partition。producer会定时访问nameserver获取broker信息，发送消息时，会通过负载均衡计算出应该发送到那个message queue上，然后发送请求给对应的broker，如果master宕机，在等待主备切换的时候，是无法往这个broker中发送消息的，结果只能是发送失败或者超时，所以要设置sendLatencyFaultEnable，设置了这个参数后，在发送超时或者失败时会回避访问这个broker一段时间，将消息发送到其他broker。
存储消息 rocketmq的消息存储是在一个commit log中，每个文件最大1g，为什么是1g？因为mmap在生成文件映射的时候限制文件大小为1.5到2G之间。收到消息后会在log文件后追加消息，然后添加到OS cache中，当配置为同步刷盘时，会马上把OS cache的消息刷到consumer queue中，consumer queue中存储的是消息在log文件中的偏移量，每个message queue对应多个consumer queue，和多个commit log。一般会把brokerRole设置成SYNC_MASTER，这样会同步复制master的消息，而flushDiskType根据情况，如果是订单、金额相关的就设置成SYNC_FLUSH，允许丢数据的就设置成ASYNC_FLUSH。
选举和消息同步 选举和消息同步都是通过DLedger + raft协议实现的，在启动或者master宕机时，每个broker都会进行投票，但是每个broker都会给自己投票，然后把结果发送给其他broker，一个master 宕机，还有两个slave，他们刚开始都给自己投票，这时每个slave都会有一票，然后进入随机睡眠，先醒的那个会继续投票，还是给自己，其他broker醒了之后收到选举消息会比对日志，谁的日志新就投给谁，只要有一半 + 1个broker投票给同一个broker就会选出来新的master。
消息同步也是基于raft协议实现的：
消费数据 消费数据有两种模式，pull和push，但是这两种模式都是consumer主动去拉取，push模式下，发送请求给对应的broker，然后broker从consumer queue中拿到上次消费消息的偏移量，去commit log中获取对应的消息，如果没有新消息，请求线程会睡眠15，后台线程一直检查commit log，有新消息后唤醒睡眠的线程，返回消息。拉取数据时是可以从master上拉取，也可以从slave上拉取，其实commitLog和consumer queue都是经过OS cache去刷盘的，commitLog使用OS cache来提高写速度，而consumer queue使用OS cache提高读写速度，因为他很小，所以几乎所有的consumer queue都是在缓存中，这样读写都是缓存级的，很快，而commitLog文件比较大，不可能全部加载到缓存中，缓存中只是刚刚收到的消息还没刷盘的，所以除非消费速度很发消息速度差不多，否则拉取消息只能读取磁盘数据了，这个会比读取磁盘慢很多，而且当master感知到读取的速度落后很多，就会认为是自己负载过高，会让消费者下次去slave broker中拉取数据。
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 消息队列" href=https://wangxiaohong123.github.io/posts/%E9%9D%A2%E8%AF%95/7.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>面试-1.复习方案</h2></header><div class=entry-content><p>知识体系： 1.java必备技术： 数据结构和算法：手写算法，中级以下难度。 并发编程：线程通信、偏向锁、锁升级、底层原理。突击就看面试资料，平时就看书。 网络与IO：NIO、BIO。 jvm：原理和调优。 MySQL：原理和调优。 Spring：源码。 Netty：源码（不一定会问）。
2.分布式架构：服务注册发现、rpc调用、分布式事务、分布式锁、接口幂等、限流熔断等 spring cloud alibba：dubbo、sentinel、seata、nacos 微服务技术体系：日志、监控、链路、配置、治理：顺带问一下，也可能问开发、测试、上线流程，代码质量检查、codereview。
先问技术栈，dubbo要会源码，其他最少知道原理，面试重点。 分布式事务、分布式锁、幂等的方案，项目里如何做的，为什么。
3.常用中间件，问的浅了也是原理 消息：RocketMQ、kafka（源码） redis：内核原理，数据库双写、读延期冷热分离、分布式锁串行转并发、热key自动探测、本地缓存降级、大value自动监测和拆分、缓存雪崩、压测数据报告。 分库分表：shardingSphere：全量数据如何同步，增量数据如何同步，终端恢复，并发冲突，代码优化，数据迁移完成之后如何无损发布，线上扩容和运维。 es：原理，分词器的二次开发，现有数据的导入优化。
项目 先把项目的业务流程、技术架构、生产部署整体讲一遍，然后在问一些生产数据。比如为什么要引用这个技术，怎么选型的，如何落地，引入这个技术是否会遇到新的问题，你觉得你解决过的最大的难题，如果以后遇到XX问题你会如何解决或者并发涨到100倍你觉得会出现那些瓶颈，你会如何解决。
架构设计和系统设计和架构演进：设计一个系统比如双11大促。</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 面试-1.复习方案" href=https://wangxiaohong123.github.io/posts/%E9%9D%A2%E8%AF%95/1.%E5%A4%8D%E4%B9%A0%E6%96%B9%E6%A1%88/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>面试-12.面经</h2></header><div class=entry-content><p>滴滴 介绍一下最近的项目
RocketMQ的事务消息原理：
上游服务会发送一条half消息，broker将half消息存储到commit log中，此时真正topic中的消息状态为prepared，同时也会将消息id存储到sys_trans_half_topic中。上游服务执行完业务会发送commit或者rollback消息，如果是commit消息就把消息放到真正的topic中，并且在commit log中将消息标记为commit，此时消息就可以被正常消费了。如果是rollback消息就把commir log中的消息标记为rollback。broker会定时轮询sys_trans_half_topic，如果有消息长时间没有没有收到commit或者rollback消息会回调上游服务，根据业务判断应该会滚还是提交。事物消息的状态在LocalTransactionState枚举类中。
MySQL的事务原理以及怎么实现脏读隔离级别。
事物有4个特性：原子性，隔离性，持久性，一致性
mysql中使用undo log保证一致性，当有sql失败时通过undo log执行会滚操作；使用mvcc+锁机制实现隔离性，使用redo log+bin log+双写缓冲区实现持久性，原子性+隔离性+持久性保证了一致性。
算法题：力扣第200题，岛屿数量
贝壳 mysql B+树的结构:
B+树的根节点在内存中，子节点存储多个键值对，key是索引值，value是下一级子节点的指针，每个叶子节点就是一个数据页，数据页由file header、page header、行数据、空闲大小、当前页最大行最小行记录、file trailer等组成，file header中有上一页信息，file trailer中有下一页信息。
mysql为什么一个数据页有16k:
操作系统读取磁盘的最小单位是蔟，为4k，所以如果要按照数据页加载数据到内存必须要为4k的倍数，默认一个数据页是16k可能因为mysql觉得16k的数据可以满足大部分的sql。
dubbo怎么自定义负载均衡策略:
自定义负载均衡类继承AbstractLoadBalance或者LoadBalance，并重写doSelect方法，之后在resource.dubbo下创建文件org.apache.dubbo.rpc.cluster.LoadBalance，文件中配置name=类的全限定名。之后在配置文件中指定
1 2 3 dubbo: consumer: loadbalance: name linkedBlockingQueue原理
linkedBlockingQueue中使用两把可重入锁来实现阻塞，调用take方法时会判断队列的长度是否为0，如果为0就进入wait()，put时判断队列是否已满，满了就进入wait()。
redis查询慢语句
首先开启slowlog-log-slower-than(超过多少纳秒算慢)和slowlog-max-len(慢日志存储条数)，使用slowlog get命令查询慢日志。
线程之间怎么通信
共享变量 等待通知机制，wait+notify 阻塞队列：一个线程将数据放到队列中，另一个线程从队列中取 使用join函数等待另一个线程之行结束 Semaphore的acquire()+release()获取和释放信号量 如何在dubbo启动provider成功之后发送邮件通知
自定义一个类实现ExporterListener接口，类上添加注解@Activity(group = “provider”)，在exported方法中编写发送邮件逻辑。
手撸带权重的轮询算法
rocketmq如何保证消息的顺序性
发送消息的方式必须是同步。发送消息时需要重写MessageQueueSelector的select方法，保证需要顺序消费的消息发送到同一个message queue中。消费者MessageListenerOrderly而不是MessageListenerConcurrently。
当使用MessageListenerOrderly消费消息时rocketmq会自动产生3把锁：
1.定时向broker申请分布式锁，申请到锁的消费者才会拉取消息消费；2.消费时需要获取本地锁，获取本地锁成功之后才会执行消费逻辑，这是为了防止多线程消费时的乱序；3.还需要一把额外的锁来控制message queue被分配给新的consumer时存在消费者正在消费且没提交偏移量导致的顺序问题。
发生broker宕机时无法保证顺序性，顺序消费性能较差，存在消息消费失败时只能不断重试消费而不能跳过。
长春合众地产 jvm动态加载类的方式
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 面试-12.面经" href=https://wangxiaohong123.github.io/posts/%E9%9D%A2%E8%AF%95/12.%E9%9D%A2%E7%BB%8F/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>面试-3.网络</h2></header><div class=entry-content><p>1.通过浏览器请求百度的时候会发生那些事情 上面的图是1次握手的流程，完成3次握手之后就开始真正的发送请求了，流程是一样的。
2.TCP三次握手过程 上面的数据都是放到TCP包头中的。
第一次握手，客户端发送带有SYN(SEQ=x)和ACK=0的连接请求报文，ACK=0说明这是个连接请求，接着客户端处于SYN-SENT状态，等待服务器响应。 第二次握手，服务端收到SYN=1的请求报文，需要返回一个SYN + ACK(ack = x + 1，seq = y)的确认报文，自己处于SYN-RECV状态。 第三次握手，客户端收到了报文，将ACK(ack = y + 1)返回给服务器，进入ESTABLISHED状态。 为什么不能是2次或者4次握手？，如果是2次握手，第一次握手服务端没收到，客户端在等了一会发现服务端没有响应就重试发送握手请求，重试的那次成功了之后正常请求数据，过了一会服务端收到了失败的那次握手请求，然后开辟资源返回响应，等待客户端发送请求，客户端收到后并没有找到对应的一次握手响应，就不会管，此时服务端会等待，浪费资源，如果是3次握手客户端不认识二次握手的请求还是会发送第三次握手给服务端，通知服务端释放资源。3次握手已经够用了，不需要4次了。
3.TCP四次挥手过程 第一次挥手，客户端发送报文，FIN=1(seq=x)，此时进入FIN-WAIT-1状态 第二次挥手，服务端收到报文，这时候进入CLOSE_WAIT状态，返回一个报文，ACK(seq=x + 1)。客户端收到这个报文之后，直接进入FIN-WAIT-2状态，此时客户端到服务端的连接就释放了。 第三次挥手，服务端关闭和客户端的链接并且发送FIN=1(seq=y)的报文，服务端进入LAST-ACK状态 第四次挥手，客户端收到连接释放报文之后，发应答报文，ACK(seq=y + 1)，进入TIME_WAIT状态，服务端收到报文之后就进入CLOSED状态，客户端等待一会发现没有收到服务端的回应确定连接已经关闭进入CLOSED状态。 为什么是4次挥手 服务端或者客户端是全双工通信，可以互相发送消息，在关闭链接的时候必须要确认双发都没有要发送的消息，前两次挥手就是客户端没有要发送的数据，请求关闭链接，如果服务端还有没发送完的数据，会先发送数据，发送完之后会发送第三次挥手。
4.socket网络编程和TCP IP协议的关系(socket网络编程的工作原理) socket是基于传输层的一个编程规范，然后再说一下封包、建立连接过程。
5.http1.0和1.1、2.0有哪些区别 http1.0默认是短连接，比如打开一个网站，请求一张图片就需要3次握手+请求资源+4次挥手。需要指定keep-alive开启持久连接。
http1.1默认是长连接，就是说打开网站后底层的tcp会保持一段时间的连接，不会马上断开，默认30s。1.1开始支持host头，意思就是支持虚拟主机。
http2.0支持多路复用，解决1.1同一时间对同一域名请求限制问题。支持将数据拆成更小的帧，比1.1更 低延迟。
6.https加密原理 常用的加密算法：
非对称加密：RSA；对称加密：AES、RC4；hash算法就是MD5；
原理：
浏览器访问服务器，告诉服务器自己支持哪些加密算法； 服务器选择加密算法，返回证书，证书中包含网站地址，加密公钥，证书颁发机构等； 浏览器收到证书后验证证书的颁发机构和时间是否合法，如果合法，在地址栏会出现一把小锁头； 浏览器生成一串随机密码，并使用公钥加密，生成一段消息（内容就随便了），把消息进行MD5加密（hash值），用随机密码把消息加密，然后把加密后的消息、has值、加密后的随机密码发送到服务器； 服务器收到消息先把公钥加密后的随机密码拿出来使用私钥解密，然后在用得到的随机密码解密消息内容，根据消息内容生成MD5的值，和接收的hash值对比，如果一样就保存这个随机密码。 服务器在用这个随机密码加密一段消息返回给浏览器，如果浏览器能用随机密码解密，就说明可以和服务器进行加密通信，之后的请求响应就都会使用随机密码加密解密； 最开始使用的是非对称机密，也就是公钥、私钥，后来的通信使用的都是对称加密。
7.http实现长连接的底层原理 http的长短连接说的就是底层的TCP的长短链接，就是建立连接之后不马上释放，之后的请求都是用这个连接。http的长连接不常见，一般都是网页加载资源什么的。
8.mmap和零拷贝 8.1普通IO操作的流程 首先操作系统有一块缓冲区叫做OS cache，JVM也有一块缓冲区叫做用户缓冲区，还有两种状态叫做用户态和内核态，用户态就是JVM级别的操作，内核态就是操作系统级别的操作，用户态和内核态切换就是上下文切换。
普通IO时，先从用户态切换到内核态，使用DMA引擎把要读取的文件从磁盘文件拷贝到OS中去，然后在从内核态切换到用户态，使用CPU引擎把OS中的文件拷贝到用户缓冲区，到此为止发生了两次的上下文切换、两次拷贝，如果后面是socket发送数据，他会在发生一次用户态到内核态的切换，使用CPU拷贝把文件从用户缓冲区拷贝到socket缓冲区，然后在用DMA拷贝把文件从socket缓冲区拷贝到网络协议引擎发送出去，然后就切换回用户态了，这就发生了四次切换、四次拷贝。
8.2mmap mmap技术跟普通的IO操作相比会少一次拷贝，他并不是把OS中的文件拷贝到用户缓冲区，而是建立一个映射，之后如果还需要拷贝就会根据映射找到OS中的文件进行操作，不过上下文切换次数没变，RocketMQ中就是使用的mmap提升磁盘读写。
8.3零拷贝原理 零拷贝相比mmap，不会建立映射，在第一次切换和拷贝之后，把数据的offset直接放到socket缓冲区中，然后socket把数据的offset给网络引擎，网络引擎直接去OS中拷贝数据，最后切换回用户态，这样只有两次切换，两次拷贝。
9.java的3个io BIO：一个socket客户端和一个服务端socket建立连接就要创建一个线程去处理客户端的消息，这个线程在链接期间是不能销毁的，这样就很容易把资源打满，服务器就死了，同步阻塞的。 NIO：不是线程直接监听socket消息，而是出现了一个多路复用器的概念，叫selector，每接入一个socket客户端的时候selector就会创建一个channel，然后它不断的去轮询channel，发现有消息了就创建一个线程去执行，处理的结果会放在一个缓冲池中，channel会自己去buf pool中读取数据返回给客户端，所以当把数据写到缓冲池中之后这个线程就被销毁了，这时候就可以创建线程池让selector去使用。因为读channel里的数据然后交给工作线程这块是同步的(他会一直轮训，如果channel里没有数据会一直空轮训，占这个线程一直占用资源)，同步非阻塞的。 AIO：和NIO非常像，只不过在多路复用器读取channel中的数据的时候是把数据放在工作线程的缓冲区，然后就结束啦，工作线程自己去缓冲区读取，所以AIO是异步非阻塞的。 这个同步阻塞什么的不是完全针对网络通信的，说的是磁盘IO读写，同步阻塞的说得就是比如BIO，FileInputStream去读取文件，在文件读取完成之前就会卡住；而是用NIO的FileChannel去读取的时候就可以干别的了，但是他还是同步的，因为你需要隔一段时间去轮询看看有没有读完，所以NIO是同步非阻塞；AIO是不需要轮询看读没读完，操作系统读完了之后会回调告诉你读完了。
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 面试-3.网络" href=https://wangxiaohong123.github.io/posts/%E9%9D%A2%E8%AF%95/3.%E7%BD%91%E7%BB%9C/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>面试-4.MySQL</h2></header><div class=entry-content><p>1.MyISAM和InnoDB的区别 MyISAM不支持事务，不支持外键，索引文件和数据文件分开，并且他没有行锁。
InnoDB有自己的redo log，他要求必须要有一个自增的主键，如果我们没有指定他会自己生成一个，默认情况会有一个根据主键的B+树索引，叫做聚簇索引，这个索引的叶子节点就是数据文件。
2.索引为什么不用二叉树、平衡二叉树、B树，而是使用B+树 二叉树容易造成节点不平衡，影响查找速度；就算他改成了平衡二叉树，深度太大也会影响查找速度；B树的子节点也会存储数据，因为MySQL的数据页是16k固定大小，如果子节点存储数据，那么他能存储的子节点个数就会变少(子节点的个数也叫阶数)，也会影响深度，B+树就是让这个索引结构更矮更胖，深度减少相对的磁盘IO就会减少。
B+树种的叶子节点有两个前后指针，让叶子节点组成了一个双向链表，这像排序和范围查也更快。
2.1 B+树能存储多少数据 以深度为3的B+树举例，首先算出第二层子节点的个数=16k / (6b + 8b)，其中6字节是指针大小，8字节是表的主键为bigint类型，得到第二层子节点的个数是1170个，这1170个子节点都会有1170个叶子节点，能够得到叶子节点的个数=1170*1170，假设一行数据是0.5k，如果不考虑数据页的其他信息，每个数据页能够存储16k / 0.5 = 32条数据，所以深度为3的B+树能够存储1170 * 1170 * 32 = 4380万条。
3.事务 事务的特性(ACID)原子性、一致性、隔离性、持久用。可以理解成用原子性+隔离性+持久性来保证一致性，也就是使用AID来保证C。
1）什么是脏读、脏写、不可重复读、幻读 脏写：事务A把id=10的数据对应的列x改成1，此时事务B对id=10的数据对应的列x改成2然后提交事务，然后事务A在执行后面的业务时发生异常把id=10的数据对应的列x回滚成了初始值0，事务B就发生了脏写。 脏读：事务A先读取一次id=10的数据对应的列x，然后去处理其他业务，此时事务B把id=10的数据对应的列x的值改成NULL，但是没有提交事务，然后事务A又回来读取一次id=10的数据对应的列x发现和之前的值不一样，事务A发生了脏读。 不可重复读：他和脏读的情况很像，只不过事务B提交了修改id=10的数据对应的列x的事务，此时事务A两次读到的数据是不一样的，我觉得这种情况可以算问题，也可以不算。 幻读：由于其他事物增加或者删除了一些数据，导致在同一个事物中前后两次查询的结果条数不一致。 2）事务的隔离级别 读未提交：要求可以读到没提交事务的数据，脏读、不可重复读、幻读的问题还在。 读已提交：要求不能读到没提交事务的数据，会有不可重复读和幻读的问题。 可重复读：要求同一事物中多次读取同一条数据一致，会有幻读问题，MySQL里可重复读级别没有幻读问题！ 串行化：只能有一个线程操作数据库。 3）MySQL默认的隔离级别及原理 默认使用可重复读，在MySQL中每个事物的事务id是全局递增的。MySQL使用readView+undo log实现了MVCC(多版本并发控制)机制，在readView中有当前操作这个数据的事务id集合，还有集合中的最大、最小事务id，还有当前事物id，读取数据时会从undo log链里找到第一个创建数据的事务id比当前事务id小的undo log去读取数据；修改的时候会插入一条新的undo log，然后会增加独占锁。这样会保证读取数据的事务不会读到比自己id大的事务操作后的数据。
在MySQL中每条数据会有两个隐藏列，一个是插入数据的事务id，还有一个删除数据的事务id。
4）项目里基于Spring的事务是怎么做的？事务传播是怎么设置的？ Spring的事务有声明式和注解式，现在使用的都是注解式，在需要开启事务的方法上增加@Transactional注解，一般传播属性使用的默认的required_new就可以。如果有业务需要考虑某块代码不需要回滚之类的根据业务设置。
4.优化SQL的步骤 互联网公司的SQL都不会出现join这种，一般都是很简单的SQL，因为SQL的资源很宝贵，可以把复杂查询的操作放到业务里处理。
测试前会统一创建索引，索引不超过4个，多了会影响增删改性能，保证每个SQL都是使用索引，注意索引失效情况(最左匹配原则、查询条件使用函数或者计算、有些时候or、not null、不等于这些关键字也会染索引失效)。 查询时返回的字段尽可能少，第一是为了减少回表(如果查询的字段都在非聚簇索引中就不需要回表)，第二是减少占用网络带宽。 平时需要观察慢SQL，找到对应的慢SQL使用explain分析，保证type在index级别一下，rows尽可能小。 5.in和exists的区别 比如select * from a where id in (select a_id from b where ……)会先执行后面in条件中的语句，select * from a where id exist (select a_id from b where ……)exists先执行前面的语句。
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 面试-4.MySQL" href=https://wangxiaohong123.github.io/posts/%E9%9D%A2%E8%AF%95/4.mysql/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>面试-5.Spring</h2></header><div class=entry-content><p>1.IOC 控制反转：把bean的生命周期由程序员自己控制反转给spring控制；
依赖注入：spring启动时创建bean的实例，程序中不需要自己创建依赖的bean的实例，依靠spring注入进来即可；
2.AOP 面向切面编程，在程序运行中会产生一些横切性问题，比如日志记录、事务的创建和提交回滚，如果不把这些问题统一放到切面里就会耦合到代码里。在Spring中默认情况下，如果是接口的实现类，AOP会使用JDK的动态代理，如果是没有实现接口的类，AOP会使用cglib的动态代理。
3.动态代理 就是动态的创建一个代理类的字节码，里面引用被代理的类，在调用被代理的方法之前或者之后加一些增强代码。通过类加载器把字节码加载到jvm里，然后在通过反射创建代理的对象。
4.spring的bean是线程安全的吗？ spring在启动的时候会创建bean的实例，默认是singleton，有五个作用域：
singleton：默认，单例；
prototype：每个bean的注入会创建一个新的实例；
下面的没用过
request：每次请求创建一个实例；
session：每次回话创建一个实例；
global-session：
refresh：应用上下文配置发生改变时标记示例失效，下次使用会创建新的；
所以默认情况吓spring的bean不是线程安全的，但是在bean里没有什么操作共享数据的代码，所以一般不会造成并发问题，没啥影响。
5.@Autowired和@Resource的区别 首先我觉得他俩既不是使用set()方法注入，也不是使用构造方法注入，而是通过反射直接调用Field.set()注入。当@Resource没有设置name属性的时候，这两个注解都是先根据类型获取，如果获取的Bean超过1个在根据属性名筛选；当@Resource设置了name属性或者检测出容器中有属性名对应的Bean就只根据name获取。
6.Bean的生命周期 Bean的生命周期大概分成6个阶段：
容器初始化：启动BeanFactory，创建扫描器，执行容器的后置处理器，扫描Bean放到beanDefinitionMap里，注册BeanPostProcessor； Bean实例化：推断创建方式(构造方法、Supplier)，实例化Bean(内省)； 属性注入：扫描@Autowired、@Resource进行缓存，创建FactoryBean处理循环依赖，注入属性； Bean的初始化：执行aware接口回调，比如BeanNameAware。执行后置处理器的回调，执行@PostConstruct注解标记方法； Bean缓存：清除创建Bean产生的临时变量，把Bean放到单例池中； Bean销毁：回调@BeforeDestroy方法，从单例池中移除Bean； 7.怎么解决循环依赖 先大概说一下生命周期，然后说一下什么是循环依赖。解决循环依赖主要依靠三级缓存：
第一级单例池：Map&lt;String, Object> singleObjects; 第二级半成品Bean集合：Map&lt;String, Object> earlySingleObjects; 第三级AbstractFactory集合Map&lt;String, AbstractFactory> singleFactories; 然后还要有一个变量标记当前Bean是否正在被创建，当getBean()发现单例池中没有而且这个Bean正在被创建，那就说明发生了循环依赖，这个时候需要把AbstractFactory转成Bean。如果没有这个singleFactories那么转成的Bean是不能被代理的，也就是说如果Bean是AOP的切点，AOP的代码不会生效，转成Bean之后需要放到二级缓存中，执行完剩下的生命周期之后再从2级缓存转移到1级缓存。
如果没有代理其实两级缓存就够用了。
8.@Configuration里的@Bean怎么保证单例性 添加了这个注解的类会被代理，被增强的类执行@Bean标记的方法时会把方法放到threadlocal变量里，如果@Bean方法中调用了第二个@Bean标记的方法，第二个@Bean方法发现当前执行的方法不是自己就不会走本身的逻辑而是去容器中直接获取。
9.事务的传播属性(propagation) REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置；
SUPPORTS：如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行；
MANDATORY：如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常；
REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务；
NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起；
NEVER：以非事务方式执行，如果当前存在事务，则抛出异常；
NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按REQUIRED属性执行；
当两个方法存在调用关系，如果两个方法使用的都是REQUIRED，那么就算调用时使用try包裹被调用方法，内层方法发生回滚时，外层方法也会回滚，比如下面这段伪代码，一条数据都插不进去：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Transactional public void insert1() { // 一条插入 try { insert2() } catch (Exception e) { // 无操作 } } // 另一个类里的方法，同类的话事务注解会失效 @Transactional public void insert2() { // 一条插入 int i = 1/0; } 嵌套事务：外层事务发生异常内层事务会一起回滚，内层事务发生异常外层事务不会滚。如果上面的代码insert2()上面的注解标记了传播行为是NESTED，结果会插入一条insert1()的数据。
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 面试-5.Spring" href=https://wangxiaohong123.github.io/posts/%E9%9D%A2%E8%AF%95/5.spring/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>面试-6.分布式系统</h2></header><div class=entry-content><p>一 认证授权 1.没有cookie的话session还能用吗 cookie的主要作用是保存sessionId，如果没有cookie比如浏览器禁用cookie可以把sessionId保存到别的地方，通过url拼接或者其他参数传过来，如果不想暴露sessionId可以加个密。
2.分布式session方案 1.使用spring session + redis。2.jwt。
3.什么是jwt jwt是基于token的跨域认证解决方案。jwt由3个base64编码字符串以’.‘拼接组成：
header：定义签名算法、token类型。 payload：实际数据。 signatrue(签名)：使用header中的签名算法处理header+payload+秘钥生成。 jwt是无状态的，服务端不需要维护，但是无状态就有个问题，jwt一旦生成，在没过期之前都是有效的，比如退出登录、注销用户并不会让旧jwt失效，解决的办法可以在redis里维护一个jwt黑名单，或者使用用户的某些信息作为生成token的秘钥，一旦注销或者退出登录就修改这些信息，这样就jwt就会自动失效。
4.如何防止jwt被篡改 当秘钥没有泄露的时候，如果header和payload被篡改那么生成的签名是不同的，这个时候token验证不会通过，所以要想jwt不被篡改就要保证秘钥不能泄露，同时payload中要包含过期时间，不能让token永久有效。
5.单点登录 单点登录就是登录过一个系统后就有权访问其他相关系统，比如登录淘宝之后可以直接跳转到天猫不需要重新登录。
SSO可以减少用户操作流程，统一的认证中心也让系统开发更方便。
6.如何实现一个SSO系统 单点登录系统不需要维护用户信息，他必须得功能只是生成token、校验token的有效性、解析token。当用户登录成功之后从当前服务端调用SSO系统，验证也是在网关里调用SSO系统。
如果想要实现注销、退出登录时token自动失效需要再数据库维护一个用户id和token的对应关系，存储失效的用户的token，可以定期删除。
7.什么事OAuth 2 OAuth 2是一种授权机制，用来给第三方应用颁发一个有时效的token，常见支付平台、开发平台、或者公司的系统调用内部的认证平台。
二 分布式系统 1.为什么要把系统拆分成分布式的？ 首先如果是单块系统，随着代码越来越多，以后想要修改很容易改出问题，模块之间耦合越来越高，多人开发一个项目，很容易不小心操作别人的表，或者把别人的代码改出问题，如果代码提交到远程仓库发生冲突也不好解决，还有一个，比如说某个模块并发很高，需要加机器，但是代码都在一起，不能单独把摸个模块多部署几台机器。
2.CAP和BASE理论 CAP中的C表示强一致性，A表示高可用，P表示分区容错行，CAP理论说的是分布式系统中只能保证CP或者AP，但是不会有CA。
BASE理论说的是最终一致，软状态和基本可用。软状态说的是不会影响结果的数据的中间状态，比如两个服务都可以查询数据，但是现在网络出现了问题导致一台服务查询不出来。当网络恢复后软状态消失数据还是会最终一致；基本可用说的是当系统出现不可预知的问题的时候可以牺牲一些可用性，比如响应时间增加，或者牺牲掉一些功能。
3.分布式事务 两阶段提交/XA：一般用于一个系统去操作多个数据库，在系统中有个事务管理器的概念，第一个阶段由事务管理器去确定要操作的数据库是否都能成功，如果是，第二阶段就执行操作。在微服务中这种方案是不会被用到的，微服务里每个服务只操作自己的库，不会出现这种情况，操作别的数据库都是调别的服务的接口。 TCC：TCC就是引入了补偿的概念，需要手动实现回滚的代码，某个服务操作失败后将原来插入的数据删除，删除的数据重新插入，实现的逻辑非常复杂，一般用在保证业务绝对不能出错时会使用这种方案，比如资金交易。 本地消息表：这也是一个不太常用的方案，分布式事务的系统都会有一张消息表，比如A系统中调用B系统，A会在逻辑处理结束之后在消息表里插入一条待确认的消息，然后去访问B系统，可以使用mq来访问，B系统在收到消息之后会先插入进消息表，这时候如果消息表已经有了就不会去消费，然后开始业务处理，如果处理成功会调用A系统的接口或者使用zk协调，A系统收到通知后再去修改消息表的状态为完成，A系统会轮询查消息表，找到超时没完成的业务数据在发送给B系统，不断的去重试，不适合高并发，直接写到库里扛不住多少QPS； 可靠消息最终一致性：根据本地消息表改的，只使用mq，去掉了本地消息表，RocketMQ天然支持。可靠消息说得是提交时可靠和rocketmq的高可用，最终一致性说的是失败不会回滚，只会不断重试，A系统首先会提交一条prepared消息到rocketmq里去，在处理完业务后提交一个confirm消息，如果rocketmq长时间没收到confirm消息会去回调A系统，A系统可以选择重新发送或者回滚prepared消息，B系统收到消息后首先要保证幂等，如果消费失败可以回调A系统让他重发或者不提交offect，在重试一定次数还是失败需要标记或者持久化等待人工补偿。 最大努力送达方案：在mq后面可能有一个通知服务，甚至都不需要这个服务，消费的服务只要尝试最大次数就可以了，对一致性要求不严格的话可以使用； 4.核心链路的事务 针对用户可能在公众号充值和在app消费的情况，使用seata的AT事务(画图)，发送漂流瓶同步到动态使用自研的最终一致性框架(画图)。
5.seata的空悬挂、空回滚问题 在seata的tcc事务里，空悬挂说的是try方法的空悬挂，空回滚说的是cancel方法的空回滚，比如在执行try方法时突然卡柱，seata server拿到try方法超时通知执行cancel方法，cancel方法并没有要回滚的数据，出现空回滚，cancel执行完try方法继续执行，此时出现空悬挂产生脏数据的问题。
这个时候可以记录try方法的执行状态，如果没执行完就执行cancel方法就在数据库里插入一条空数据，当try方法操作数据库前发现这条空数据就表示这次事务已经失败，删掉这条空数据结束方法就可以了，同时当confirm或者cancel方法超时的时候seata server会不断发起调用，这个时候需要做好幂等处理。
6.分布式id 分布式方案主要有以下几种：
基于单台数据库单张表主键自增，不能抗住并发。 雪花算法：第0位没意义，1-41位表示时间戳，接着5位机房(集群)id，接着5位机器id，最后12位自增，一台机器每ms可以产生4096个id，他只能保证同一台机器的id自增，就是局部自增，他还有时钟回拨问题。 UUID：很长的字符串，浪费空间，不是自增，存到MySQL中会频繁页分裂。 flicker及其变种：flicker也是基于数据库，要求是个集群，表中有最少2列，id和stub，stub可以代表项目也可以代表业务，通过replace和select last_insert_id获取新的id，这个方案要求自增的步长非常大，比如10000，客户端每次拿到最大id，然后用最大id减掉步长作为最小id，在内存中使用LongAdder这种自增，快用完的时候再去数据库获取，这个方案不支持扩容，并且如果号段没用完就重启造成了号段浪费。 redis自增：他和flicker一样的问题。 业务+时间戳：这个方案最省事，优先考虑。 雪花算法的时钟回调问题：把前半个小时每毫秒每台机器生成的最大的id保存到起来(比如map)，同时需要记录最后一次id，当本次生成的id比上次的id小说明发生时钟回拨，如果发生回调，找到之前生成的最大id继续开始加，每ms都是，直到map里没有说明时间正常了，从1开始加。
雪花算法实现整个分布式全局递增：需要全局递增的业务要保证跨服务每次调用到相同的发号器服务，从nacos获取发号器所有地址，根据业务+dubbo自定义负载均衡路由到相同的发号器。
7.网关的技术选型 我们系统里的网关主要负责请求转发(动态路由)、token认证、用户状态过滤等。
zuul：使用简单，通过自定义过滤器扩展，1版本使用同步IO扛不住并发，2版本好像是使用netty了。 kong：基于nginx+lua，这就相当于一个简单的网关，和系统交互麻烦但是抗高并发能力很强。 gateway：gateway比zuul2更早，也是基于netty，也是自定义过滤器(实现GlobalFilter接口)实现扩展，但是他基于webflux开发，目前不支持数据库的动态路由。 shenyu：他也是基于webFlux开发的Apache开源网关，自带控制台，自带治理功能，使用SPI扩展。 当时考虑我们所有的服务都是统一使用Sentinel进行限流熔断，统一使用sentinel的控制台，所以选择gateway。
8.怎么实现动态路由 首先通过ConfigService监听Nacos上的实力变化，当发生变化的时候发布RefreshRoutesEvent事件，gateway会消费这个事件更新路由。
9.接口幂等性怎么保证？ 出现重试有可能重复下单，首先插入逻辑最好有唯一索引保证，比如扣款记录中的订单id，这样能保证不重复扣款，如果要做统一幂等可以写一个接口执行结束后的拦截器，把post和put请求的所有参数都拼在一起当成一个key，去redis中查找，如果有结果就是重复访问，但是这样实现会有问题，解决不了超时重试的重复问题，而且我项目里并不是所有接口都要做幂等，所以我是在具体的接口中单独耦合的幂等，进入接口的时候redis中set数据，如果失败了就删除redis中的数据然后回滚，成功了就不管。
8.分布式系统中的接口调用如何保证顺序性？ 可以在被调用接口之前加一个接入服务，这个服务负责分发，把需要顺序执行的请求分到同一机器上。
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 面试-6.分布式系统" href=https://wangxiaohong123.github.io/posts/%E9%9D%A2%E8%AF%95/6.%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>面试-8.redis</h2></header><div class=entry-content><p>1.项目里怎么使用缓存，为什么用缓存 用缓存的地方比较多，比如一些读多写少的场景，动态、用户信息、存漂流瓶的池子等等；分布式锁；我还见过推荐系统的用户画像也存到redis里的。
使用redis可以减少数据库的压力(高并发)，还能减少接口的响应时间(高性能)。
2.redis使用不当会有什么问题 2.1.双写不一致问题 比如说获取用户信息的流程是先读缓存，缓存中没有就去数据库中查，然后在写缓存，修改数据库的流程是先改数据库，然后在更新缓存，如果在修改用户的同时有线程去查询用户，这个时候缓存刚好过期，那么就会把旧数据查出来然后放到缓存里，但是这个时候修改数据已经成功，再次把用户的新信息写到缓存中，此刻缓存的数据时没问题的，但是查询用户的线程会把从数据库里拿到的旧数据再次写到缓存中，就会出现问题。
最简单的方法就是加分布式锁，把读和写都加同一把锁，写请求可以把整个操作都加上锁，但是读操作的第一步先去缓存中查找是没有必要加锁的，而且加锁之后会严重影响性能，读操作需要在第二步也就是缓存中没有的话就先去数据库中查找，然后在写缓存，这步和写竞争同一把锁就可以了，还可以在拿到锁之后先去redis中再次查询，这样的double check可以优化上面的场景。 上面的解决方案有个问题就是大量的查询同一个用户的请求过来，这些大量的请求会串行执行，这样的性能也不高，所以可以在加锁的时候设置一个超时时间，如果到时见还没加锁成功就直接查缓存，这个超时转并发可以结局大量相同key读取的性能问题，但是有个问题就是一个写和大量读一起过来还是会有不一致问题，伪代码：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 public User getUserInfo(long userId) { String userInfoKey = ""; String userInfoLockKey = ""; String userString = redis.get(userInfoKey); if (StringUtils.hasLength(userString)) { return JsonObject.parseObject(userString, User.class); } try(加锁) { String userString = redis.get(userInfoKey); if (StringUtils.hasLength(userString)) { return JsonObject.parseObject(userString, User.class); } User user = userMapper.get(userId); redis.set(userInfoKey, user.toString(), 2天+随机几小时); if (加锁超时) { String userString = redis.get(userInfoKey); if (StringUtils.hasLength(userString)) { return JsonObject.parseObject(userString, User.class); } else { return fail; } } } catch(Exception e) { String userString = redis.get(userInfoKey); if (StringUtils.hasLength(userString)) { return JsonObject.parseObject(userString, User.class); } else { return fail; } } } public void updateUser(User user) { try (加锁) { userMapper.update(user); redis.set(userInfoKey, user.toString(), 2天+随机几小时); } catch(Exception e) { return fail; } } 2.2惊群和缓存穿透问题 惊群也叫雪崩就是突然在某个时间点出了一个故障，一堆机器或者线程或者进程被同时惊动，在redis中，比如存在一大批用户的缓存过期时间相同，同一时间点全部过期(加上过期时间是为了冷热分离，长时间没人访问的用户信息没必要存在缓存中)，这个时候查询这批用户的请求会全部打到MySQL中，出现惊群，首先要保证redis高可用，然后可以在写入redis时过期时间加上一个小随机数，可以是几个小时或者几十分钟。
...</p></div><footer class=entry-footer>2 min</footer><a class=entry-link aria-label="post link to 面试-8.redis" href=https://wangxiaohong123.github.io/posts/%E9%9D%A2%E8%AF%95/8.redis/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://wangxiaohong123.github.io/categories/%E9%9D%A2%E8%AF%95%E4%B8%93%E9%A2%98/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>