<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>6.计算机视觉(CV)介绍 | 王小红的笔记</title><meta name=keywords content="计算计视觉"><meta name=description content="图像是由长度、宽度、颜色通道组成的矩阵，一般是3个通道RGB，每个通道有多个像素点，像素点的值是0到255，这个数值表示的是亮度，比如0就是最暗-黑色，255是最亮-白色。
计算机视觉的挑战：部分遮掩(比如模型识别不出来被遮住头的猫)，背景混入(无法识别和背景颜色相似的目标)。
一、主要流程
1. 数据采集与预处理（Data Acquisition & Preprocessing）
获取高质量的视觉数据，并进行规范化处理。比如图像/视频采集、数据增强（如翻转、旋转、缩放）、数据标准化（如均值归一化、缩放到 [0,1]）、去噪、去模糊。常用工具OpenCV、Pillow（PIL）、Albumentations。
常用的开源基准数据集有2种，VOC和COCO，里面包含了一些人、动物、物品等带b标注图片。
2. 特征提取（Featrue Extraction / Backbone）
从原始图像中提取有代表性的特征，经典网络VGG、ResNet、MobileNet、Darknet。输出的是高维的特征图。
3. 特征表示与学习（Featrue Representation & Learning）
对特征进行降维或压缩、将特征输入到分类器或检测器中、学习特征与任务目标之间的映射关系。常见模型：

分类任务：Softmax 分类器
检测任务：RPN（Region Proposal Network）
分割任务：上采样模块（如 U-Net 中的 Decoder）

4. 任务特定头（Task-Specific Heads）
根据不同任务设计不同的网络头（Head）。常见任务头：

图像分类：全连接层 + Softmax
目标检测：边界框回归 + 分类头
语义分割：像素级分类头
实例分割：目标检测头 + 分割头（如 Mask R-CNN）

5. 推理与后处理（Inference & Post-processing）
将模型的输出转换为可解释的结果，常见后处理方法：

NMS（非极大值抑制）：去除冗余边界框
Softmax：转换为类别概率
阈值化：过滤低置信度的检测结果
CRF（条件随机场）：优化分割边界

5.1 NMS
非极大值抑制（Non-Maximum Suppression, NMS） 是一种常用于目标检测任务中的后处理技术，主要目的是从多个重叠的候选框（Bounding Boxes）中选择出最佳的框，减少冗余框，确保每个目标只保留一个检测框。流程：

对所有候选框按置信度分数进行降序排序。
选择当前置信度最高的框，将其加入保留框列表 Keep 中。
计算当前选择的框与所有剩余框之间的IoU。
对于与当前框 IoU 大于设定阈值（例如 0.5）的其他框，将它们从候选框列表中移除。因为这些高重叠的框很可能指向同一个目标，保留多个会导致冗余。
从剩余的候选框中，选择下一个置信度最高的框，重复步骤 2 → 3 → 4。

如果目标靠的太近可能造成误删，改进版有Soft-NMS(调整置信度而不是直接丢弃框)和Multi-Class NMS(针对不同类别分别进行 NMS)。"><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/posts/ai/6.%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/posts/ai/6.%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://wangxiaohong123.github.io/posts/ai/6.%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="6.计算机视觉(CV)介绍"><meta property="og:description" content="图像是由长度、宽度、颜色通道组成的矩阵，一般是3个通道RGB，每个通道有多个像素点，像素点的值是0到255，这个数值表示的是亮度，比如0就是最暗-黑色，255是最亮-白色。
计算机视觉的挑战：部分遮掩(比如模型识别不出来被遮住头的猫)，背景混入(无法识别和背景颜色相似的目标)。
一、主要流程 1. 数据采集与预处理（Data Acquisition & Preprocessing） 获取高质量的视觉数据，并进行规范化处理。比如图像/视频采集、数据增强（如翻转、旋转、缩放）、数据标准化（如均值归一化、缩放到 [0,1]）、去噪、去模糊。常用工具OpenCV、Pillow（PIL）、Albumentations。
常用的开源基准数据集有2种，VOC和COCO，里面包含了一些人、动物、物品等带b标注图片。
2. 特征提取（Featrue Extraction / Backbone） 从原始图像中提取有代表性的特征，经典网络VGG、ResNet、MobileNet、Darknet。输出的是高维的特征图。
3. 特征表示与学习（Featrue Representation & Learning） 对特征进行降维或压缩、将特征输入到分类器或检测器中、学习特征与任务目标之间的映射关系。常见模型：
分类任务：Softmax 分类器 检测任务：RPN（Region Proposal Network） 分割任务：上采样模块（如 U-Net 中的 Decoder） 4. 任务特定头（Task-Specific Heads） 根据不同任务设计不同的网络头（Head）。常见任务头：
图像分类：全连接层 + Softmax 目标检测：边界框回归 + 分类头 语义分割：像素级分类头 实例分割：目标检测头 + 分割头（如 Mask R-CNN） 5. 推理与后处理（Inference & Post-processing） 将模型的输出转换为可解释的结果，常见后处理方法：
NMS（非极大值抑制）：去除冗余边界框 Softmax：转换为类别概率 阈值化：过滤低置信度的检测结果 CRF（条件随机场）：优化分割边界 5.1 NMS 非极大值抑制（Non-Maximum Suppression, NMS） 是一种常用于目标检测任务中的后处理技术，主要目的是从多个重叠的候选框（Bounding Boxes）中选择出最佳的框，减少冗余框，确保每个目标只保留一个检测框。流程：
对所有候选框按置信度分数进行降序排序。 选择当前置信度最高的框，将其加入保留框列表 Keep 中。 计算当前选择的框与所有剩余框之间的IoU。 对于与当前框 IoU 大于设定阈值（例如 0.5）的其他框，将它们从候选框列表中移除。因为这些高重叠的框很可能指向同一个目标，保留多个会导致冗余。 从剩余的候选框中，选择下一个置信度最高的框，重复步骤 2 → 3 → 4。 如果目标靠的太近可能造成误删，改进版有Soft-NMS(调整置信度而不是直接丢弃框)和Multi-Class NMS(针对不同类别分别进行 NMS)。"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:tag" content="计算计视觉"><meta name=twitter:card content="summary"><meta name=twitter:title content="6.计算机视觉(CV)介绍"><meta name=twitter:description content="图像是由长度、宽度、颜色通道组成的矩阵，一般是3个通道RGB，每个通道有多个像素点，像素点的值是0到255，这个数值表示的是亮度，比如0就是最暗-黑色，255是最亮-白色。
计算机视觉的挑战：部分遮掩(比如模型识别不出来被遮住头的猫)，背景混入(无法识别和背景颜色相似的目标)。
一、主要流程
1. 数据采集与预处理（Data Acquisition & Preprocessing）
获取高质量的视觉数据，并进行规范化处理。比如图像/视频采集、数据增强（如翻转、旋转、缩放）、数据标准化（如均值归一化、缩放到 [0,1]）、去噪、去模糊。常用工具OpenCV、Pillow（PIL）、Albumentations。
常用的开源基准数据集有2种，VOC和COCO，里面包含了一些人、动物、物品等带b标注图片。
2. 特征提取（Featrue Extraction / Backbone）
从原始图像中提取有代表性的特征，经典网络VGG、ResNet、MobileNet、Darknet。输出的是高维的特征图。
3. 特征表示与学习（Featrue Representation & Learning）
对特征进行降维或压缩、将特征输入到分类器或检测器中、学习特征与任务目标之间的映射关系。常见模型：

分类任务：Softmax 分类器
检测任务：RPN（Region Proposal Network）
分割任务：上采样模块（如 U-Net 中的 Decoder）

4. 任务特定头（Task-Specific Heads）
根据不同任务设计不同的网络头（Head）。常见任务头：

图像分类：全连接层 + Softmax
目标检测：边界框回归 + 分类头
语义分割：像素级分类头
实例分割：目标检测头 + 分割头（如 Mask R-CNN）

5. 推理与后处理（Inference & Post-processing）
将模型的输出转换为可解释的结果，常见后处理方法：

NMS（非极大值抑制）：去除冗余边界框
Softmax：转换为类别概率
阈值化：过滤低置信度的检测结果
CRF（条件随机场）：优化分割边界

5.1 NMS
非极大值抑制（Non-Maximum Suppression, NMS） 是一种常用于目标检测任务中的后处理技术，主要目的是从多个重叠的候选框（Bounding Boxes）中选择出最佳的框，减少冗余框，确保每个目标只保留一个检测框。流程：

对所有候选框按置信度分数进行降序排序。
选择当前置信度最高的框，将其加入保留框列表 Keep 中。
计算当前选择的框与所有剩余框之间的IoU。
对于与当前框 IoU 大于设定阈值（例如 0.5）的其他框，将它们从候选框列表中移除。因为这些高重叠的框很可能指向同一个目标，保留多个会导致冗余。
从剩余的候选框中，选择下一个置信度最高的框，重复步骤 2 → 3 → 4。

如果目标靠的太近可能造成误删，改进版有Soft-NMS(调整置信度而不是直接丢弃框)和Multi-Class NMS(针对不同类别分别进行 NMS)。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://wangxiaohong123.github.io/posts/"},{"@type":"ListItem","position":2,"name":"6.计算机视觉(CV)介绍","item":"https://wangxiaohong123.github.io/posts/ai/6.%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"6.计算机视觉(CV)介绍","name":"6.计算机视觉(CV)介绍","description":"图像是由长度、宽度、颜色通道组成的矩阵，一般是3个通道RGB，每个通道有多个像素点，像素点的值是0到255，这个数值表示的是亮度，比如0就是最暗-黑色，255是最亮-白色。\n计算机视觉的挑战：部分遮掩(比如模型识别不出来被遮住头的猫)，背景混入(无法识别和背景颜色相似的目标)。\n一、主要流程 1. 数据采集与预处理（Data Acquisition \u0026amp; Preprocessing） 获取高质量的视觉数据，并进行规范化处理。比如图像/视频采集、数据增强（如翻转、旋转、缩放）、数据标准化（如均值归一化、缩放到 [0,1]）、去噪、去模糊。常用工具OpenCV、Pillow（PIL）、Albumentations。\n常用的开源基准数据集有2种，VOC和COCO，里面包含了一些人、动物、物品等带b标注图片。\n2. 特征提取（Featrue Extraction / Backbone） 从原始图像中提取有代表性的特征，经典网络VGG、ResNet、MobileNet、Darknet。输出的是高维的特征图。\n3. 特征表示与学习（Featrue Representation \u0026amp; Learning） 对特征进行降维或压缩、将特征输入到分类器或检测器中、学习特征与任务目标之间的映射关系。常见模型：\n分类任务：Softmax 分类器 检测任务：RPN（Region Proposal Network） 分割任务：上采样模块（如 U-Net 中的 Decoder） 4. 任务特定头（Task-Specific Heads） 根据不同任务设计不同的网络头（Head）。常见任务头：\n图像分类：全连接层 + Softmax 目标检测：边界框回归 + 分类头 语义分割：像素级分类头 实例分割：目标检测头 + 分割头（如 Mask R-CNN） 5. 推理与后处理（Inference \u0026amp; Post-processing） 将模型的输出转换为可解释的结果，常见后处理方法：\nNMS（非极大值抑制）：去除冗余边界框 Softmax：转换为类别概率 阈值化：过滤低置信度的检测结果 CRF（条件随机场）：优化分割边界 5.1 NMS 非极大值抑制（Non-Maximum Suppression, NMS） 是一种常用于目标检测任务中的后处理技术，主要目的是从多个重叠的候选框（Bounding Boxes）中选择出最佳的框，减少冗余框，确保每个目标只保留一个检测框。流程：\n对所有候选框按置信度分数进行降序排序。 选择当前置信度最高的框，将其加入保留框列表 Keep 中。 计算当前选择的框与所有剩余框之间的IoU。 对于与当前框 IoU 大于设定阈值（例如 0.5）的其他框，将它们从候选框列表中移除。因为这些高重叠的框很可能指向同一个目标，保留多个会导致冗余。 从剩余的候选框中，选择下一个置信度最高的框，重复步骤 2 → 3 → 4。 如果目标靠的太近可能造成误删，改进版有Soft-NMS(调整置信度而不是直接丢弃框)和Multi-Class NMS(针对不同类别分别进行 NMS)。\n","keywords":["计算计视觉"],"articleBody":"图像是由长度、宽度、颜色通道组成的矩阵，一般是3个通道RGB，每个通道有多个像素点，像素点的值是0到255，这个数值表示的是亮度，比如0就是最暗-黑色，255是最亮-白色。\n计算机视觉的挑战：部分遮掩(比如模型识别不出来被遮住头的猫)，背景混入(无法识别和背景颜色相似的目标)。\n一、主要流程 1. 数据采集与预处理（Data Acquisition \u0026 Preprocessing） 获取高质量的视觉数据，并进行规范化处理。比如图像/视频采集、数据增强（如翻转、旋转、缩放）、数据标准化（如均值归一化、缩放到 [0,1]）、去噪、去模糊。常用工具OpenCV、Pillow（PIL）、Albumentations。\n常用的开源基准数据集有2种，VOC和COCO，里面包含了一些人、动物、物品等带b标注图片。\n2. 特征提取（Featrue Extraction / Backbone） 从原始图像中提取有代表性的特征，经典网络VGG、ResNet、MobileNet、Darknet。输出的是高维的特征图。\n3. 特征表示与学习（Featrue Representation \u0026 Learning） 对特征进行降维或压缩、将特征输入到分类器或检测器中、学习特征与任务目标之间的映射关系。常见模型：\n分类任务：Softmax 分类器 检测任务：RPN（Region Proposal Network） 分割任务：上采样模块（如 U-Net 中的 Decoder） 4. 任务特定头（Task-Specific Heads） 根据不同任务设计不同的网络头（Head）。常见任务头：\n图像分类：全连接层 + Softmax 目标检测：边界框回归 + 分类头 语义分割：像素级分类头 实例分割：目标检测头 + 分割头（如 Mask R-CNN） 5. 推理与后处理（Inference \u0026 Post-processing） 将模型的输出转换为可解释的结果，常见后处理方法：\nNMS（非极大值抑制）：去除冗余边界框 Softmax：转换为类别概率 阈值化：过滤低置信度的检测结果 CRF（条件随机场）：优化分割边界 5.1 NMS 非极大值抑制（Non-Maximum Suppression, NMS） 是一种常用于目标检测任务中的后处理技术，主要目的是从多个重叠的候选框（Bounding Boxes）中选择出最佳的框，减少冗余框，确保每个目标只保留一个检测框。流程：\n对所有候选框按置信度分数进行降序排序。 选择当前置信度最高的框，将其加入保留框列表 Keep 中。 计算当前选择的框与所有剩余框之间的IoU。 对于与当前框 IoU 大于设定阈值（例如 0.5）的其他框，将它们从候选框列表中移除。因为这些高重叠的框很可能指向同一个目标，保留多个会导致冗余。 从剩余的候选框中，选择下一个置信度最高的框，重复步骤 2 → 3 → 4。 如果目标靠的太近可能造成误删，改进版有Soft-NMS(调整置信度而不是直接丢弃框)和Multi-Class NMS(针对不同类别分别进行 NMS)。\n二、图像分类 特征提取：backbone。从给定类别集合中为图像分配标签的任务。\n1. AlexNet 使用8层卷积神经网络赢得2012年imageNet冠军。5个卷积层+2个隐藏层+1个输出层，大尺度卷积核计算开销大。模型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import tensorflow as tf net = tf.keras.Sequential([ # 卷积层：96个卷积核，卷积核大小是11 * 11，步长是4，激活函数是rule tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=4, activation='relu'), # 池化层：窗口大小是3*3，步长是2 tf.keras.layers.MaxPooling2D(pool_size=3, strides=2), # 卷积层：256个卷积核，卷积核大小是5 * 5，padding是same，激活函数是rule tf.keras.layers.Conv2D(filters=256, kernel_size=5, padding='same', activation='relu'), # 池化层：窗口大小是3*3，步长是2 tf.keras.layers.MaxPooling2D(pool_size=3, strides=2), # 卷积层：384个卷积核，卷积核大小是3 * 3，padding是same，激活函数是rule tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same', activation='relu'), tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same', activation='relu'), tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'), tf.keras.layers.MaxPooling2D(pool_size=3, strides=2), # 伸展成1维向量 tf.keras.layers.Flatten(), # 隐藏层：4096个神经元 tf.keras.layers.Dense(4096, activation='relu'), # 随机失活 tf.keras.layers.Dropout(0.5), tf.keras.layers.Dense(4096, activation='relu'), tf.keras.layers.Dropout(0.5), # 输出层：10个神经元，激活函数是softmax tf.keras.layers.Dense(10, activation='softmax') ]) # 1张图片，大小是227 * 227，通道数是1 X = tf.random.uniform((1, 227, 227, 1)) y = net(X) # 输出模型结构 net.summary() 2. VGG 分为VGG16和VGG19，一个16层一个19层。他的卷积核只有3*3，比AlexNet小很多，常用作特征提取，小适度卷积核无法捕捉大尺度特征。模型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import tensorflow as tf def vgg_block(num_conv, num_filters): \"\"\" 构建卷积块 :param num_conv: 卷积层个数 :param num_filters: 卷积核个数 \"\"\" blk = tf.keras.Sequential() for _ in range(num_conv): blk.add(tf.keras.layers.Conv2D(num_filters, (3, 3), padding='same', activation='relu')) blk.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2)) return blk def vgg(conv_arch): net = tf.keras.Sequential() for (num_conv, num_filters) in conv_arch: net.add(vgg_block(num_conv, num_filters)) # 全联接层 net.add(tf.keras.Sequential([ tf.keras.layers.Flatten(), tf.keras.layers.Dense(4096, activation='relu'), tf.keras.layers.Dropout(0.5), tf.keras.layers.Dense(10, activation='softmax'), ])) return net # 创建模型 net = vgg(((2, 64), (2, 128), (3, 256), (3, 512), (3, 512))) 3. GoogLeNet 引入Inception代替之前的卷积+激活函数，他的错误率很接近人眼。Inception不需要堆叠多层卷积核，他的核心思想是同一层同时使用不同大小的卷积核（1×1、3×3、5×5）和池化层，然后将它们的输出拼接起来，Inception包含下面几个部分：\n1*1卷积：减少特征图的通道数，降低后续大尺寸卷积的计算开销 3*3卷积：捕获中等尺度的特征 5*5卷积：捕获较大尺度的特征 3*3池化：减少特征图的空间尺寸，保留主要特征 1*1卷积：在池化之后进行降维 模型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 import tensorflow as tf class Inception(tf.keras.layers.Layer): # 设置模块的构成 def __init__(self, c1, c2, c3, c4): super().__init__() # 1*1 self.p1_1 = tf.keras.layers.Conv2D(c1, kernel_size=1, activation='relu', padding='same') # 3*3 self.p2_1 = tf.keras.layers.Conv2D(c2[0], kernel_size=1, activation='relu', padding='same') self.p2_2 = tf.keras.layers.Conv2D(c2[1], kernel_size=1, activation='relu', padding='same') # 5*5 self.p3_1 = tf.keras.layers.Conv2D(c3[0], kernel_size=1, activation='relu', padding='same') self.p3_2 = tf.keras.layers.Conv2D(c3[1], kernel_size=5, activation='relu', padding='same') # 3*3池化+1*1卷积 self.p4_1 = tf.keras.layers.MaxPooling2D(pool_size=3, padding='same', strides=1) self.p4_2 = tf.keras.layers.Conv2D(c4, kernel_size=1, activation='relu', padding='same') # 前向传播过程 def call(self, inputs): p1 = self.p1_1(inputs) p2 = self.p2_2(self.p2_1(inputs)) p3 = self.p3_2(self.p3_1(inputs)) p4 = self.p4_2(self.p4_1(inputs)) outputs = tf.concat([p1, p2, p3, p4], axis=-1) return outputs def aux_classifier(x, filter_size): \"\"\" 辅助分类器 :param x: 输入数据 :param filter_size: 卷积核个数 \"\"\" x = tf.keras.layers.AveragePooling2D(pool_size=5, strides=3, padding='same')(x) x = tf.keras.layers.Conv2D(filter_size=filter_size[0], kernel_size=1, strides=1, padding='valid', activation='relu')(x) x = tf.keras.layers.Flatten()(x) x = tf.keras.layers.Dense(units=filter_size[1], activation='relu')(x) x = tf.keras.layers.Dense(units=10, activation='softmax')(x) return x # B1模块 inputs = tf.keras.Input(shape=(224, 224, 3), name='input') # 64个卷积核，每个卷积核大小7*7 x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same', activation='relu')(inputs) x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # B2模块 x = tf.keras.layers.Conv2D(64, kernel_size=1, strides=1, padding='same', activation='relu')(x) x = tf.keras.layers.Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu')(x) x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # B3模块 x = Inception(64, (96, 128), (16, 32), 32)(x) x = Inception(128, (128, 192), (32, 96), 64)(x) x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # B4模块 x = Inception(192, (96, 208), (16, 48), 64)(x) aux_output_1 = aux_classifier(x, [128, 1024]) x = Inception(160, (112, 224), (24, 64), 64)(x) x = Inception(128, (128, 256), (24, 64), 64)(x) x = Inception(112, (114, 288), (32, 64), 64)(x) aux_output_2 = aux_classifier(x, [128, 1024]) x = Inception(256, (160, 320), (32, 128), 128)(x) x = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # B5模块 x = Inception(256, (160, 320), (32, 128), 128)(x) x = Inception(384, (192, 384), (48, 128), 128)(x) x = tf.keras.layers.GlobalAvgPool2D()(x) output = tf.keras.layers.Dense(units=10, activation='softmax')(x) model = tf.keras.Model(inputs=inputs, outputs=[output, aux_output_1, aux_output_2]) 4. ResNet 15年出来的真神，10年了大家还在用。网络越深获取的信息越多，特征也越丰富，但是实践中网络越深，训练效果反而越差，针对这个问题，何凯明提出了残差网络(ResNet):同样是增加网络层数，但是增加之前向保存当前网络，增加完1层之后将结果和之前相比，选择2个里最优的，不过残差网络保存的网络变多，需要的显存也更大。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 import tensorflow as tf from tensorflow.keras import layers, models def residual_block(x, filters, kernel_size=3, stride=1, downsample=False): \"\"\" 定义一个残差块（Residual Block） - x: 输入张量 - filters: 卷积核的数量 - kernel_size: 卷积核大小，默认3x3 - stride: 步幅，默认1 - downsample: 是否下采样，用于改变通道数和尺寸 :return 输出张量 \"\"\" # 保存输入（用于跳跃连接） shortcut = x # 主路径 - 第一层卷积 x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', use_bias=False)(x) x = layers.BatchNormalization()(x) x = layers.ReLU()(x) # 主路径 - 第二层卷积 x = layers.Conv2D(filters, kernel_size, strides=1, padding='same', use_bias=False)(x) x = layers.BatchNormalization()(x) # 如果需要下采样或通道不匹配，调整 shortcut if downsample: shortcut = layers.Conv2D(filters, 1, strides=stride, use_bias=False)(shortcut) shortcut = layers.BatchNormalization()(shortcut) # 将输入（shortcut）和输出相加 x = layers.Add()([x, shortcut]) x = layers.ReLU()(x) return x def build_resnet(input_shape, num_classes): \"\"\" 构建 ResNet-18 模型 - input_shape: 输入图像的形状 (H, W, C) - num_classes: 输出类别数量 :return ResNet 模型 \"\"\" inputs = layers.Input(shape=input_shape) # 初始卷积层和池化层 x = layers.Conv2D(64, 7, strides=2, padding='same', use_bias=False)(inputs) x = layers.BatchNormalization()(x) x = layers.ReLU()(x) x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # 残差块阶段 x = residual_block(x, 64) x = residual_block(x, 64) x = residual_block(x, 128, stride=2, downsample=True) x = residual_block(x, 128) x = residual_block(x, 256, stride=2, downsample=True) x = residual_block(x, 256) x = residual_block(x, 512, stride=2, downsample=True) x = residual_block(x, 512) # 全局平均池化层 x = layers.GlobalAveragePooling2D()(x) # 全连接层输出分类结果 outputs = layers.Dense(num_classes, activation='softmax')(x) # 创建模型 return models.Model(inputs, outputs) # 构建模型 resnet_model = build_resnet((224, 224, 3), 10) # 编译模型 resnet_model.compile( optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'] ) # 输出模型结构 resnet_model.summary() OpenVC OpenCV 是一个计算机视觉的工具库，安装：\n1 2 3 4 # 3.4.2之后有一些算法申请专利用不了了 pip install opencv-python==3.4.1.15 # 两个工具的版本要一致 pip install opencv-contrib-python==3.4.1.15 基本操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import cv2 # 读取图像,读取进来的数据是一个3维数组(numpy的ndarray)：像素点是2维的 + 通道的维度 # IMREAD_GRAYSCALE表示读取方式是灰度图,灰度图的通道只有1 img = cv2.imread('xxx.jpg', cv2.IMREAD_GRAYSCALE) # 输出图片数组的长度：长、宽、通道数 print(img.shape) # 截取图像 cat = img[0:200, 0:200] # 改变图像大小，这个不是截取而是拉伸或者压缩图像 dog = cv2.resize(img, (200, 200)) # 提取颜色通道 b, g, r = cv2.split(img) # 合并通道 cv2.merge((b, g, r)) # 边界填充，填充类型有很多，比如BORDER_REPLICATE表示复制最近像素 cv2.copyMakeBorder(img, 10, 10, 10, 10, borderType=cv2.BORDER_REPLICATE) # 读取视频 open1 = False vc = cv2.VideoCaptrue('xxx.mp4') if vc.isOpened(): open1, frame = vc.read() # 视频读取就是把每帧都读取成图片数组 while open1: ret, frame = vc.read() if frame is None: break if ret: # 3通道转成灰度图 gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) cv2.imshow('result', gray) # 每0.1s播放下一帧，27是esc按键，意思是按esc退出播放 if cv2.waitKey(100) \u0026 0xFF == 27: break vc.release() cv2.destroyAllWindows() 它还可以处理图像的阈值、平滑、腐蚀、膨胀、开闭运算等等。\n信用卡数字识别 OCR识别 图像特征 全景图象拼接 停车场车位识别 答题卡判卷 背景建模 光流估计 DNN模块 目标追踪 卷积原理 疲劳检测 四、图像分割 图像分割是目标检测的进阶，就是为图像中的每个像素进行分类，可以用在自动驾驶，医疗影像诊断，图片美化等领域。主要分2类，语义分割和实例分割，实例分割分割不仅仅要区分类别，还要区分不同类别中的不同个体。\n常用的开源数据集有VOC、coco、城市风光数据集(自动驾驶模型专用)。\n1 评价指标 像素精度 平均像素精度 平均交并比 2 语义分割 2.1 FCN FCN使用全卷积架构，是目前图像分割算法的基础框架。 除了全卷积层还多了一个上采样层，上采样层使用反卷积可以将低分辨率的特征图恢复到原图相同的尺寸。\nFCN还引入的跳跃连接，让不同层次的特征图进行融合，可以保留高层语义信息和底层空间信息，提高分割精度和保留更多细节。\n2.2 Unet 采用对称的编码器-解码器（Encoder-Decoder） 结构，类似英文字母 “U” 的形状。编码器就是卷积层，卷积核是3*3，通道数递增，解码器就是采样层，通道数递减，适合高分辨率图像分割。\n3 实例分割 3.1 MaskRCNN 就是在faster-RCNN的基础上增加一个分支，实现目标检测的同时分割目标像素。\n4 Segment Anything 23年Facebook开源的图片分割大模型，这是第一个视觉大模型，基于VIT增加了数据引擎和提示词编码器：\n数据引擎：由模型自己创建训练的标记数据。 提示词系统：通过提示告诉模型要分割哪些物体，而不是和传统模型一样只能自动分割样本数据中的物体。 ","wordCount":"1176","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://wangxiaohong123.github.io/posts/ai/6.%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/"},"publisher":{"@type":"Organization","name":"王小红的笔记","logo":{"@type":"ImageObject","url":"https://wangxiaohong123.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">6.计算机视觉(CV)介绍</h1><div class=post-meta>6 min</div></header><div class=post-content><p>图像是由长度、宽度、颜色通道组成的矩阵，一般是3个通道RGB，每个通道有多个像素点，像素点的值是0到255，这个数值表示的是亮度，比如0就是最暗-黑色，255是最亮-白色。</p><p>计算机视觉的挑战：部分遮掩(比如模型识别不出来被遮住头的猫)，背景混入(无法识别和背景颜色相似的目标)。</p><h3 id=一主要流程>一、主要流程<a hidden class=anchor aria-hidden=true href=#一主要流程>#</a></h3><h4 id=1-数据采集与预处理data-acquisition--preprocessing>1. 数据采集与预处理（Data Acquisition & Preprocessing）<a hidden class=anchor aria-hidden=true href=#1-数据采集与预处理data-acquisition--preprocessing>#</a></h4><p>获取高质量的视觉数据，并进行规范化处理。比如图像/视频采集、数据增强（如翻转、旋转、缩放）、数据标准化（如均值归一化、缩放到 [0,1]）、去噪、去模糊。常用工具OpenCV、Pillow（PIL）、Albumentations。</p><p>常用的开源基准数据集有2种，VOC和COCO，里面包含了一些人、动物、物品等带b标注图片。</p><h4 id=2-特征提取featrue-extraction--backbone>2. 特征提取（Featrue Extraction / Backbone）<a hidden class=anchor aria-hidden=true href=#2-特征提取featrue-extraction--backbone>#</a></h4><p>从原始图像中提取有代表性的特征，经典网络VGG、ResNet、MobileNet、Darknet。输出的是高维的特征图。</p><h4 id=3-特征表示与学习featrue-representation--learning>3. 特征表示与学习（Featrue Representation & Learning）<a hidden class=anchor aria-hidden=true href=#3-特征表示与学习featrue-representation--learning>#</a></h4><p>对特征进行降维或压缩、将特征输入到分类器或检测器中、学习特征与任务目标之间的映射关系。常见模型：</p><ul><li>分类任务：Softmax 分类器</li><li>检测任务：RPN（Region Proposal Network）</li><li>分割任务：上采样模块（如 U-Net 中的 Decoder）</li></ul><h4 id=4-任务特定头task-specific-heads>4. 任务特定头（Task-Specific Heads）<a hidden class=anchor aria-hidden=true href=#4-任务特定头task-specific-heads>#</a></h4><p>根据不同任务设计不同的网络头（Head）。常见任务头：</p><ul><li>图像分类：全连接层 + Softmax</li><li>目标检测：边界框回归 + 分类头</li><li>语义分割：像素级分类头</li><li>实例分割：目标检测头 + 分割头（如 Mask R-CNN）</li></ul><h4 id=5-推理与后处理inference--post-processing>5. 推理与后处理（Inference & Post-processing）<a hidden class=anchor aria-hidden=true href=#5-推理与后处理inference--post-processing>#</a></h4><p>将模型的输出转换为可解释的结果，常见后处理方法：</p><ul><li>NMS（非极大值抑制）：去除冗余边界框</li><li>Softmax：转换为类别概率</li><li>阈值化：过滤低置信度的检测结果</li><li>CRF（条件随机场）：优化分割边界</li></ul><h5 id=51-nms>5.1 NMS<a hidden class=anchor aria-hidden=true href=#51-nms>#</a></h5><p><strong>非极大值抑制（Non-Maximum Suppression, NMS）</strong> 是一种常用于目标检测任务中的后处理技术，主要目的是从多个重叠的候选框（Bounding Boxes）中选择出最佳的框，减少冗余框，确保每个目标只保留一个检测框。流程：</p><ol><li>对所有候选框按<strong>置信度分数</strong>进行降序排序。</li><li>选择<strong>当前置信度最高的框</strong>，将其加入保留框列表 <code>Keep</code> 中。</li><li>计算当前选择的框与<strong>所有剩余框</strong>之间的IoU。</li><li>对于与当前框 <strong>IoU 大于设定阈值</strong>（例如 0.5）的其他框，将它们从候选框列表中<strong>移除</strong>。因为这些高重叠的框很可能指向同一个目标，保留多个会导致冗余。</li><li>从剩余的候选框中，<strong>选择下一个置信度最高的框</strong>，重复步骤 <strong>2 → 3 → 4</strong>。</li></ol><p><strong>如果目标靠的太近可能造成误删</strong>，改进版有Soft-NMS(调整置信度而不是直接丢弃框)和Multi-Class NMS(针对不同类别分别进行 NMS)。</p><h3 id=二图像分类>二、图像分类<a hidden class=anchor aria-hidden=true href=#二图像分类>#</a></h3><p>特征提取：backbone。从给定类别集合中为图像分配标签的任务。</p><h4 id=1-alexnet>1. AlexNet<a hidden class=anchor aria-hidden=true href=#1-alexnet>#</a></h4><p>使用8层卷积神经网络赢得2012年imageNet冠军。5个卷积层+2个隐藏层+1个输出层，<strong>大尺度卷积核计算开销大</strong>。模型：</p><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> tensorflow <span style=color:#ff79c6>as</span> tf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>net <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>Sequential([
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 卷积层：96个卷积核，卷积核大小是11 * 11，步长是4，激活函数是rule</span>
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(filters<span style=color:#ff79c6>=</span><span style=color:#bd93f9>96</span>, kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>11</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>4</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 池化层：窗口大小是3*3，步长是2</span>
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>MaxPooling2D(pool_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>),
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 卷积层：256个卷积核，卷积核大小是5 * 5，padding是same，激活函数是rule</span>
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(filters<span style=color:#ff79c6>=</span><span style=color:#bd93f9>256</span>, kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>5</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 池化层：窗口大小是3*3，步长是2</span>
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>MaxPooling2D(pool_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>),
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 卷积层：384个卷积核，卷积核大小是3 * 3，padding是same，激活函数是rule</span>
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(filters<span style=color:#ff79c6>=</span><span style=color:#bd93f9>384</span>, kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(filters<span style=color:#ff79c6>=</span><span style=color:#bd93f9>384</span>, kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(filters<span style=color:#ff79c6>=</span><span style=color:#bd93f9>256</span>, kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>MaxPooling2D(pool_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>),
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 伸展成1维向量</span>
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Flatten(),
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 隐藏层：4096个神经元</span>
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dense(<span style=color:#bd93f9>4096</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 随机失活</span>
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dropout(<span style=color:#bd93f9>0.5</span>),
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dense(<span style=color:#bd93f9>4096</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dropout(<span style=color:#bd93f9>0.5</span>),
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 输出层：10个神经元，激活函数是softmax</span>
</span></span><span style=display:flex><span>    tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dense(<span style=color:#bd93f9>10</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;softmax&#39;</span>)
</span></span><span style=display:flex><span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 1张图片，大小是227 * 227，通道数是1</span>
</span></span><span style=display:flex><span>X <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>random<span style=color:#ff79c6>.</span>uniform((<span style=color:#bd93f9>1</span>, <span style=color:#bd93f9>227</span>, <span style=color:#bd93f9>227</span>, <span style=color:#bd93f9>1</span>))
</span></span><span style=display:flex><span>y <span style=color:#ff79c6>=</span> net(X)
</span></span><span style=display:flex><span><span style=color:#6272a4># 输出模型结构</span>
</span></span><span style=display:flex><span>net<span style=color:#ff79c6>.</span>summary()
</span></span></code></pre></td></tr></table></div></div><h4 id=2-vgg>2. VGG<a hidden class=anchor aria-hidden=true href=#2-vgg>#</a></h4><p>分为VGG16和VGG19，一个16层一个19层。他的卷积核只有3*3，比AlexNet小很多，常用作特征提取，<strong>小适度卷积核无法捕捉大尺度特征</strong>。模型：</p><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> tensorflow <span style=color:#ff79c6>as</span> tf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>vgg_block</span>(num_conv, num_filters):
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    构建卷积块
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    :param num_conv: 卷积层个数
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    :param num_filters: 卷积核个数
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    blk <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>Sequential()
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> _ <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(num_conv):
</span></span><span style=display:flex><span>        blk<span style=color:#ff79c6>.</span>add(tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(num_filters, (<span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>3</span>), padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>))
</span></span><span style=display:flex><span>    blk<span style=color:#ff79c6>.</span>add(tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>MaxPooling2D(pool_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>))
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> blk
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>vgg</span>(conv_arch):
</span></span><span style=display:flex><span>    net <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>Sequential()
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> (num_conv, num_filters) <span style=color:#ff79c6>in</span> conv_arch:
</span></span><span style=display:flex><span>        net<span style=color:#ff79c6>.</span>add(vgg_block(num_conv, num_filters))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 全联接层</span>
</span></span><span style=display:flex><span>    net<span style=color:#ff79c6>.</span>add(tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>Sequential([
</span></span><span style=display:flex><span>        tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Flatten(),
</span></span><span style=display:flex><span>        tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dense(<span style=color:#bd93f9>4096</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>),
</span></span><span style=display:flex><span>        tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dropout(<span style=color:#bd93f9>0.5</span>),
</span></span><span style=display:flex><span>        tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dense(<span style=color:#bd93f9>10</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;softmax&#39;</span>),
</span></span><span style=display:flex><span>    ]))
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> net
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 创建模型</span>
</span></span><span style=display:flex><span>net <span style=color:#ff79c6>=</span> vgg(((<span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>64</span>), (<span style=color:#bd93f9>2</span>, <span style=color:#bd93f9>128</span>), (<span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>256</span>), (<span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>512</span>), (<span style=color:#bd93f9>3</span>, <span style=color:#bd93f9>512</span>)))
</span></span></code></pre></td></tr></table></div></div><h4 id=3-googlenet>3. GoogLeNet<a hidden class=anchor aria-hidden=true href=#3-googlenet>#</a></h4><p>引入Inception代替之前的卷积+激活函数，他的错误率很接近人眼。Inception不需要堆叠多层卷积核，他的核心思想是<strong>同一层同时使用不同大小的卷积核（1×1、3×3、5×5）和池化层</strong>，然后将它们的输出拼接起来，Inception包含下面几个部分：</p><ol><li>1*1卷积：减少特征图的通道数，降低后续大尺寸卷积的计算开销</li><li>3*3卷积：捕获中等尺度的特征</li><li>5*5卷积：捕获较大尺度的特征</li><li>3*3池化：减少特征图的空间尺寸，保留主要特征</li><li>1*1卷积：在池化之后进行降维</li></ol><p>模型：</p><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">64
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">65
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">66
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">67
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">68
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">69
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">70
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">71
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">72
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">73
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">74
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">75
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">76
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> tensorflow <span style=color:#ff79c6>as</span> tf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>class</span> <span style=color:#50fa7b>Inception</span>(tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Layer):
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 设置模块的构成</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>__init__</span>(<span style=font-style:italic>self</span>, c1, c2, c3, c4):
</span></span><span style=display:flex><span>        <span style=color:#8be9fd;font-style:italic>super</span>()<span style=color:#ff79c6>.</span><span style=color:#50fa7b>__init__</span>()
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 1*1</span>
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p1_1 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(c1, kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 3*3</span>
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p2_1 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(c2[<span style=color:#bd93f9>0</span>], kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>)
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p2_2 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(c2[<span style=color:#bd93f9>1</span>], kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 5*5</span>
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p3_1 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(c3[<span style=color:#bd93f9>0</span>], kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>)
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p3_2 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(c3[<span style=color:#bd93f9>1</span>], kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>5</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>)
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 3*3池化+1*1卷积</span>
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p4_1 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>MaxPooling2D(pool_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p4_2 <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(c4, kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 前向传播过程</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>call</span>(<span style=font-style:italic>self</span>, inputs):
</span></span><span style=display:flex><span>        p1 <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p1_1(inputs)
</span></span><span style=display:flex><span>        p2 <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p2_2(<span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p2_1(inputs))
</span></span><span style=display:flex><span>        p3 <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p3_2(<span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p3_1(inputs))
</span></span><span style=display:flex><span>        p4 <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p4_2(<span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>p4_1(inputs))
</span></span><span style=display:flex><span>        outputs <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>concat([p1, p2, p3, p4], axis<span style=color:#ff79c6>=-</span><span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>return</span> outputs
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>aux_classifier</span>(x, filter_size):
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    辅助分类器
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    :param x: 输入数据
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    :param filter_size: 卷积核个数
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>AveragePooling2D(pool_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>5</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>)(x)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(filter_size<span style=color:#ff79c6>=</span>filter_size[<span style=color:#bd93f9>0</span>], kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;valid&#39;</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>)(x)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Flatten()(x)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dense(units<span style=color:#ff79c6>=</span>filter_size[<span style=color:#bd93f9>1</span>], activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>)(x)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dense(units<span style=color:#ff79c6>=</span><span style=color:#bd93f9>10</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;softmax&#39;</span>)(x)
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> x
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># B1模块</span>
</span></span><span style=display:flex><span>inputs <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>Input(shape<span style=color:#ff79c6>=</span>(<span style=color:#bd93f9>224</span>, <span style=color:#bd93f9>224</span>, <span style=color:#bd93f9>3</span>), name<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;input&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#6272a4># 64个卷积核，每个卷积核大小7*7</span>
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(<span style=color:#bd93f9>64</span>, kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>7</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>)(inputs)
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>MaxPooling2D(pool_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>)(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># B2模块</span>
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(<span style=color:#bd93f9>64</span>, kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>)(x)
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Conv2D(<span style=color:#bd93f9>192</span>, kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;relu&#39;</span>)(x)
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>MaxPooling2D(pool_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>)(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># B3模块</span>
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> Inception(<span style=color:#bd93f9>64</span>, (<span style=color:#bd93f9>96</span>, <span style=color:#bd93f9>128</span>), (<span style=color:#bd93f9>16</span>, <span style=color:#bd93f9>32</span>), <span style=color:#bd93f9>32</span>)(x)
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> Inception(<span style=color:#bd93f9>128</span>, (<span style=color:#bd93f9>128</span>, <span style=color:#bd93f9>192</span>), (<span style=color:#bd93f9>32</span>, <span style=color:#bd93f9>96</span>), <span style=color:#bd93f9>64</span>)(x)
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>MaxPooling2D(pool_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>)(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># B4模块</span>
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> Inception(<span style=color:#bd93f9>192</span>, (<span style=color:#bd93f9>96</span>, <span style=color:#bd93f9>208</span>), (<span style=color:#bd93f9>16</span>, <span style=color:#bd93f9>48</span>), <span style=color:#bd93f9>64</span>)(x)
</span></span><span style=display:flex><span>aux_output_1 <span style=color:#ff79c6>=</span> aux_classifier(x, [<span style=color:#bd93f9>128</span>, <span style=color:#bd93f9>1024</span>])
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> Inception(<span style=color:#bd93f9>160</span>, (<span style=color:#bd93f9>112</span>, <span style=color:#bd93f9>224</span>), (<span style=color:#bd93f9>24</span>, <span style=color:#bd93f9>64</span>), <span style=color:#bd93f9>64</span>)(x)
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> Inception(<span style=color:#bd93f9>128</span>, (<span style=color:#bd93f9>128</span>, <span style=color:#bd93f9>256</span>), (<span style=color:#bd93f9>24</span>, <span style=color:#bd93f9>64</span>), <span style=color:#bd93f9>64</span>)(x)
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> Inception(<span style=color:#bd93f9>112</span>, (<span style=color:#bd93f9>114</span>, <span style=color:#bd93f9>288</span>), (<span style=color:#bd93f9>32</span>, <span style=color:#bd93f9>64</span>), <span style=color:#bd93f9>64</span>)(x)
</span></span><span style=display:flex><span>aux_output_2 <span style=color:#ff79c6>=</span> aux_classifier(x, [<span style=color:#bd93f9>128</span>, <span style=color:#bd93f9>1024</span>])
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> Inception(<span style=color:#bd93f9>256</span>, (<span style=color:#bd93f9>160</span>, <span style=color:#bd93f9>320</span>), (<span style=color:#bd93f9>32</span>, <span style=color:#bd93f9>128</span>), <span style=color:#bd93f9>128</span>)(x)
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>MaxPooling2D(pool_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>)(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># B5模块</span>
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> Inception(<span style=color:#bd93f9>256</span>, (<span style=color:#bd93f9>160</span>, <span style=color:#bd93f9>320</span>), (<span style=color:#bd93f9>32</span>, <span style=color:#bd93f9>128</span>), <span style=color:#bd93f9>128</span>)(x)
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> Inception(<span style=color:#bd93f9>384</span>, (<span style=color:#bd93f9>192</span>, <span style=color:#bd93f9>384</span>), (<span style=color:#bd93f9>48</span>, <span style=color:#bd93f9>128</span>), <span style=color:#bd93f9>128</span>)(x)
</span></span><span style=display:flex><span>x <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>GlobalAvgPool2D()(x)
</span></span><span style=display:flex><span>output <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>layers<span style=color:#ff79c6>.</span>Dense(units<span style=color:#ff79c6>=</span><span style=color:#bd93f9>10</span>, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;softmax&#39;</span>)(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model <span style=color:#ff79c6>=</span> tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>Model(inputs<span style=color:#ff79c6>=</span>inputs, outputs<span style=color:#ff79c6>=</span>[output, aux_output_1, aux_output_2])
</span></span></code></pre></td></tr></table></div></div><h4 id=4-resnet>4. ResNet<a hidden class=anchor aria-hidden=true href=#4-resnet>#</a></h4><p>15年出来的真神，10年了大家还在用。网络越深获取的信息越多，特征也越丰富，但是实践中网络越深，训练效果反而越差，针对这个问题，何凯明提出了残差网络(ResNet):同样是增加网络层数，但是增加之前向保存当前网络，增加完1层之后将结果和之前相比，选择2个里最优的，<strong>不过残差网络保存的网络变多，需要的显存也更大。</strong></p><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">64
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">65
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">66
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">67
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">68
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">69
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">70
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">71
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">72
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">73
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">74
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">75
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">76
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">77
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">78
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">79
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">80
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">81
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">82
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">83
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">84
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">85
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">86
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">87
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">88
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> tensorflow <span style=color:#ff79c6>as</span> tf
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> tensorflow.keras <span style=color:#ff79c6>import</span> layers, models
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>residual_block</span>(x, filters, kernel_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, stride<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, downsample<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>):
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    定义一个残差块（Residual Block）
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    - x: 输入张量
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    - filters: 卷积核的数量
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    - kernel_size: 卷积核大小，默认3x3
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    - stride: 步幅，默认1
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    - downsample: 是否下采样，用于改变通道数和尺寸
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    :return 输出张量
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 保存输入（用于跳跃连接）</span>
</span></span><span style=display:flex><span>    shortcut <span style=color:#ff79c6>=</span> x
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 主路径 - 第一层卷积</span>
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>Conv2D(filters, kernel_size, strides<span style=color:#ff79c6>=</span>stride, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>, use_bias<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>)(x)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>BatchNormalization()(x)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>ReLU()(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 主路径 - 第二层卷积</span>
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>Conv2D(filters, kernel_size, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>1</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>, use_bias<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>)(x)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>BatchNormalization()(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 如果需要下采样或通道不匹配，调整 shortcut</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>if</span> downsample:
</span></span><span style=display:flex><span>        shortcut <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>Conv2D(filters, <span style=color:#bd93f9>1</span>, strides<span style=color:#ff79c6>=</span>stride, use_bias<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>)(shortcut)
</span></span><span style=display:flex><span>        shortcut <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>BatchNormalization()(shortcut)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 将输入（shortcut）和输出相加</span>
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>Add()([x, shortcut])
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>ReLU()(x)
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> x
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>build_resnet</span>(input_shape, num_classes):
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    构建 ResNet-18 模型
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    - input_shape: 输入图像的形状 (H, W, C)
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    - num_classes: 输出类别数量
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    :return ResNet 模型
</span></span></span><span style=display:flex><span><span style=color:#f1fa8c>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    inputs <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>Input(shape<span style=color:#ff79c6>=</span>input_shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 初始卷积层和池化层</span>
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>Conv2D(<span style=color:#bd93f9>64</span>, <span style=color:#bd93f9>7</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>, use_bias<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>)(inputs)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>BatchNormalization()(x)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>ReLU()(x)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>MaxPooling2D(pool_size<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3</span>, strides<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, padding<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;same&#39;</span>)(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 残差块阶段</span>
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> residual_block(x, <span style=color:#bd93f9>64</span>)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> residual_block(x, <span style=color:#bd93f9>64</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> residual_block(x, <span style=color:#bd93f9>128</span>, stride<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, downsample<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> residual_block(x, <span style=color:#bd93f9>128</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> residual_block(x, <span style=color:#bd93f9>256</span>, stride<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, downsample<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> residual_block(x, <span style=color:#bd93f9>256</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> residual_block(x, <span style=color:#bd93f9>512</span>, stride<span style=color:#ff79c6>=</span><span style=color:#bd93f9>2</span>, downsample<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> residual_block(x, <span style=color:#bd93f9>512</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 全局平均池化层</span>
</span></span><span style=display:flex><span>    x <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>GlobalAveragePooling2D()(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 全连接层输出分类结果</span>
</span></span><span style=display:flex><span>    outputs <span style=color:#ff79c6>=</span> layers<span style=color:#ff79c6>.</span>Dense(num_classes, activation<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;softmax&#39;</span>)(x)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#6272a4># 创建模型</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> models<span style=color:#ff79c6>.</span>Model(inputs, outputs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 构建模型</span>
</span></span><span style=display:flex><span>resnet_model <span style=color:#ff79c6>=</span> build_resnet((<span style=color:#bd93f9>224</span>, <span style=color:#bd93f9>224</span>, <span style=color:#bd93f9>3</span>), <span style=color:#bd93f9>10</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 编译模型</span>
</span></span><span style=display:flex><span>resnet_model<span style=color:#ff79c6>.</span>compile(
</span></span><span style=display:flex><span>    optimizer<span style=color:#ff79c6>=</span>tf<span style=color:#ff79c6>.</span>keras<span style=color:#ff79c6>.</span>optimizers<span style=color:#ff79c6>.</span>Adam(learning_rate<span style=color:#ff79c6>=</span><span style=color:#bd93f9>0.001</span>),
</span></span><span style=display:flex><span>    loss<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;sparse_categorical_crossentropy&#39;</span>,
</span></span><span style=display:flex><span>    metrics<span style=color:#ff79c6>=</span>[<span style=color:#f1fa8c>&#39;accuracy&#39;</span>]
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 输出模型结构</span>
</span></span><span style=display:flex><span>resnet_model<span style=color:#ff79c6>.</span>summary()
</span></span></code></pre></td></tr></table></div></div><h3 id=openvc>OpenVC<a hidden class=anchor aria-hidden=true href=#openvc>#</a></h3><p>OpenCV 是一个计算机视觉的工具库，安装：</p><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span><span style=color:#6272a4># 3.4.2之后有一些算法申请专利用不了了</span>
</span></span><span style=display:flex><span>pip install opencv-python<span style=color:#ff79c6>==</span>3.4.1.15
</span></span><span style=display:flex><span><span style=color:#6272a4># 两个工具的版本要一致</span>
</span></span><span style=display:flex><span>pip install opencv-contrib-python<span style=color:#ff79c6>==</span>3.4.1.15
</span></span></code></pre></td></tr></table></div></div><p>基本操作：</p><div class=highlight><div style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>import</span> cv2
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 读取图像,读取进来的数据是一个3维数组(numpy的ndarray)：像素点是2维的 + 通道的维度</span>
</span></span><span style=display:flex><span><span style=color:#6272a4># IMREAD_GRAYSCALE表示读取方式是灰度图,灰度图的通道只有1</span>
</span></span><span style=display:flex><span>img <span style=color:#ff79c6>=</span> cv2<span style=color:#ff79c6>.</span>imread(<span style=color:#f1fa8c>&#39;xxx.jpg&#39;</span>, cv2<span style=color:#ff79c6>.</span>IMREAD_GRAYSCALE)
</span></span><span style=display:flex><span><span style=color:#6272a4># 输出图片数组的长度：长、宽、通道数</span>
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(img<span style=color:#ff79c6>.</span>shape)
</span></span><span style=display:flex><span><span style=color:#6272a4># 截取图像</span>
</span></span><span style=display:flex><span>cat <span style=color:#ff79c6>=</span> img[<span style=color:#bd93f9>0</span>:<span style=color:#bd93f9>200</span>, <span style=color:#bd93f9>0</span>:<span style=color:#bd93f9>200</span>]
</span></span><span style=display:flex><span><span style=color:#6272a4># 改变图像大小，这个不是截取而是拉伸或者压缩图像</span>
</span></span><span style=display:flex><span>dog <span style=color:#ff79c6>=</span> cv2<span style=color:#ff79c6>.</span>resize(img, (<span style=color:#bd93f9>200</span>, <span style=color:#bd93f9>200</span>))
</span></span><span style=display:flex><span><span style=color:#6272a4># 提取颜色通道</span>
</span></span><span style=display:flex><span>b, g, r <span style=color:#ff79c6>=</span> cv2<span style=color:#ff79c6>.</span>split(img)
</span></span><span style=display:flex><span><span style=color:#6272a4># 合并通道</span>
</span></span><span style=display:flex><span>cv2<span style=color:#ff79c6>.</span>merge((b, g, r))
</span></span><span style=display:flex><span><span style=color:#6272a4># 边界填充，填充类型有很多，比如BORDER_REPLICATE表示复制最近像素</span>
</span></span><span style=display:flex><span>cv2<span style=color:#ff79c6>.</span>copyMakeBorder(img, <span style=color:#bd93f9>10</span>, <span style=color:#bd93f9>10</span>, <span style=color:#bd93f9>10</span>, <span style=color:#bd93f9>10</span>, borderType<span style=color:#ff79c6>=</span>cv2<span style=color:#ff79c6>.</span>BORDER_REPLICATE)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#6272a4># 读取视频</span>
</span></span><span style=display:flex><span>open1 <span style=color:#ff79c6>=</span> <span style=color:#ff79c6>False</span>
</span></span><span style=display:flex><span>vc <span style=color:#ff79c6>=</span> cv2<span style=color:#ff79c6>.</span>VideoCaptrue(<span style=color:#f1fa8c>&#39;xxx.mp4&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#ff79c6>if</span> vc<span style=color:#ff79c6>.</span>isOpened():
</span></span><span style=display:flex><span>    open1, frame <span style=color:#ff79c6>=</span> vc<span style=color:#ff79c6>.</span>read()
</span></span><span style=display:flex><span><span style=color:#6272a4># 视频读取就是把每帧都读取成图片数组</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>while</span> open1:
</span></span><span style=display:flex><span>    ret, frame <span style=color:#ff79c6>=</span> vc<span style=color:#ff79c6>.</span>read()
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>if</span> frame <span style=color:#ff79c6>is</span> <span style=color:#ff79c6>None</span>:
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>break</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>if</span> ret:
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 3通道转成灰度图</span>
</span></span><span style=display:flex><span>        gray <span style=color:#ff79c6>=</span> cv2<span style=color:#ff79c6>.</span>cvtColor(frame, cv2<span style=color:#ff79c6>.</span>COLOR_BGR2GRAY)
</span></span><span style=display:flex><span>        cv2<span style=color:#ff79c6>.</span>imshow(<span style=color:#f1fa8c>&#39;result&#39;</span>, gray)
</span></span><span style=display:flex><span>        <span style=color:#6272a4># 每0.1s播放下一帧，27是esc按键，意思是按esc退出播放</span>
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>if</span> cv2<span style=color:#ff79c6>.</span>waitKey(<span style=color:#bd93f9>100</span>) <span style=color:#ff79c6>&amp;</span> <span style=color:#bd93f9>0xFF</span> <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>27</span>:
</span></span><span style=display:flex><span>            <span style=color:#ff79c6>break</span>
</span></span><span style=display:flex><span>vc<span style=color:#ff79c6>.</span>release()
</span></span><span style=display:flex><span>cv2<span style=color:#ff79c6>.</span>destroyAllWindows()
</span></span></code></pre></td></tr></table></div></div><p>它还可以处理图像的阈值、平滑、腐蚀、膨胀、开闭运算等等。</p><h5 id=信用卡数字识别>信用卡数字识别<a hidden class=anchor aria-hidden=true href=#信用卡数字识别>#</a></h5><h5 id=ocr识别>OCR识别<a hidden class=anchor aria-hidden=true href=#ocr识别>#</a></h5><h5 id=图像特征>图像特征<a hidden class=anchor aria-hidden=true href=#图像特征>#</a></h5><h5 id=全景图象拼接>全景图象拼接<a hidden class=anchor aria-hidden=true href=#全景图象拼接>#</a></h5><h5 id=停车场车位识别>停车场车位识别<a hidden class=anchor aria-hidden=true href=#停车场车位识别>#</a></h5><h5 id=答题卡判卷>答题卡判卷<a hidden class=anchor aria-hidden=true href=#答题卡判卷>#</a></h5><h5 id=背景建模>背景建模<a hidden class=anchor aria-hidden=true href=#背景建模>#</a></h5><h5 id=光流估计>光流估计<a hidden class=anchor aria-hidden=true href=#光流估计>#</a></h5><h5 id=dnn模块>DNN模块<a hidden class=anchor aria-hidden=true href=#dnn模块>#</a></h5><h5 id=目标追踪>目标追踪<a hidden class=anchor aria-hidden=true href=#目标追踪>#</a></h5><h5 id=卷积原理>卷积原理<a hidden class=anchor aria-hidden=true href=#卷积原理>#</a></h5><h5 id=疲劳检测>疲劳检测<a hidden class=anchor aria-hidden=true href=#疲劳检测>#</a></h5><h3 id=四图像分割>四、图像分割<a hidden class=anchor aria-hidden=true href=#四图像分割>#</a></h3><p>图像分割是目标检测的进阶，就是为图像中的每个像素进行分类，可以用在自动驾驶，医疗影像诊断，图片美化等领域。主要分2类，语义分割和实例分割，实例分割分割不仅仅要区分类别，还要区分不同类别中的不同个体。</p><p>常用的开源数据集有VOC、coco、城市风光数据集(自动驾驶模型专用)。</p><h4 id=1-评价指标>1 评价指标<a hidden class=anchor aria-hidden=true href=#1-评价指标>#</a></h4><ol><li>像素精度</li><li>平均像素精度</li><li>平均交并比</li></ol><h4 id=2-语义分割>2 语义分割<a hidden class=anchor aria-hidden=true href=#2-语义分割>#</a></h4><h5 id=21-fcn>2.1 FCN<a hidden class=anchor aria-hidden=true href=#21-fcn>#</a></h5><p>FCN使用全卷积架构，是目前图像分割算法的基础框架。 除了全卷积层还多了一个上采样层，上采样层使用<strong>反卷积</strong>可以将低分辨率的特征图恢复到原图相同的尺寸。</p><p>FCN还引入的跳跃连接，让不同层次的特征图进行融合，可以保留高层语义信息和底层空间信息，提高分割精度和保留更多细节。</p><h5 id=22-unet>2.2 Unet<a hidden class=anchor aria-hidden=true href=#22-unet>#</a></h5><p>采用<strong>对称的编码器-解码器（Encoder-Decoder）</strong> 结构，类似英文字母 &ldquo;U&rdquo; 的形状。编码器就是卷积层，卷积核是3*3，通道数递增，解码器就是采样层，通道数递减，适合高分辨率图像分割。</p><h4 id=3-实例分割>3 实例分割<a hidden class=anchor aria-hidden=true href=#3-实例分割>#</a></h4><h5 id=31-maskrcnn>3.1 MaskRCNN<a hidden class=anchor aria-hidden=true href=#31-maskrcnn>#</a></h5><p>就是在faster-RCNN的基础上增加一个分支，实现目标检测的同时分割目标像素。</p><h4 id=4-segment-anything>4 Segment Anything<a hidden class=anchor aria-hidden=true href=#4-segment-anything>#</a></h4><p>23年Facebook开源的图片分割<strong>大模型</strong>，这是第一个视觉大模型，基于VIT增加了数据引擎和提示词编码器：</p><ol><li>数据引擎：由模型自己创建训练的标记数据。</li><li>提示词系统：通过提示告诉模型要分割哪些物体，而不是和传统模型一样只能自动分割样本数据中的物体。</li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://wangxiaohong123.github.io/tags/%E8%AE%A1%E7%AE%97%E8%AE%A1%E8%A7%86%E8%A7%89/>计算计视觉</a></li></ul><nav class=paginav><a class=prev href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/leecode/6.%E6%9C%80%E5%B0%8F%E6%A0%88/><span class=title>« Prev</span><br><span>6.最小栈</span>
</a><a class=next href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/spring/cloud-alibaba/cloud-alibaba-demo%E4%B9%8B%E8%AE%A2%E5%8D%95/6.%E9%99%90%E6%B5%81%E7%86%94%E6%96%AD/><span class=title>Next »</span><br><span>6.限流熔断</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 6.计算机视觉(CV)介绍 on x" href="https://x.com/intent/tweet/?text=6.%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89%28CV%29%e4%bb%8b%e7%bb%8d&amp;url=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f6.%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E8%25A7%2586%25E8%25A7%2589%25E4%25BB%258B%25E7%25BB%258D%2f&amp;hashtags=%e8%ae%a1%e7%ae%97%e8%ae%a1%e8%a7%86%e8%a7%89"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 6.计算机视觉(CV)介绍 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f6.%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E8%25A7%2586%25E8%25A7%2589%25E4%25BB%258B%25E7%25BB%258D%2f&amp;title=6.%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89%28CV%29%e4%bb%8b%e7%bb%8d&amp;summary=6.%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89%28CV%29%e4%bb%8b%e7%bb%8d&amp;source=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f6.%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E8%25A7%2586%25E8%25A7%2589%25E4%25BB%258B%25E7%25BB%258D%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 6.计算机视觉(CV)介绍 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f6.%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E8%25A7%2586%25E8%25A7%2589%25E4%25BB%258B%25E7%25BB%258D%2f&title=6.%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89%28CV%29%e4%bb%8b%e7%bb%8d"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 6.计算机视觉(CV)介绍 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f6.%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E8%25A7%2586%25E8%25A7%2589%25E4%25BB%258B%25E7%25BB%258D%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 6.计算机视觉(CV)介绍 on whatsapp" href="https://api.whatsapp.com/send?text=6.%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89%28CV%29%e4%bb%8b%e7%bb%8d%20-%20https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f6.%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E8%25A7%2586%25E8%25A7%2589%25E4%25BB%258B%25E7%25BB%258D%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 6.计算机视觉(CV)介绍 on telegram" href="https://telegram.me/share/url?text=6.%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89%28CV%29%e4%bb%8b%e7%bb%8d&amp;url=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f6.%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E8%25A7%2586%25E8%25A7%2589%25E4%25BB%258B%25E7%25BB%258D%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 6.计算机视觉(CV)介绍 on ycombinator" href="https://news.ycombinator.com/submitlink?t=6.%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89%28CV%29%e4%bb%8b%e7%bb%8d&u=https%3a%2f%2fwangxiaohong123.github.io%2fposts%2fai%2f6.%25E8%25AE%25A1%25E7%25AE%2597%25E6%259C%25BA%25E8%25A7%2586%25E8%25A7%2589%25E4%25BB%258B%25E7%25BB%258D%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>