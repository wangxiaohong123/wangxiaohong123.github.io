<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | 王小红的笔记</title><meta name=keywords content><meta name=description content="Posts - 王小红的笔记"><meta name=author content><link rel=canonical href=https://wangxiaohong123.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://wangxiaohong123.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://wangxiaohong123.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://wangxiaohong123.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://wangxiaohong123.github.io/apple-touch-icon.png><link rel=mask-icon href=https://wangxiaohong123.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://wangxiaohong123.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://wangxiaohong123.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://wangxiaohong123.github.io/posts/"><meta property="og:site_name" content="王小红的笔记"><meta property="og:title" content="Posts"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://wangxiaohong123.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://wangxiaohong123.github.io/ accesskey=h title="王小红的笔记 (Alt + H)">王小红的笔记</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://wangxiaohong123.github.io/posts/ title=笔记><span class=active>笔记</span></a></li><li><a href=https://wangxiaohong123.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://wangxiaohong123.github.io/categories/ title=分类><span>分类</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.两数之和</h2></header><div class=entry-content><p>题目： 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值target的那两个整数，并返回它们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。你可以按任意顺序返回答案。
根据题目可以得到的结论：
不管存在多少解，找到一个就可以返回，这是一个剪枝条件； 数组中的每个元素只能使用一次； 下标返回可以无序，无序的结果对算法的限制更小； 首先想到的暴力算法有两种，一种是随机，一种是循环：
1：随机算法
随机算法就是随机取一个数，然后在随机取一个数，当两个数的索引不相等时判断两数之和，这个思路简单，关键就是要计算随机多少次
首先先看抛硬币的概率问题，当假设硬币只有正反两种结果的时候，连续抛出两次，最少有一次为正面的概率并不是100%，因为正面的概率是0.5，至少有一次为正面的概率并不是0.5+0.5，而是1-(1-0.5)^2^，意思是1-连续两次都是不好的结果的概率，所以当我随机取一个数的时候正确的概率是1/n，那么循环n(n是数组长度)次时，全部未命中的概率是(1-1/n)^n^，然后在带入e的极限公式得到： $$ (1-\frac 1 n)^n \ =(1+\frac 1 {-n})^n \ =[(1+\frac 1 {-n})^{-n}]^{-1} \ 因为e=(1+\frac 1 n)^n \ 所以，命中概率=e^{-1} \approx 1/3 $$ 所以至少命中一次的概率约等于2/3，也就是说遍历2n次至少会有一次命中，那么连续两次都命中需要遍历(2n)^2^次，代码如下，leecode已通过：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public int[] twoSumRandom(int[] nums, int target) { int[] ret = new int[2]; Random r = new Random(); int length = nums.length; int i,j; for (int count = 0; count &lt; Math.pow(2 * length, 2); count++) { i = r.nextInt(length); do { j = r.nextInt(length); } while (i == j); if (nums[i] + nums[j] == target) { return new int[]{i,j}; } } return ret; } 时间复杂度的话最外层就已经是(2n)^2^的了，然后里层还有一个while循环，但是可以忽略，复杂度的话就是n^2^
...</p></div><footer class=entry-footer>3 min</footer><a class=entry-link aria-label="post link to 1.两数之和" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E7%AE%97%E6%B3%95/leecode/1.%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.分库分表-sharding_sphere</h2></header><div class=entry-content><p>sharding-sphere仅仅是一个框架，业务引入依赖就可以使用了，通过一些配置，他就会根据指定sharding字段路由，执行SQL，[官网][https://shardingsphere.apache.org/index_zh.html]。现在sharding-sphere也有proxy server模式了，它还支持主键生成、事务(最终一致性、XA)、数据迁移、数据可视化链路追踪、扩容等，就是说基本上除了垮裤跨表的复杂查询，分库分表用到的功能他基本上都有了，最早是当当开源出来的。
mycat是proxy server模式，需要独立部署server端，然后在业务引入client依赖，所有SQL通过client发送到server</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 1.分库分表-sharding_sphere" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/2.sharding-sphere/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.分库分表-介绍</h2></header><div class=entry-content><p>1.怎么拆 分库分表之前要考虑怎么拆分，一般都是先垂直后水平，首先垂直拆分把表的列按模块尽可能分到不同的库中，这样可能会解决读写并发压力过大的问题和单条数据过大导致磁盘瓶颈问题，然后在考虑水平拆分。
然后在考虑用什么技术，一般就是sharding-sphere和mcat。
2.唯一id 使用leaf
3.多场景不同条件查询 比如电商的订单，用户可以查询自己的id获取订单记录，商家可以根据自己的id获取订单记录，这个时候是以用户id路由，保证同一个用户的订单分到了同一张表还是以商家id路由，如果不考虑存储空间就都做，这样数据量会变成原来的两倍，如果考虑存储空间就以经常访问的业务作为路有条件，其他的可以二次路由。
4.分布式事务 分库分表后由于规则不同，比如订单使用用户id作为路由条件，订单条目使用订单id作为路由条件，这样就会导导致跨库的事务，就需要使用XA事务。
5.查询条件中没有sharding字段 比如查询是一堆组合条件，可以用sharding-jdbc之类的中间件，他会去所有表中把符合条件的数据都merge到一台机器的内存中，这个很慢也很占带宽，可以把条件放到es中， 根据条件查询出sharding字段，在回表查询。分库分表之后使用es抗复杂查询是不可避免的。
6.读写分离 使用一主多从分摊大部分的查询请求，这样一主多从抗住80%的crud，es抗住20%的复杂查询。
7.物理架构的规划 一般表就是1024张，库的话需要根据写并发和数据大小做出规划，比如高峰时这个库有多少tps，未来是否会增长，然后每天增长多少数据，计算主库和从库的配置，分几台主库，es要几台服务器，几个分片，保证分库之后可以抗几年。
8.数据迁移 首先开发一个数据同步加检测的程序，同步就一直在同步，检测也是一直在检测，保证某一个时间点时之后旧库和新库的数据完全一致。 然后在开发新系统，数据的crud全部打到新数据库中。 进行双写，比如使用nginx把一个请求分发到两套系统里，停掉数据同步，只开启数据检测。 运行一段时间后如果检测没有问题修改nginx，把请求只打到新程序中，停掉旧程序完成数据迁移。 9.控制台 分库分表之前需要操作控制台实现大量的DDL操作，不能每个表拆成1024张都手动去操作吧，以后新业务需要新表新库的时候也不能手动操作吧，太没效率了，在分库分表之后还需要监控每个库表的性能、负载，还需要知道每张物理表的数据量，占用空间，1024张物理表组成的大逻辑表一共有多少数据等等。
10.扩容问题 之前创建的1024张表在扩容时可以直接移动表，不需要重新把路由数据，但是在迁移表的时候还要考虑迁移的时候数据写入问题、迁移之后数据库配置，这也是很麻烦的，可以编写一套脚本，然后在控制台控制执行，在来一个配置中心，也可以是控制台，修改数据库连接之类的。</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 1.分库分表-介绍" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/1.%E4%BB%8B%E7%BB%8D/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.基础</h2></header><div class=entry-content><p>1.源码编译 源码的README.md有编译源码的步骤，但是由于操作系统、硬件环境可能会出现一些问题，而且文档里说的是没有开发工具的情况，这里我们自己把源码下载直接导入到idea里。
首先确保idea里配置好了git，然后下载gradle5.6安装。
1）修改配置文件 然后进入下载的spring源码的根目录，这里下载的是5.2.x，找到build.gradle文件，修改repositories属性为阿里云镜像：
1 2 3 4 5 6 7 8 9 repositories { // mavenCentral() // maven { url "https://repo.spring.io/libs-spring-framework-build" } maven { url "https://maven.aliyun.com/nexus/content/groups/public/"} maven { url "https://maven.aliyun.com/nexus/content/repositories/jcenter"} maven { url "https://repo.spring.io/libs-spring-framework-build" } maven { url "https://repo.spring.io/snapshot" } // Reactor maven { url "https://oss.jfrog.org/artifactory/oss-snapshot-local" } // RSocket } 在spring源码的根目录的gradle.properties文件中可以查看当前源码的小版本，我的是5.2.23：
...</p></div><footer class=entry-footer>2 min</footer><a class=entry-link aria-label="post link to 1.基础" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/spring/framework/1.%E5%9F%BA%E7%A1%80/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.机器学习介绍</h2></header><div class=entry-content><p>图灵在50年的时候提出机器思维：一个人在不知道对方是计算机的情况下进行很长时间的问答，如果无法判断对方是不是计算机就说明这个计算机有了人的思维。56年的时候麦卡锡提出了人工智能的术语。
柏拉图假说：不同的人工智能系统以不同的方式表示世界，视觉系统表示为形状和颜色，语言模型表示为语法和语义；但是随着参数规模、训练数据的不断扩大，不同模型对于现实的表征方式会越来越相似，所以现在的大语言模型或者文生视频这种其他模型都使用全模态(文本、视频、音频、深度图等)数据来训练，比单一模态数据性能提高20%。这就发展成现在很多模型都是在大语言模型上微调来的，比如qwen2-VL是基于qwen2的，CogVLM2机遇llama3 8b微调来的。
1 介绍 人工智能发展阶段
1.1 人工智能 三要素：数据，算法，计算力，CPU核心数较少，基于冯诺依曼架构(存储程序，顺序执行)，适合逻辑控制，处理复杂的指令集；GPU核心数较多，适合并行处理大量简单且重复的指令，比如矩阵、向量计算；TPU是Google专门为机器学习设计的芯片。
机器学习是人工智能的实现途径，而深度学习是机器学习发展而来，也就是神经网络。195x年最开始人工智能最多就是和人下个黑白棋，198x年开始使用机器学习分辨垃圾邮件，201x年开始深度学习让机器可以识别图片。
现在的模型分大模型和普通模型，普通模型就像专攻一样，训练的数据有10种类别，他就只能做这10种类别的事。大模型的不光是模型的架构大，也是数据集的大，大模型也可能自己创造训练数据，训练自己，比如segment anything。
1.1.1 当前人工智能目前主要应用领域 计算机视觉(CV)：机器感知环境的能力，比如物体检测和人脸识别。 自然语言处理(NLP)：自然语言处理又包括语音识别、机器翻译、文本挖掘和分类： 文本挖掘和分类：主要是对文字的情绪分析和垃圾检测，目前尤其是中文不同的词在不同的场景有不同的语义是一个难点。 机器翻译：方言、行话是难题。 语音：语音识别，语音合成什么的，音转文和文转音是一个领域，现在声纹识别和鸡尾酒会效应很难处理好。声纹和指纹差不多，每个人的声音都不一样，如果能提取出人的声纹那就可以实现声音支付了。鸡尾酒会是说人的大脑在和别人专心讨论的时候会自动降燥，专注和交流目标对话，目前计算机只能做到很多人说话，找不到应该重点听谁发出的声音。 1.2 机器学习算法分类 算法方向分为ML机器学习，DL深度学习，RL强化学习。
根据数据集组成可以将机器学习的算法分为监督学习、无监督学习、半监督学习和强化学习。如果输出是连续的成为回归，输出是有限个离散值叫分类。
监督学习：输入数据由特征值和目标值组成； 无监督学习：输入数据只有特征没有目标值； 半监督学习：输入数据部分没有目标值，适合数据难标记或者标记成本高的情况，先用少量标记初步训练，然后用未标记数据训练； 强化学习：强化学习是一个决策问题，可以做连续的自动决策，包含5个元素：agent(代理体)，action(行动)，reward(奖励)，environment(环境)和observation(观察情况)，比如让程序中的某个角色模拟走路，这个角色就是agent，他需要决定先迈左脚还是右脚，迈出一步还要不要在迈一步，迈步就是action，地面就是environment，走了几步可以给他reward。强化学习的目标是获得最多的累积奖励；他是不断跟环境交互获取经验，不断进步的过程。通过设计奖励惩罚机制，每正确n步会产生奖励，模型的本质就是获取更多奖励。ALPHAGo、机械手臂、deepseek R1模型都是强化学习实现的。强化学习更像有大脑在思考一样。 对比学习：相当于计算机视觉上的自监督学习，通过随机的图像增强让一张图片随机变成别的样子，但是还属于同一类，这样来代替打标签的操作，同类越相似的思想。如果数据增强变成了核心，数据越离谱学到的东西可能就越多，越花里胡哨效果越好。 监督学习输入的特征都是独立同分布的，独立说的是每次抽样之间相互独立，没有影响，比如掷2次骰子的和大于8，第二次的结果和第一次相关，就不是独立的；同分布说的是每次抽样的样本服从同一个分布，比如掷骰子，每次得到任意点数的概率都是1/6。
1.2.1 强化学习算法 1.2.1.1 Proximal Policy Optimization(PPO)算法 核心思想：PPO 主要改进了策略梯度方法（如 REINFORCE）和信赖域策略优化（Trust Region Policy Optimization, TRPO），使其更加稳定、高效，并且易于实现。其核心思想包括：
克服策略更新的不稳定性： 在策略梯度方法中，策略的更新可能会导致较大的变化，从而影响学习稳定性。 TRPO 通过优化约束（KL 散度约束）限制策略更新的幅度，但实现较为复杂。 PPO 采用了一种更简单且高效的方法，即 剪辑（Clipping）策略比率 来约束策略的更新幅度。 使用信赖区域（Trust Region）控制策略更新幅度： PPO 通过 目标函数中的剪辑项 限制策略的更新步长，从而避免策略发生剧烈变化，提高训练稳定性。 PPO 的两种变体：
PPO-Clip（剪辑版 PPO）： 直接对策略比率（ratio）进行剪辑，确保策略不会更新过大。 目标函数： $L^{clip}(θ)=E[min⁡(r_t(θ)A_t,clip(r_t(θ),1−ϵ,1+ϵ)A_t)]$ 其中： $r_t(θ)= \frac{\pi_{\theta}(a_t | s_t)}{\pi_{\theta_{\text{old}}}(a_t | s_t)}$（新的策略与旧的策略的比率） $A_t$ 为优势函数（Advantage Function） ϵ 是超参数（通常设为 0.1~0.2） PPO-Penalty（KL 散度惩罚版 PPO）： 在优化目标中添加 KL 散度（Kullback-Leibler Divergence）惩罚项，确保策略不会偏离过远： $L^{KL}(θ)=E[L^{clip}(θ)−βD_{KL}[π_{θold}∣∣π_θ]]$ 其中： $D_{\text{KL}}$ 表示旧策略与新策略之间的 KL 散度。 β 是一个超参数，用于调整 KL 惩罚的权重。 1.2.1.2 Q-learning和DQN Q-learing包括2部分，瞬时奖励(做了1个动作就能获得的奖励)和记忆经验奖励(按照训练时的记忆，之后怎么做才能获得更大的奖励)，DQN是对Q-learning的扩展，使用神经网络计算Q-learning函数的参数。
...</p></div><footer class=entry-footer>5 min</footer><a class=entry-link aria-label="post link to 1.机器学习介绍" href=https://wangxiaohong123.github.io/posts/ai/1.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.概念</h2></header><div class=entry-content><p>什么是搜索 当我们在百度里搜索关键词的时候就是一个搜索的过程，但是搜索不光是百度，还有一些垂直搜索（站内搜索）比如淘宝里搜一下商品关键字，比如OA系统搜个打卡统计之类的。简单来说就是在任何场景下输入关键字会返回一些想要的信息。
倒排索引 就是把数据拆成词，每个词对应着一条数据的id之类的东西。 比如有3条数据：1 生化危机电影，2 生化危机海报， 3 生化危机新闻，这3条数据生成的倒排索引就类似下面这样：
关键词 ids 生化 1,2,3 危机 1,2,3 生化危机 1,2,3 海报 2 新闻 3 电影 1 如果不考虑搜索优化，假设我们使用es或者lucene进行所有的时候，倒排索引的结构也要比MySQL全表扫描的模糊查询要快很多，因为这里相当于对关键词进行equals比较，而模糊搜索要检查是否包含。
全文检索 全文检索包括把数据插入倒排索引，然后把搜索条件拆词，每个词都去倒排索引中查找数据。
Lucene 就是一个jar包，里面封装好了很多建立倒排索引和全文检索的算法。用lucene可以把现有的数据在磁盘上建立索引，并且Lucene会帮我们组织索引的数据结构，还可用Lucene提供的api对磁盘上的索引数据进行搜索。
elasticsearch Lucene可以实现全文检索功能，但是他有很大的弊端：比如它不支持分布式，api有点复杂。 当我们的数据量在一台机器上放不下的时候，每次查询需要我们自己去各个Lucene机器上搜索，插入数据时也要自己维护索引所在机器，当某一台机器宕机，那这台机器上的数据就全搜不出来了。
所以分布式的搜索引擎elasticsearch就诞生了，对比Lucene而言，他自动冗余数据备份，更高可用，分布式存储更多的数据，自动维护数据到多个节点的索引，还封装了更多高级的功能。
ES功能 数据分析：比如查看最近七天的牙膏的销量前十的商家，每个商品分类下有多少商品。 数据搜索：全文检索和结构化检索，结构化检索就是根据类型，比如搜索日用品类型的商品。 搜索推荐、自动补全这些。 他是一个分布式的海量数据的近实时搜索引擎。
核心概念 Near Realtime（NRT），近实时，有两个意思，第1个是从写入到可查询到是秒级的延迟，第2个是搜索和分析也是秒级的延迟。 Cluster和Node，集群和节点，集群和节点都可以设置名字的，集群的默认名字是elasticsearch，节点的默认名字随机分配，如果节点没有配置集群的名字就会默认加入到elasticsearch集群中。 Document：es里的最小数据单元，就是一条数据。 field：document中的数据字段。 Index：索引，一个index包含很多document，index中是所有类似或者相同的document。 type：index中的document的逻辑分类，比如说index中有10000个document，1到3000个document的field一样，3001到6000的filed一样，6001到10000的id一样，那么就可以定义index中有三个type，type更像是MySQL中的一样表，而index像是一类数据库，新版本中废弃了，因为在es中存储是不区分type的。 shard：一个index可以包含多个shard，这些shared会散落在多台服务器上，这样搜索可以在多个服务器上并行执行，提升吞吐量。扩容时新创建一个更多的shard的index，把数据重新导入进去就可以了，他也叫primary shard，可以接受读写请求。 replica：就是shard的副本，也叫replica shard，每个shard可以有多个replica。replica也可以提供读的请求。 默认情况下每个index有5个shard，每个shard有一个replic，es规定了shard和replica不能在同一节点上，也就是说要部署在两台机器上。使用replica的第一个好处就是分摊查询的压力，提高吞吐，第2个好处就是保证高可用，shard宕机时进行切换。
es是面向文档的数据格式。
锁 es有三个粒度的锁，全局锁（加在索引上）；document锁；读写锁（共享锁和排它锁）；</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 1.概念" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/es/1.%E6%A6%82%E5%BF%B5/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.环境搭建</h2></header><div class=entry-content><p>1.安装jdk jdk版本：8u191
把rpm包传到虚拟机，执行命令安装：
1 rpm -ivh jdk-8u191-linux-x64.rpm 默认的安装目录是**/usr/java/**
配置环境变量，编辑.bash_profile文件：
1 vi ~/.bash_profile 在文件中添加JAVA_HOME：
1 2 export JAVA_HOME=/usr/java/latest export PATH=$PATH:$JAVA_HOME/bin 保存退出，刷新配置文件：
1 source ~/.bash_profile 2.安装MySQL 使用yum仓库安装mysql5.7版本：
1 2 3 4 5 wget http://repo.mysql.com//mysql57-community-release-el7-11.noarch.rpm yum localinstall mysql57-community-release-el7-11.noarch.rpm yum install -y mysql-community-server.x86_64 启动MySQL server：
...</p></div><footer class=entry-footer>3 min</footer><a class=entry-link aria-label="post link to 1.环境搭建" href=https://wangxiaohong123.github.io/posts/%E6%A1%86%E6%9E%B6/spring/cloud-alibaba/cloud-alibaba-demo%E4%B9%8B%E8%AE%A2%E5%8D%95/1.%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.环境配置</h2></header><div class=entry-content><p>macos 安装 1. 环境 按照网页https://docs.flutter.dev/community/china将镜像配置到环境变量中
1 2 export PUB_HOSTED_URL="https://pub.flutter-io.cn" export FLUTTER_STORAGE_BASE_URL="https://storage.flutter-io.cn" 按照网页https://docs.flutter.dev/install/archive下载sdk压缩包，增加配置到配置文件：
1 export PATH="/Users/xiaohong/flutter/flutter-3.32/bin:$PATH" 2.ios虚拟机 安装xcode。
3.android虚拟机 在android studio官网下载android studio并安装，安装完在设置中安装flutter插件。然后根据下图创建flutter项目(以后的flutter项目都这么创建，可以设置包名什么的)。
![androidstudio创建fluter项目](https://raw.githubusercontent.com/wangxiaohong123/p-bed/main/uPic/android studio创建fluter项目.png)
然后进入到tools->SDK Manager，选择需要的安卓sdk进行安装(在SDK Tools选项卡中需要额外选中Android SDK Command-line Tools (latest))。进入tools->Device Manager创建一个虚拟机。
然后在终端输入flutter doctor检测开发环境，可能会提示Some Android licenses not accepted. To resolve this, run: flutter doctor --android-licenses，如果提示这个就在终端执行下面命令，然后会依次弹出多份协议（大概 5~6 个），每次输入 y 回车接受即可。
1 flutter doctor --android-licenses 之后的开发可以通过android studio的虚拟机或者不启动android studio通过外链一个测试机来调试。</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 1.环境配置" href=https://wangxiaohong123.github.io/posts/flutter/1.%E5%AE%89%E8%A3%85/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.网络-基础</h2></header><div class=entry-content><p>一.TCP/IP和OSI 为什么要定义那么多层？
两台计算机用网线连接后就可以通信，但是世界有那么多计算机，不可能两两相连，而且传输的0/1信号，如果不是一个厂商的计算机不知道是什么意思，还有其他的问题，比如两个计算机怎么识别、怎么知道对方的IP、怎么知道这个数据是发给我的，所以要定义多层，每层解决不同的问题，国际标准化组织（OSI）制定了一套计算机或者通信系统互联的标准体系，这就是OSI七层网络模型。还有TCP/IP四层和TCP/IP五层，都是将七层合并简化出来的。
1.OSI七层网络模型 1）物理层 物理层就是表面意思，网线或者各国的光缆或者现在无线信号，物理层传输的是0/1电路信号。
2）数据链路层 计算机并不知道0/1是干啥的，而且一大串01过来计算机并不知道从那到那是一组数据，所以数据链路层定义了这些0/1电路信号如何分组，每组的描述，比如第一组是从计算机1到计算机2的，第二组是从计算机3到计算机4的。每组电路信号叫做就是一个数据包，也叫一帧（frame），每一帧由两部分组成：标头（head）和数据（data），标头包括一些描述性的东西，包括发送者、接受者、数据类型等。
最开始每个计算机厂商都自己定义分组方式，但是不同的厂商之间还是无法通信，所以以太网协议就诞生了。以太网规定每台接入网络的电脑必须有网卡，并且要使用网卡发送和接收数据，网卡必须要有一个唯一标识，也叫MAC地址。每块网卡出厂的时候都会产生一个MAC地址，MAC地址是48位的2进制，但是由12个16进制表示，前6位表示生产厂商，后6位是流水号，这样就会保证MAC地址的唯一，所以发送数据包时必须指定目标计算机的MAC地址，数据包发送出去后会通过以太网协议使用交换机广播给局域网（也叫子网）里的所有电脑，子网下的电脑收到包后会比较标头中的MAC地址，和自己一样的就接收。
1 2 # windows上查看MAC地址 ipconfig /all 3）网络层 通过以太网协议广播之前需要知道那些电脑在同一子网下，这个是通过网关来实现的，但是如果两台计算机不在同一子网下，这时候就会用到网络层，定义了一些IP协议，IP协议主要就是定义了IP地址、子网掩码，每个ip地址都会对应一个mac地址。
每一台计算机都有自己ip（外网），现在最普遍的是IPV4，由4位10进制或者32位2进制组成，据说快用完了，用的最多的ip是前三位表示网络号，最后一位表示主机(C类)，通过使用子网掩码（255.0.0.0/255.255.0.0/255.255.255.0）的网络位的二进制和ip的网络位的二进制做与运算，如果相同就表示在一个子网内。
不同子网通信就要用到路由器（标准的叫法是网关），路由器中有多块网卡，当不在同一子网的计算机通信时，标头中会多出一个真实的目标ip和路由器的MAC地址，首先会广播数据，但是MAC地址是路由器中的网卡，所以路由器会收到数据，收到数据后根据目标ip检索路由表找到MAC地址在替换MAC地址，再次发送，如果没找到mac地址会改成上层网关的mac继续发送。
ARP协议：每个子网中的计算机都有在子网下的所有计算机的ip和MAC的映射关系缓存，所以知道ip就知道MAC地址。
LAN：局域网；WAN：广域网；WLAN：无线局域网(就是WiFi)；家里的路由器是网关和交换机的结合体。
4）传输层 因为计算机上可能有很多程序，为了判断数据要交给那个程序，就需要传输层的端口号来判断这条数据是发送给哪个程序的，基于TCP或UDP协议可以实现端对端、点对点的数据传输，UDP协议不可靠，TCP是可靠的，因为TCP封装了一套完整的数据通信机制，比如三次握手、四次挥手，java的socket就是封装的TCP。
5）会话层 在应用直接建立、维护或者解除会话连接。
6）表示层 负责数据加密、压缩、格式转换。
7）应用层 这层定义了程序拿到数据后要知道怎么处理数据，最常见的就是http协议。
2.TCP/IP TCP/IP五层协议就是把会话层、表示层、应用层合并到一起，TCP/IP四层协议就是把物理层和数据链路层合并到一起，四层协议流程：
数据包格式：
3.DNS domain name system：就是将域名转换成ip地址的服务器。
操作系统里有一个socket库，和DNS解析器，通过这个DNS解析器操作socket库请求DNS服务，请求DNS服务器的过程也是通过TCP先建立连接，然后在请求查找域名对应的ip地址。每个电脑都可以设置DNS服务器的地址，或者设置自动获取DNS服务器地址。
全世界有差不多13台根域DNS服务器，数万台DNS服务器，当浏览器访问DNS服务器没找到这个域名的时候，就会去访问根域服务器，根域服务器知道.com域的DNS服务器，然后在访问管理.com的所有DNS服务器，然后找到管理google.com这个域名的DNS服务器，一层一层，直到找到labs.google.com这个域名所在的DNS服务器，然后拿到ip地址，把ip缓存之后再返回。
4.无线局域网和以太网之间是什么关系 无线局域网和以太网都是数据链路层的协议，其实就是打包方式不同，通过有线网卡或者无线网卡传输电信号给交换机，交换机可以使用无线局域网或者以太网方式继续广播。
5.ARP机制 ARP就是地址解析协议，询问目标ip对应的mac地址，计算机拿到地址后会缓存起来，在打包以太网数据包的时候就直接用了。
6.全双工和半双工 半双工就是计算机A和计算机B在交换机层面不能在同一时间相互发包，比如交换机收到了A发给B的包，这时候就不能收到B发给A的包，如果收到了就会发生信号碰撞。
全双工就是可以同时相互发。
7.粘包和拆包 通过tcp发数据的时候是一个流的形式，比如说数据很大，需要发两个包，这两个包的数据可能第一条消息占一个半，第二个消息占半个，服务器把这两个包当成一条消息来处理，这就是粘包。拆包就是说，因为是流数据，服务器可能收到了一半的数据就开始处理了，都是因为服务器不知道这个包有多长，到哪里应该结束了。
8.交换机和路由器 计算机打完数据包，找到交换机，交换机通过mac地址发给路由器，路由器进行拆包，然后拿到目标ip，这样就知道该发给那个路由器，然后在根据下一个路由器的mac地址进行打包，封成新的以太网协议包，发送出去，所以交换机是数据链路层，网关是工作在网络层的。
9.调制解调器 modem：就是猫，他在收到数据包以后拆分成信源，然后转成电信号，通过网线发给运营商的路由器。
Netty JDk提供的NIO是对对IO的封装，比如磁盘IO，网络IO，Netty就是把网络IO进行封装的框架，提供网络通信的API。
Netty的原理就是客户端和服务端有很多个EventLoop线程、selector（多路复用组件），客户端和服务端建立连接之后两个端的SocketChannel就会绑定，这时候服务端的SocketChannel就会注册到selector上，selector对应的是多个EventLoop去不断轮询，比如说现在有20个链接，四个EventLoop，那么也就是有四个selector每个EventLoop会监听五个链接，这五个SocketChannel注册到同一个selector上，收到客户端的请求之后就会把请求解析交给Handler Pipline（系统处理逻辑）处理，处理完成也是通过SocketChannel给客户端响应，客户端同样的也是使用EventLoop监听，解析交给Pipline处理。</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 1.网络-基础" href=https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E7%BD%91%E7%BB%9C/1.%E5%9F%BA%E7%A1%80/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>1.记一次生产服务堆外内存泄露</h2></header><div class=entry-content><p>除夕放假前一天运营跟我说app用不了，赶紧起来查看，线上监控使用的阿里arms并没有报警信息，应用状态也都正常。 怀疑那个中间件欠费导致，但是没找到。 然后又去看了下管理后台是可用的，因为我们后台和app的代码是分开的，并没有使用app的网关，所以猜测网关除了问题，在进入arms查看果然网关掉线了。
登录网关服务器检查oom日志和GC日志，并没有OOM日志，GC也都正常，然后进入/var/log/查看messages文件看看是不是操作系统把进程杀死，果然看到了日志： 操作系统内存溢出把网关进程杀死，anon-rss就是网关进程malloc出来的内存，可以理解成实际使用内存，7个G很高了，但是total-vm更高，先看一下服务的启动参数，看到堆内存分配了6个G，元数据空间256M，再加上栈什么的7个G也差不多，然后我把堆内存调成4G，重启网关，并在arms中添加内存报警规则，启动之前我在启动参数中增加参数：
1 2 3 # 打开NMT会带来5%－10%的性能损耗 # 可以使用jcmd 5687 VM.native_memory shutdown关闭NMT -XX:NativeMemoryTracking=detail 因为total-vm过大，而网关进程已经被杀死，防止不是堆内存问题导致的操作系统OOM到时候可以使用jcmd pid VM.native_memory detail scale=MB >temp.txt查看内存分布。
果然没过几天突然收到内存报警，还是网关，使用top命令查看内存使用已经快6个G了： virt是申请的大小，res是实际使用的大小，这两个不管那个都很大，然后我使用一下命令把内存分布输出到文件里:
1 jcmd 5687 VM.native_memory detail scale=MB > temp.txt 可以看到Internal占用很大，使用命令jmap -heap 5687看一下是否是元数据空间过大，但是并没有，怀疑是堆外内存溢出。
如果不是堆外内存的问题可以使用以下命令分析内存快照，使用mat分析：
1 jmap -dump:live,format=b,file=gateway.hprof 5687 排查堆外内存泄露 使用strace追踪申请内存请求：
1 strace -Ff -ebrk,mmap,munmap -p 5687 这里看不出来异常申请，而且在系统运行几天之后才会出现内存泄漏，所以尝试使用pmap查看内存分配情况：
...</p></div><footer class=entry-footer>1 min</footer><a class=entry-link aria-label="post link to 1.记一次生产服务堆外内存泄露" href=https://wangxiaohong123.github.io/posts/%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98/1.%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E6%9C%8D%E5%8A%A1%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://wangxiaohong123.github.io/posts/page/6/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://wangxiaohong123.github.io/posts/page/8/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://wangxiaohong123.github.io/>王小红的笔记</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>