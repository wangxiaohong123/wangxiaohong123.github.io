<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Posts | 王小红的笔记</title>
<meta name="keywords" content="">
<meta name="description" content="Posts - 王小红的笔记">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css" integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="http://localhost:1313/posts/index.xml">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="/katex/katex.min.css">
<script defer src="/katex/katex.min.js"></script>
<script defer src="/katex/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: "$$", right: "$$", display: true},
        {left: "$", right: "$", display: false},
        {left: "\\(", right: "\\)", display: false},
        {left: "\\[", right: "\\]", display: true}
      ]
    });
  });
</script>

</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="王小红的笔记 (Alt + H)">王小红的笔记</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/posts/" title="笔记">
                    <span class="active">笔记</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/" title="分类">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="标签">
                    <span>标签</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    Posts
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">12.kafka源码-副本同步机制
    </h2>
  </header>
  <div class="entry-content">
    <p>大致流程 之前在看刷盘的源码的时候看到初始化ReplicaManager的时候创建了一些组件，其中就有一个replicaFetcherManager，看名字就知道这个是负责副本同步的，他实例化了一个ReplicaFetcherManager对象，这个类只有两个方法，createFetcherThread()和shutdown()，再进父类AbstractFetcherManager中看一下，发现父类中多了两个方法：addFetcherForPartitions和removeFetcherForPartitions，add方法就是为一部分分区创建同步的线程，回到ReplicaManager中找一下在哪用到了add方法，然后就找到了方法：makeFollowers()，思路大概就懂了，在broker感知到自己负责了某个partition的副本后，就调用这个方法，然后创建线程，不断地拉取和更新数据，首先看下方法注释：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /* * 说得是让这个broker负责的一批partition变成follower都有哪些步骤 * Make the current broker to become follower for a given set of partitions by: * * 把这些分区的leader从leader的set中移除 * 1. Remove these partitions from the leader partitions set. * 把这些partition标记成follower，这样任何producer都不能往这写分区中写数据 * 2. Mark the replicas as followers so that no more data can be added from the producer clients. * 对这些分区停止已有的replica fetcher线程 * 3. Stop fetchers for these partitions so that no more data can be added by the replica fetcher threads. * 把这些分区的日志阶段，记录offset * 4. Truncate the log and checkpoint offsets for these partitions. * 清理掉分区的延迟调度 * 5. Clear the produce and fetch requests in the purgatory * 给新的副本分区添加fetcher * 6. If the broker is not shutting down, add the fetcher to the new leaders. * * 保证不会有脏数据 */ 进到AbstractFetcherManager的addFetcherForPartitions()方法，循环创建fetcherThread：
...</p>
  </div>
  <footer class="entry-footer"><span title='2021-09-25 06:27:35 +0000 UTC'>September 25, 2021</span>&nbsp;·&nbsp;4 min</footer>
  <a class="entry-link" aria-label="post link to 12.kafka源码-副本同步机制" href="http://localhost:1313/posts/%E6%A1%86%E6%9E%B6/mq/kafka/12.%E5%89%AF%E6%9C%AC%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">11.kafka源码-磁盘操作
    </h2>
  </header>
  <div class="entry-content">
    <p>之前启动的时候看到了跟磁盘有关的两个组件，一个是LogManager，还有一个是ReplicaManager，而且在初始化ReplicaManager的时候LogManager是被当做参数传进去的，先看一下ReplicaManager都实例化了那些东西：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 // 配置的brokerId private val localBrokerId = config.brokerId // 所有的partition信息 private val allPartitions = new Pool[(String, Int), Partition](valueFactory = Some { case (t, p) =&gt; new Partition(t, p, time, this) }) // 这个就是一把锁 private val replicaStateChangeLock = new Object val replicaFetcherManager = new ReplicaFetcherManager(config, this, metrics, jTime, threadNamePrefix) // 高水位的检查，只有当所有的副本都保存了消息，高水位才会指向最新的消息 // 消费者只能消费到高水位之前的消息 private val highWatermarkCheckPointThreadStarted = new AtomicBoolean(false) val highWatermarkCheckpoints = config.logDirs.map(dir =&gt; (new File(dir).getAbsolutePath, new OffsetCheckpoint(new File(dir, ReplicaManager.HighWatermarkFilename)))).toMap private var hwThreadInitialized = false val stateChangeLogger = KafkaController.stateChangeLogger // isr列表相关 // 当follower没有落后太多的时候才会出现在isr列表 private val isrChangeSet: mutable.Set[TopicAndPartition] = new mutable.HashSet[TopicAndPartition]() private val lastIsrChangeMs = new AtomicLong(System.currentTimeMillis()) private val lastIsrPropagationMs = new AtomicLong(System.currentTimeMillis()) // 延迟调度机制，实践论的算法 val delayedProducePurgatory = DelayedOperationPurgatory[DelayedProduce]( purgatoryName = &#34;Produce&#34;, config.brokerId, config.producerPurgatoryPurgeIntervalRequests) val delayedFetchPurgatory = DelayedOperationPurgatory[DelayedFetch]( purgatoryName = &#34;Fetch&#34;, config.brokerId, config.fetchPurgatoryPurgeIntervalRequests) // 本地存储的leader数 val leaderCount = newGauge(&#34;LeaderCount&#34;, new Gauge[Int] { def value = { getLeaderPartitions().size } }) // 本地的分区数 val partitionCount = newGauge(&#34;PartitionCount&#34;, new Gauge[Int] { def value = allPartitions.size }) // 副本数量不充足的partition val underReplicatedPartitions = newGauge(&#34;UnderReplicatedPartitions&#34;, new Gauge[Int] { def value = underReplicatedPartitionCount() }) // isr列表扩张和伸缩的速率 val isrExpandRate = newMeter(&#34;IsrExpandsPerSec&#34;, &#34;expands&#34;, TimeUnit.SECONDS) val isrShrinkRate = newMeter(&#34;IsrShrinksPerSec&#34;, &#34;shrinks&#34;, TimeUnit.SECONDS) // 下面还有一些函数和线程之类的 初始化完ReplicaManager之后执行startup方法，启动两个关于isr的定时调度线程：
...</p>
  </div>
  <footer class="entry-footer"><span title='2021-09-21 06:27:35 +0000 UTC'>September 21, 2021</span>&nbsp;·&nbsp;9 min</footer>
  <a class="entry-link" aria-label="post link to 11.kafka源码-磁盘操作" href="http://localhost:1313/posts/%E6%A1%86%E6%9E%B6/mq/kafka/11.%E7%A3%81%E7%9B%98%E6%93%8D%E4%BD%9C%E6%BA%90%E7%A0%81/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">10.kafka源码-服务端网络通信
    </h2>
  </header>
  <div class="entry-content">
    <p>在本地安装scala2.10.7、gradle3.1、和zk。
到kafka官网下载0.10.01的源码，然后进入kafka-0.10.0.1-src目录执行下面目录为idea构建：
1 gradle idea 构建的时候出现如下错误：
打开build.gradle文件，在import和build script中间加上以下代码重新构建即可：
ScalaCompileOptions.metaClass.daemonServer = true ScalaCompileOptions.metaClass.fork = true ScalaCompileOptions.metaClass.useAnt = false ScalaCompileOptions.metaClass.useCompileDaemon = false 然后打开idea安装scala插件，导入kafka源码。
结构 bin：一些执行脚本 checkstyle：静态代码的检查配置 clients：客户端代码，用java写的 config：配置文件 connect：这个是kafka一个新的项目，把数据源的数据引入进来，比如说把数据交给clients项目 core：消息系统，使用scala写的 streams：kafka提供的流式计算的项目，java写的 修改server.properties的log.dirs路径，然后在edit configurations做如下配置：
运行core下的kafka文件启动测试。
进入core模块，在最下面有一个kafka的类，这个就是启动类，里面有一个main方法：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 def main(args: Array[String]): Unit = { try { // 读取配置 val serverProps = getPropsFromArgs(args) // 创建KafkaServerStartable对象 val kafkaServerStartable = KafkaServerStartable.fromProps(serverProps) // 处理control &#43; c杀掉进程用的 Runtime.getRuntime().addShutdownHook(new Thread() { override def run() = { kafkaServerStartable.shutdown } }) // kafkaServerStartable启动，其实里面调用的就是server包下的KafkaServer的startup()方法 kafkaServerStartable.startup // 关闭事件 kafkaServerStartable.awaitShutdown } catch { case e: Throwable =&gt; fatal(e) System.exit(1) } System.exit(0) } 在KafkaServer的startUp()中初始化了所有组件，核心的是下面这些：
...</p>
  </div>
  <footer class="entry-footer"><span title='2021-09-20 06:27:35 +0000 UTC'>September 20, 2021</span>&nbsp;·&nbsp;5 min</footer>
  <a class="entry-link" aria-label="post link to 10.kafka源码-服务端网络通信" href="http://localhost:1313/posts/%E6%A1%86%E6%9E%B6/mq/kafka/10.%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">2.集群搭建
    </h2>
  </header>
  <div class="entry-content">
    <p>首先安装3台虚拟机，需要密码登录。在/etc/hosts配置本机的hostname到ip地址的映射，然后配置yum：
1 2 3 yum clean all yum makecache yum install -y wget 因为集群内部需要通信，所以需要关闭防火墙或者设置开放端口：
1 2 systemctl stop firewalld.service systemctl disable firewalld.service 安装jdk，把rpm包上传到虚拟机，安装：
1 rpm -ivh jdk-8u181-linux-x64.rpm 在~/ .bashrc中配置jdk的环境变量：
1 2 export JAVA_HOME=/usr/java/latest export PATH=$PATH:$JAVA_HOME/bin 每台虚拟机的hosts文件配置其他两台机器的ip映射，类似这样：
1 2 172.24.5.218 cluster01 172.24.5.217 cluster03 设置虚拟机互相免密登陆
...</p>
  </div>
  <footer class="entry-footer"><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;2 min</footer>
  <a class="entry-link" aria-label="post link to 2.集群搭建" href="http://localhost:1313/posts/%E6%A1%86%E6%9E%B6/mq/kafka/2.%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">3.kafka集群管理
    </h2>
  </header>
  <div class="entry-content">
    <p>删除topic： 删除topic需要先设置delete.topic.enable为true，执行命令删除：
1 2 # 删除是异步的，可能需要删除很长时间 ./kafka-topics.sh --delete --zookeeper cluster01:2181,cluster02:2181,cluster03:2181 --topic test-topic topic管理平台： 一般的小公司是不需要这个topic管理的，因为小公司可能就1个人或者几个人来维护kafka，像实时计算团队或者业务团队可能就跟你说一声要使用哪个topic，平时是没人管这个topic的，所以维护的人可以直接在命令行看一看就可以了。
查看消息数量： 查看消息数量需要先查看当前的消息索引，然后在查看其实的消息索引，他俩一减就是消息数量，为什么要减呢，因为kafka的消息不止一只保留的，可能只是最近7天的：
1 2 3 4 # 查看每个分区最大的消息位移 ./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list cluster01:9092,cluster02:9092,cluster03:9092 --topic test01 --time -1 # 查看每个分区最小的消息位移 ./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list cluster01:9092,cluster02:9092,cluster03:9092 --topic test01 --time -2 扩容partition 1 2 # 把partition数量调整到10，kafka的分区只能增不能减 ./kafka-topics.sh --alter --zookeeper cluster01:2181 --partitions 10 --topic test-topic 自研监控平台 其实就是在代码里执行一些命令或者api，或者直接掉kafka的脚本，可以每天凌晨扫描topic的数据量，如果发现topic数据量增长的很快，就可以自动扩容分区。
...</p>
  </div>
  <footer class="entry-footer"><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 3.kafka集群管理" href="http://localhost:1313/posts/%E6%A1%86%E6%9E%B6/mq/kafka/3.kafka%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">4.producer
    </h2>
  </header>
  <div class="entry-content">
    <p>发送消息过程 首先每个producer会从配置的broker上拉取topic、分区、broker等信息，在producer收到消息之后会先封装成一个producerRecord对象，然后把对象交给序列化组件，然后经过partitioner组件分配发送到那个broker上，如果发消息时没指定key，也没指定分区算法，默认会轮询，然后把消息发送给缓冲区，通过sender组件从缓冲区读取数据，打包成batch发送给broler。
常见异常 LeaderNotAvailableException：leader不可用，这个时候可能是leader挂了，正在选举；
NotControllerException：如果controller所在的broker挂了就会出现这个异常；
NetworkException：网络异常；
这些异常一般重试就可以解决。
TimeOutException：默认连接broker的超时时间是30s，如果30s没连上kafka可能集群都挂了。
参数配置 buffer.memory：缓冲的大小，默认是33554432，就是32M，如果说发送消息速度特别快，等到senderer线程封装batch在发送出去会慢一点，慢慢缓冲区满了发送消息就会卡住，刚开始可能是够用的，可以在发送消息前后加时间戳，看到发送消息大于10mx的时候可能就是缓冲区满了。 compression.type：发送消息时压缩算法，默认是none，开启后会增加CPU的开销，但是可以提升吞吐量，效率最好的就是lz4。 batch.size：打包发送的数据的字节数，默认是16k，这个在高并发的时候是偏小的，可以统计每100ms的消息的发送数量，然后适当调大这个值，看看吞吐量是不是有提升，16k是偏小的，一般是64k或者128k。 linger.ms：默认是0，可以设置成50或者100，意思是在50ms还没凑到batch大小，也把消息发送出去。 max.request.size：默认是1048576，就是1M，表示单条消息的最大值，1M是偏小的，可以设置成10M。 request.timeout.ms：超时时间，默认30s，够用。 retries：发送失败的重试次数，3到5次就可以cover住一般的异常了，不放心的话可以重试10次，但是重试可能导致消息的重复后者消息的乱序，因为在你重试的时候可能别的消息已经发出去了。 retry.backoff.ms：每次重试的毫秒数。 max.in.flight.request.per.connection：同时间发送消息的条数，如果设置成1表示同时间只能发同一条消息，就是在消息重试的时候其他消息需要等待这个法成功。 acks：他有3个选项，0：表示只要发出去就算成功，不管leader写没写成功；1：leader写成功才算成功；-1或者all：leader和所有follower写成功才算成功； max.block.ms：默认60s，当缓冲区慢了的时候，会阻塞住60s，超过时间会抛出异常。 自定义分区 一般情况不需要顺序消费的话发送消息时连key都不需要指定，默认的轮询就好了，如果想要顺序比支付和退款，这种需要先付钱在退款的可以把key设置成订单的id，这样就会发送到固定的partition上，broker的写一定是有序的，所以这个分区器一般用不到，如果非要用可以实现Partitioner接口：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class HotDataPartitioner implements Partitioner { private Random random; @Override public void configure(Map&lt;String, ?&gt; configs) { random = new Random(); } @Override public int partition(String topic, Object keyObj, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) { String key = (String)keyObj; List&lt;PartitionInfo&gt; partitionInfoList = cluster.availablePartitionsForTopic(topic); int partitionCount = partitionInfoList.size(); int hotDataPartition = partitionCount - 1; return !key.contains(“hot_data”) ? random.nextInt(partitionCount - 1) : hotDataPartition; } } 然后把配置partitioner就可以了：
...</p>
  </div>
  <footer class="entry-footer"><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 4.producer" href="http://localhost:1313/posts/%E6%A1%86%E6%9E%B6/mq/kafka/4.producer/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">5.consumer
    </h2>
  </header>
  <div class="entry-content">
    <p>参数 heartbeat.interval.ms：心跳的时间间隔。 session.timeout.ms：默认10s，如果broker10s内感知不到consumer的心跳就会认为consumer宕机，进行rebalance。 max.poll.interval.ms：两次pool的间隔超时，比如说虽然你一直在发心跳，但是poll一次消息之后，很长时间都没消费完，那broker就会认为你不靠谱，也会把你踢出去。 fetch.max.bytes：消费消息的最大值，一般可以设置成10M（10485760），要不然来一条大消息就消费不了了。 max.poll.records：每次最多拉多少条数据，默认500，如果消费的吞吐量特别大，这个参数可以调大。 connection.max.idle.ms：这个是说如果socket连接空闲得话会不会回收，可以设置成-1，不要回收。 enable.auto.commit：开启自动提交，开启之后消息消费完会有consumer自己去定时提交offset，这样会出现一个问题，就是每次重启都会重复消费一批数据。 auto.commit.ineterval.ms：自动提交的间隔。 auto.offset.reset：重启后发现offet在broker中找不到，怎么处理，可以设置成earliest，从最早的开始消费。 原理 每个consumer都要有一个组，并且每个分区只能被一个consumer消费，但是一个consumer可以消费多个分区，所以如果只有3个分区，创建10个consumer是没用的。consumer收到消息之后默认定时自动提交offset，就是把offset发送到_consumer_offsets队列。
coordinator coordinator是负责consumer的心跳、宕机判断以及rebalance的，当consumer group启动的时候，会对consumer group id的hash取模，然后根据_consumer_offsets的分区数，默认是50进行取余，拿到的分区的leader所在的broker就是这个group的coordinator。
每个consumer都发送JoinGroup请求到Coordinator，然后Coordinator从一个consumer group中选择一个consumer作为leader，把consumer group情况发送给这个leader，接着这个leader会负责制定分区方案，通过SyncGroup发给Coordinator，接着Coordinator就把分区方案下发给各个consumer，他们会从指定的分区的leader broker开始进行socket连接以及消费消息。
rebalance策略：
range：按照区间给，比如0-2的分区给第一个consumer，3-5分区给第二个consumer。 round-robin：轮询，第一个消费者消费0分区，第二个消费1分区……。 sticky：强两个分区方式问题很大，比如第二个consumer死了，可能所有的consumer被新分配的分区和之前的都不一样，为了解决上面的问题sticky把宕机的consumer的分区在均匀的分配给现有的consumer。 自定义消费分区 1 2 3 4 List&lt;PartitionInfo&gt; partitions = consumer.partitionsFor(“order-topic”); new TopicPartition(partitionInfo.topic(), partitionInfo.partition()); // 指定每个consumer要消费哪些分区，你就不是依靠consumer的自动的分区分配方案来做了 consumer.assign(partitions); </p>
  </div>
  <footer class="entry-footer"><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 5.consumer" href="http://localhost:1313/posts/%E6%A1%86%E6%9E%B6/mq/kafka/5.consumer/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">6.常见问题
    </h2>
  </header>
  <div class="entry-content">
    <p>消息丢失 数据重复 消息乱序 消息积压 配合分布式事务实现消息事务支持 消息的过期时间TTL 延迟队列 多优先级队列 私信队列 重试队列 下游数据计算错误如何回溯 当下游的代码有bug时，产生了一些错误数据，这个时候应该删掉错误数据然后在判断是不是应该数据的回溯。
消息路由 消息流转链路进行轨迹监控 消息质量监控 就是每天流转了多少条数据，链路完整、流转完整占比多少，流转不完整的占比多少，处理错误的占比多少。
</p>
  </div>
  <footer class="entry-footer"><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;1 min</footer>
  <a class="entry-link" aria-label="post link to 6.常见问题" href="http://localhost:1313/posts/%E6%A1%86%E6%9E%B6/mq/kafka/6.%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">7.kafka源码-producer初始化
    </h2>
  </header>
  <div class="entry-content">
    <p>producer初始化 初始化producer，直接new KafkaProducer就可以，初始化的代码都在这个类里：
1 KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(Properties); 在这个构造方法里首先把我们配置的Properties转成ProducerConfig，kafka自己的配置文件，这个文件里有所有的Producer配置和默认值，还有一些属性的名字和注释在CommonClientConfigs里：
1 2 this(new ProducerConfig(ProducerConfig.addSerializerToConfig(properties, keySerializer, valueSerializer)), keySerializer, valueSerializer, null, null); 然后调用另一个构造方法初始化核心组件：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 KafkaProducer(ProducerConfig config, Serializer&lt;K&gt; keySerializer, Serializer&lt;V&gt; valueSerializer, Metadata metadata, KafkaClient kafkaClient) { try { // 我们自己的配置 Map&lt;String, Object&gt; userProvidedConfigs = config.originals(); this.producerConfig = config; this.time = Time.SYSTEM; // 获取client.id属性，默认是空串 String clientId = config.getString(ProducerConfig.CLIENT_ID_CONFIG); if (clientId.length() &lt;= 0) // 空串的话会走到这里，producer-自增数字作为clientId，线程安全的 clientId = &#34;producer-&#34; &#43; PRODUCER_CLIENT_ID_SEQUENCE.getAndIncrement(); this.clientId = clientId; // 核心组件，用来决定你的消息会发送到那个topic的那个分区里的 this.partitioner = config.getConfiguredInstance(ProducerConfig.PARTITIONER_CLASS_CONFIG, Partitioner.class); // retry.backoff.ms，重试间隔，默认100ms long retryBackoffMs = config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG); // 序列组件 if (keySerializer == null) { this.keySerializer = ensureExtended(config.getConfiguredInstance(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, Serializer.class)); this.keySerializer.configure(config.originals(), true); } else { config.ignore(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG); this.keySerializer = ensureExtended(keySerializer); } if (valueSerializer == null) { this.valueSerializer = ensureExtended(config.getConfiguredInstance(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, Serializer.class)); this.valueSerializer.configure(config.originals(), false); } else { config.ignore(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG); this.valueSerializer = ensureExtended(valueSerializer); } // 拦截器组件 userProvidedConfigs.put(ProducerConfig.CLIENT_ID_CONFIG, clientId); List&lt;ProducerInterceptor&lt;K, V&gt;&gt; interceptorList = (List) (new ProducerConfig(userProvidedConfigs, false)).getConfiguredInstances(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, ProducerInterceptor.class); this.interceptors = new ProducerInterceptors&lt;&gt;(interceptorList); ClusterResourceListeners clusterResourceListeners = configureClusterResourceListeners(keySerializer, valueSerializer, interceptorList, reporters); // max.request.size，每个请求的最大大小，默认1M this.maxRequestSize = config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG); // buffer.memory，缓冲池大小，默认32M this.totalMemorySize = config.getLong(ProducerConfig.BUFFER_MEMORY_CONFIG); this.compressionType = CompressionType.forName(config.getString(ProducerConfig.COMPRESSION_TYPE_CONFIG)); // max.block.ms缓冲区满了的阻塞时间，默认一分钟，超过1分钟会抛出异常 this.maxBlockTimeMs = config.getLong(ProducerConfig.MAX_BLOCK_MS_CONFIG); // request.timeout.ms，请求超时时间，默认30s this.requestTimeoutMs = config.getInt(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG); this.transactionManager = configureTransactionState(config, logContext, log); // 这个应该是重试次数 int retries = configureRetries(config, transactionManager != null, log); int maxInflightRequests = configureInflightRequests(config, transactionManager != null); short acks = configureAcks(config, transactionManager != null, log); this.apiVersions = new ApiVersions(); // 核心组件，缓冲池 this.accumulator = new RecordAccumulator(logContext, config.getInt(ProducerConfig.BATCH_SIZE_CONFIG), this.totalMemorySize, this.compressionType, config.getLong(ProducerConfig.LINGER_MS_CONFIG), retryBackoffMs, metrics, time, apiVersions, transactionManager); // broker地址 List&lt;InetSocketAddress&gt; addresses = ClientUtils.parseAndValidateAddresses(config.getList(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG)); // 核心组件，维护broker的元数据信息 if (metadata != null) { this.metadata = metadata; } else { this.metadata = new Metadata(retryBackoffMs, // metadata.max.age.ms，默认5分钟强制刷新一次 config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG), true, true, clusterResourceListeners); // 如果metadata是空需要拉取一下元数据 this.metadata.update(Cluster.bootstrap(addresses), Collections.&lt;String&gt;emptySet(), time.milliseconds()); } ChannelBuilder channelBuilder = ClientUtils.createChannelBuilder(config); Sensor throttleTimeSensor = Sender.throttleTimeSensor(metricsRegistry.senderMetrics); // 核心组件，网络通信组件，这里初始化了一个selector KafkaClient client = kafkaClient != null ? kafkaClient : new NetworkClient( new Selector(config.getLong(ProducerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG), this.metrics, time, &#34;producer&#34;, channelBuilder, logContext), // 这个是元数据的信息，负责元数据的增改，唤醒主线程 this.metadata, clientId, // max.in.flight.requests.per.connection，同时发送的消息数 // 这个最大就是5 maxInflightRequests, // reconnect.backoff.ms，重新建立连接的等待时长 config.getLong(ProducerConfig.RECONNECT_BACKOFF_MS_CONFIG), // reconnect.backoff.max.ms，建立连接的最大时长 // 连接失败的时候会重试，每次间隔reconnect.backoff.ms成倍增加，直到超过max.ms config.getLong(ProducerConfig.RECONNECT_BACKOFF_MAX_MS_CONFIG), // send.buffer.bytes，# 发送缓冲区的大小 config.getInt(ProducerConfig.SEND_BUFFER_CONFIG), // receive.buffer.bytes，接收缓冲区的大小 config.getInt(ProducerConfig.RECEIVE_BUFFER_CONFIG), // request.timeout.ms，发送的超时时间 this.requestTimeoutMs, time, true, apiVersions, throttleTimeSensor, logContext); // 核心组件，负责把缓冲池里的消息发送到broker上 this.sender = new Sender(logContext, client, // 这个是元数据的信息，负责元数据的增改，唤醒主线程 this.metadata, this.accumulator, maxInflightRequests == 1, // max.request.size单次请求的最大字节 config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG), acks, // 重试次数 retries, metricsRegistry.senderMetrics, Time.SYSTEM, // 发送的超时时间 this.requestTimeoutMs, // retry.backoff.ms，重试的最大时间 config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG), this.transactionManager, apiVersions); // 线程名：kafka-producer-network-thread|clientId String ioThreadName = NETWORK_THREAD_PREFIX &#43; &#34; | &#34; &#43; clientId; // 把sender放到线程里，启动 this.ioThread = new KafkaThread(ioThreadName, this.sender, true); this.ioThread.start(); } catch (Throwable t) { close(0, TimeUnit.MILLISECONDS, true); throw new KafkaException(&#34;Failed to construct kafka producer&#34;, t); } } 看拉取元数据的方法：
...</p>
  </div>
  <footer class="entry-footer"><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;5 min</footer>
  <a class="entry-link" aria-label="post link to 7.kafka源码-producer初始化" href="http://localhost:1313/posts/%E6%A1%86%E6%9E%B6/mq/kafka/7.producer%E5%88%9D%E5%A7%8B%E5%8C%96%E6%BA%90%E7%A0%81/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">8.kafka源码-producer发送消息
    </h2>
  </header>
  <div class="entry-content">
    <p>初始化完成后就可以调用producer的send方法了，先看异步发送，传进一个ProducerRecord类型的消息体和一个回调函数，最终调用到KafkaProducer的doSend方法：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 // 调用doSend之前会使用拦截器在处理一下record private Futrue&lt;RecordMetadata&gt; doSend(ProducerRecord&lt;K, V&gt; record, Callback callback) { TopicPartition tp = null; try { // 这里要获取topic了，同步阻塞 ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs); long remainingWaitMs = Math.max(0, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs); Cluster cluster = clusterAndWaitTime.cluster; // 把key和value都进行序列化 byte[] serializedKey; try { serializedKey = keySerializer.serialize(record.topic(), record.headers(), record.key()); } catch (ClassCastException cce) { throw new SerializationException(&#34;Can&#39;t convert key of class &#34; &#43; record.key().getClass().getName() &#43; &#34; to class &#34; &#43; producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() &#43; &#34; specified in key.serializer&#34;, cce); } // value就是消息的body byte[] serializedValue; try { serializedValue = valueSerializer.serialize(record.topic(), record.headers(), record.value()); } catch (ClassCastException cce) { throw new SerializationException(&#34;Can&#39;t convert value of class &#34; &#43; record.value().getClass().getName() &#43; &#34; to class &#34; &#43; producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() &#43; &#34; specified in value.serializer&#34;, cce); } // 根据topic信息获取对应的分区 int partition = partition(record, serializedKey, serializedValue, cluster); tp = new TopicPartition(record.topic(), partition); setReadOnly(record.headers()); Header[] headers = record.headers().toArray(); // 统计消息大小 int serializedSize = AbstractRecords.estimateSizeInBytesUpperBound(apiVersions.maxUsableProduceMagic(), compressionType, serializedKey, serializedValue, headers); // 检查消息是否超过了设置的大小上限和是否超过了缓冲区的大小上限 ensureValidRecordSize(serializedSize); long timestamp = record.timestamp() == null ? time.milliseconds() : record.timestamp(); log.trace(&#34;Sending record {} with callback {} to topic {} partition {}&#34;, record, callback, record.topic(), partition); // producer callback will make sure to call both &#39;callback&#39; and interceptor callback // 设置自定义回调和拦截器的回调 Callback interceptCallback = new InterceptorCallback&lt;&gt;(callback, this.interceptors, tp); if (transactionManager != null &amp;&amp; transactionManager.isTransactional()) transactionManager.maybeAddPartitionToTransaction(tp); // 把消息放到缓冲里 RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, headers, interceptCallback, remainingWaitMs); // 这里就是判断如果一个batch满了或者创建了一个新的batch，就要唤醒sender线程，发送消息 if (result.batchIsFull || result.newBatchCreated) { log.trace(&#34;Waking up the sender since topic {} partition {} is either full or getting a new batch&#34;, record.topic(), partition); this.sender.wakeup(); } // 返回futrue对象 return result.futrue; // 下面是一大堆异常处理，基本上每一个步骤都会自定义一个自己的异常，在这层捕获进行处理 // 一般中间件的异常捕获处理之后也会抛出去 // 如果是业务代码要在业务的最顶层进行捕获处理，根据异常返回给前端对应的提示 } catch (ApiException e) { log.debug(&#34;Exception occurred during message send:&#34;, e); if (callback != null) callback.onCompletion(null, e); this.errors.record(); this.interceptors.onSendError(record, tp, e); return new FutrueFailure(e); } catch (InterruptedException e) { this.errors.record(); this.interceptors.onSendError(record, tp, e); throw new InterruptException(e); } catch (BufferExhaustedException e) { this.errors.record(); this.metrics.sensor(&#34;buffer-exhausted-records&#34;).record(); this.interceptors.onSendError(record, tp, e); throw e; } catch (KafkaException e) { this.errors.record(); this.interceptors.onSendError(record, tp, e); throw e; } catch (Exception e) { // we notify interceptor about all exceptions, since onSend is called before anything else in this method this.interceptors.onSendError(record, tp, e); throw e; } } 同步阻塞获取topic KafkaProducer的waitOnMetadata方法有三个参数，topic、partition、maxWaitMs，topic和partition是在发消息时候设置的，maxWaitMs是初始化producer的时候配置的max.block.ms，最开始是简单配置一下然后判断缓存：
...</p>
  </div>
  <footer class="entry-footer"><span title='2021-08-06 06:27:35 +0000 UTC'>August 6, 2021</span>&nbsp;·&nbsp;11 min</footer>
  <a class="entry-link" aria-label="post link to 8.kafka源码-producer发送消息" href="http://localhost:1313/posts/%E6%A1%86%E6%9E%B6/mq/kafka/8.producer%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="prev" href="http://localhost:1313/posts/">
      «&nbsp;Prev&nbsp;
    </a>
    <a class="next" href="http://localhost:1313/posts/page/3/">Next&nbsp;&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">王小红的笔记</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
