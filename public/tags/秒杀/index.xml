<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>秒杀 on 王小红的笔记</title>
    <link>http://localhost:1313/tags/%E7%A7%92%E6%9D%80/</link>
    <description>Recent content in 秒杀 on 王小红的笔记</description>
    <generator>Hugo -- 0.150.0</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 18 Jul 2021 06:27:35 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/%E7%A7%92%E6%9D%80/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>秒杀架构</title>
      <link>http://localhost:1313/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E7%A7%92%E6%9D%80/%E6%9E%B6%E6%9E%84%E5%92%8C%E6%80%9D%E8%B7%AF/</link>
      <pubDate>Sun, 18 Jul 2021 06:27:35 +0000</pubDate>
      <guid>http://localhost:1313/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E7%A7%92%E6%9D%80/%E6%9E%B6%E6%9E%84%E5%92%8C%E6%80%9D%E8%B7%AF/</guid>
      <description>&lt;h3 id=&#34;整体思路&#34;&gt;整体思路&lt;/h3&gt;
&lt;h5 id=&#34;前端页面&#34;&gt;前端页面&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;前端页面静态化：秒杀的商品变化的频率很低，基本上在设置成功后到秒杀结束不会发生改变，这是纯静态的页面，所以秒杀的页面或者数据可以存在nginx中，或者说在nginx中都会浪费带宽，可以放到CDN缓存中，当秒杀的商品发生变更的时候让CDN失效就可以了。同时CDN数量不能太多，太多失效的时间会变长，而且有些地区的用户数很少就没必要使用CDN了，只需要在用户数量较多的地方集中设置几个CDN就够用，可以提升整体的缓存命中率。&lt;/li&gt;
&lt;li&gt;时钟同步问题：秒杀的倒计时需要和后台的时间同步，否则可能前端的时间到了但是服务器的还没开始，或者前端的时间到了，但是秒杀在上一秒已经开始了，可以搞一个时钟同步服务器， 所有和秒杀有关的服务器都需要和这台服务器保持时间同步，还要有一台单独的时钟授时系统，前端每分钟或者半分钟同步一下时间。&lt;/li&gt;
&lt;li&gt;秒杀接口的隐藏：在秒杀开始之前，不应该把秒杀的url暴露出来，防止黄牛和黑客提前写好脚本，开始前1分钟由前端请求后台获取秒杀的url。&lt;/li&gt;
&lt;li&gt;防刷单和限流：如果秒杀的瞬时QPS非常高或者有被刷单的风险可以引入行为验证这种商业验证码，腾讯、网易、极验这些都不错，就是小贵，但是这个验证码真是好东西，一般后台都需要进行二次验证，参与秒杀的都是注册用户，二次验证通过后可以和用户id进行绑定，当秒杀请求过来时判断是否通过过验证，当然行为验证的结果只能使用一次，而且放到nginx中就可以了，使用lua和验证三方交互和在redis中存放二次验证通过的用户。&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;负载均衡&#34;&gt;负载均衡&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;LVS+keepalive架构+高带宽，单机抗下数十万并发。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;是否需要网关：如果服务少的话，是不需要的，在nginx中配几个反向代理，前端多配置几个基础路径，但是大量的服务是需要网关，频繁的增减服务不可能每次都要重启nginx。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;独立的二级域名：秒杀的服务的域名需要和正常业务分开，要不然容易影响正常业务。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;防DDoS攻击：使用云厂商的DDoS高防产品，就是有点贵。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;后台架构&#34;&gt;后台架构&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;nginx的限流方案：上线之前会进行全链路压测，然后根据也测结果调优之后需要在nginx中做整体的限流，滑动窗口、令牌桶、漏斗算法等，同时还需要一个业务限流，因为每个商品的秒杀数量都不相同，当商品秒杀库存为空的时候可以通知nginx，再有这个商品的秒杀请求直接返回商品被抢光啦。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;商品超卖：商品的数量等信息都是放在redis中的，这样才可以抗下并发，超卖问题就是当一个线程扣减库存的时候，一个线程去查询，发现库存充足，还会继续走下单逻辑，这样会出现库存负数的情况。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;最普通的解决方案就是分布式锁，可以解决问题，但是秒杀就变成串行得了，很慢；&lt;/li&gt;
&lt;li&gt;还有一种方案是乐观锁（可以是redis 的watch机制），在更新库存的时候先去查询版本号，这样会变快，但是会产生很多空轮训，牺牲CPU；&lt;/li&gt;
&lt;li&gt;一般大厂是把商品的数量分片放到redis集群中，然后把查询是否可以抢购+修改信息+返回结果封装到lua中，redis是可以保证lua的执行时原子的，这样上万的并发会被分到多台redis集群中的master节点上，每个节点就是执行几百上千个lua脚本，同时需要记录那个节点的库存为0，会转移到有库存的节点上；&lt;/li&gt;
&lt;li&gt;网上一些课程说可以把商品信息放到redis的队列中，比如list，然后一个一个出队，这方案听起来就很怪，如果秒杀的商品有1000个，每个商品500个，需要全都放到redis中吗？&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;黄金支付链路：秒杀系统在收到请求之后就要去redis集群中进行库存扣减，扣减成功之后发送消息到mq，这个时候需要有一个秒杀成功的下单服务，他需要使用线程池进行流控，为什么要流控呢，因为订单服务不只是在秒杀的时候才会用到，大部分的时间都是服务于正常业务的，服务可接受的tps是有上限的。订单系统就可以消费这条秒杀消息了，前端在支付时，调用三放支付平台，后台需要等待三方回调，如果超时没收到回调需要还原库存，修改订单状态是已超时。这些都不是秒杀系统该做的，电商平台自己的一套东西。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;tomcat调优：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;前端感知订单状态：前端在收到秒杀成功的响应后，就可以定时轮询秒杀状态服务，在订单创建成功后，秒杀状态服务感知到订单创建好了，就可以返回给前端，前端正常走支付流程。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;秒杀成功的mq消息领丢失方案：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;秒杀成功消息重复消费方案：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;秒杀成功消息延迟问题：如果订单系统消费的很慢，此时mq的消息积压到了数十万条，这个时候如果还是慢慢消费，可能客户端要等10分钟或者更久才能刷出来这个订单，这样用户就会很疑惑，当消费的时候可以比较消息的发送时间和当前时间，如果超过了1分钟，那么就还原库存，然后把这个消息状态改成秒杀失败，让用户在抢一次，这样数十万的消息会变成几分钟，平均打过来。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;redis+mq的一致性回滚方案：在秒杀的时候需要使用redis的事务+mq的事务消息，防止发送秒杀成功消息的时候失败了，库存还是扣减的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;高可用架构&#34;&gt;高可用架构&lt;/h5&gt;
&lt;p&gt;正常服务只要保证多机器的冗余部署就可以保证基本的高可用了。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;redis集群挂掉：如果集群全部挂掉了，秒杀也就不能正常进行了，这个时候可以把用户的秒杀行为以日志的形式存到本地磁盘里，然后返回给用户秒杀抢购中，等到redis回复了，在把磁盘的日志顺序读取出来执行一遍。&lt;/li&gt;
&lt;li&gt;redis主从切换导致的超卖：这个其实发生的概率很低，如果真的要防止这种情况，可以去掉redis集群，不让他有主从切换的机会，使用twemproxy或者codis对多个redis做分布式存储，如果有一台宕机，还是写日志、等待修复。还有一个方案就是下订单的时候订单系统检查冻结的库存是不是负数，这个需要订单系统做一些操作，感觉不是太好。&lt;/li&gt;
&lt;li&gt;与秒杀下单系统的直连降级：如果mq挂掉，消息一直发不出去，不能走之前的降级逻辑，因为这个时候返回秒杀失败，用户会一直点秒杀，一直失败，这个时候可以用抢购服务直连秒杀下单服务，控制好速度就行，就是以很慢的速度下单。&lt;/li&gt;
&lt;li&gt;秒杀下单系统异常：这个时候可以进行重试，重试很多次也不行就需要进入死信队列。&lt;/li&gt;
&lt;li&gt;多机房部署：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gsqkyv56fjj313u0phq5x.jpg&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>LVS</title>
      <link>http://localhost:1313/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E7%A7%92%E6%9D%80/lvs/</link>
      <pubDate>Mon, 12 Jul 2021 06:27:35 +0000</pubDate>
      <guid>http://localhost:1313/posts/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E7%A7%92%E6%9D%80/lvs/</guid>
      <description>&lt;p&gt;在我第一个压测的nginx是使用的4c8g的服务器+openresty搭建的nginx代理服务器，nginx使用4个worker绑核，返回的一段静态页面，发现在QPS达到2k后CPU都跑到了2000+，100M的带宽也被占满，开始以为想要接收高并发，nginx是第一个瓶颈，没想到是带宽，但是反过来推算4c8g的nginx也是扛不住200M的带宽的，所以要想抗住高并发，高带宽和高配置的nginx是必须的，但是配置再高也会有上限，还不如搞一个nginx集群，这样就可以无限的横向扩容了。&lt;/p&gt;
&lt;p&gt;LVS（Linux Virtual Server）：Linux虚拟机服务器，就是一种负载均衡的技术，负载均衡的缩写是SLB（server load balance），它运行在linux内核层面，4c8g的服务器+LVS每秒处理几十万的请求不是问题，他是建立在4层网络协议基础上的，像nginx就是基于7层网络协议的负载均衡服务器。目前主流的负载均衡架构都是LVS+keepalive+nginx。&lt;/p&gt;
&lt;h3 id=&#34;原理&#34;&gt;原理&lt;/h3&gt;
&lt;p&gt;首先当LVS收到客户端的报文（建立连接、断开连接、请求数据都是报文）之后，会在本地的hash表中查看是否有这个链接对应的后台服务器，如果没有就从后端的服务器地址中通过负载均衡算法拿到一台服务器，然后通过NAT（Network Address Translation，网络地址转换）技术把报文的请求地址换成后端服务器的地址，把请求发送到后端服务器，在hash表中记录这个链接对应的后端服务器，收到后台服务器的报文之后也会通过NAT技术把报文重新定位到客户端，在LVS中是没有HTTP协议这种说法的。&lt;/p&gt;
&lt;p&gt;可以想一下，因为大部分的请求都是请求报文比响应报文小很多，如果响应也通过LVS的话会占用很多带宽，严重降低LVS的吞吐量，所以可以使用ip隧道把响应直接从nginx返回给客户端。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://tva1.sinaimg.cn/large/008i3skNly1gskwsola92j31lz0u041p.jpg&#34;&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
