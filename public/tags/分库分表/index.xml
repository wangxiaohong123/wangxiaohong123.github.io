<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>分库分表 on 王小红的笔记</title><link>https://wangxiaohong123.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</link><description>Recent content in 分库分表 on 王小红的笔记</description><generator>Hugo -- 0.150.0</generator><language>zh-CN</language><atom:link href="https://wangxiaohong123.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/index.xml" rel="self" type="application/rss+xml"/><item><title>1.分库分表-sharding_sphere</title><link>https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/2.sharding-sphere/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/2.sharding-sphere/</guid><description>&lt;p&gt;sharding-sphere仅仅是一个框架，业务引入依赖就可以使用了，通过一些配置，他就会根据指定sharding字段路由，执行SQL，[官网][https://shardingsphere.apache.org/index_zh.html]。现在sharding-sphere也有proxy server模式了，它还支持主键生成、事务(最终一致性、XA)、数据迁移、数据可视化链路追踪、扩容等，就是说基本上除了垮裤跨表的复杂查询，分库分表用到的功能他基本上都有了，最早是当当开源出来的。&lt;/p&gt;
&lt;p&gt;mycat是proxy server模式，需要独立部署server端，然后在业务引入client依赖，所有SQL通过client发送到server&lt;/p&gt;</description></item><item><title>1.分库分表-介绍</title><link>https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/1.%E4%BB%8B%E7%BB%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/1.%E4%BB%8B%E7%BB%8D/</guid><description>&lt;h5 id="1怎么拆"&gt;1.怎么拆&lt;/h5&gt;
&lt;p&gt;分库分表之前要考虑怎么拆分，一般都是先垂直后水平，首先垂直拆分把表的列按模块尽可能分到不同的库中，这样可能会解决读写并发压力过大的问题和单条数据过大导致磁盘瓶颈问题，然后在考虑水平拆分。&lt;/p&gt;
&lt;p&gt;然后在考虑用什么技术，一般就是sharding-sphere和mcat。&lt;/p&gt;
&lt;h5 id="2唯一id"&gt;2.唯一id&lt;/h5&gt;
&lt;p&gt;使用leaf&lt;/p&gt;
&lt;h5 id="3多场景不同条件查询"&gt;3.多场景不同条件查询&lt;/h5&gt;
&lt;p&gt;比如电商的订单，用户可以查询自己的id获取订单记录，商家可以根据自己的id获取订单记录，这个时候是以用户id路由，保证同一个用户的订单分到了同一张表还是以商家id路由，如果不考虑存储空间就都做，这样数据量会变成原来的两倍，如果考虑存储空间就以经常访问的业务作为路有条件，其他的可以二次路由。&lt;/p&gt;
&lt;h5 id="4分布式事务"&gt;4.分布式事务&lt;/h5&gt;
&lt;p&gt;分库分表后由于规则不同，比如订单使用用户id作为路由条件，订单条目使用订单id作为路由条件，这样就会导导致跨库的事务，就需要使用XA事务。&lt;/p&gt;
&lt;h5 id="5查询条件中没有sharding字段"&gt;5.查询条件中没有sharding字段&lt;/h5&gt;
&lt;p&gt;比如查询是一堆组合条件，可以用sharding-jdbc之类的中间件，他会去所有表中把符合条件的数据都merge到一台机器的内存中，这个很慢也很占带宽，可以把条件放到es中， 根据条件查询出sharding字段，在回表查询。分库分表之后使用es抗复杂查询是不可避免的。&lt;/p&gt;
&lt;h5 id="6读写分离"&gt;6.读写分离&lt;/h5&gt;
&lt;p&gt;使用一主多从分摊大部分的查询请求，这样一主多从抗住80%的crud，es抗住20%的复杂查询。&lt;/p&gt;
&lt;h5 id="7物理架构的规划"&gt;7.物理架构的规划&lt;/h5&gt;
&lt;p&gt;一般表就是1024张，库的话需要根据写并发和数据大小做出规划，比如高峰时这个库有多少tps，未来是否会增长，然后每天增长多少数据，计算主库和从库的配置，分几台主库，es要几台服务器，几个分片，保证分库之后可以抗几年。&lt;/p&gt;
&lt;h5 id="8数据迁移"&gt;8.数据迁移&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;首先开发一个数据同步加检测的程序，同步就一直在同步，检测也是一直在检测，保证某一个时间点时之后旧库和新库的数据完全一致。&lt;/li&gt;
&lt;li&gt;然后在开发新系统，数据的crud全部打到新数据库中。&lt;/li&gt;
&lt;li&gt;进行双写，比如使用nginx把一个请求分发到两套系统里，停掉数据同步，只开启数据检测。&lt;/li&gt;
&lt;li&gt;运行一段时间后如果检测没有问题修改nginx，把请求只打到新程序中，停掉旧程序完成数据迁移。&lt;/li&gt;
&lt;/ol&gt;
&lt;h5 id="9控制台"&gt;9.控制台&lt;/h5&gt;
&lt;p&gt;分库分表之前需要操作控制台实现大量的DDL操作，不能每个表拆成1024张都手动去操作吧，以后新业务需要新表新库的时候也不能手动操作吧，太没效率了，在分库分表之后还需要监控每个库表的性能、负载，还需要知道每张物理表的数据量，占用空间，1024张物理表组成的大逻辑表一共有多少数据等等。&lt;/p&gt;
&lt;h5 id="10扩容问题"&gt;10.扩容问题&lt;/h5&gt;
&lt;p&gt;之前创建的1024张表在扩容时可以直接移动表，不需要重新把路由数据，但是在迁移表的时候还要考虑迁移的时候数据写入问题、迁移之后数据库配置，这也是很麻烦的，可以编写一套脚本，然后在控制台控制执行，在来一个配置中心，也可以是控制台，修改数据库连接之类的。&lt;/p&gt;</description></item><item><title>3.分库分表-经验</title><link>https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/3.%E7%BB%8F%E9%AA%8C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wangxiaohong123.github.io/posts/%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/3.%E7%BB%8F%E9%AA%8C/</guid><description>&lt;h5 id="shard-key"&gt;shard key&lt;/h5&gt;
&lt;p&gt;分库分表后首先要考虑的就是分片key的设计，比如单号和用户关联，订单号使用类型(10表示正向下单，20表示退单)+flicker+用户id后3位，这样订单就和用户关联起来，查询用户的订单会路由到同一个库的同一张表中，查询订单明细也会路由到同一个库的同一张表中&lt;/p&gt;
&lt;h5 id="主键id"&gt;主键id&lt;/h5&gt;
&lt;p&gt;分库分表后的id一般都会使用雪花算法生成，保证不同表的id也没有重复，但是一般shard key不会采用id，这个id其实是没有查询意义的。&lt;/p&gt;
&lt;h5 id="默认策略"&gt;默认策略&lt;/h5&gt;
&lt;p&gt;有的表不需要分库分表(比如seata)，有的表只要分库，有的表需要分库分表，不分库分表的会去走默认策略。有的业务需要一种每个库存储一样的数据，就要配置成广播表。&lt;/p&gt;
&lt;h5 id="配合其他数据库"&gt;配合其他数据库&lt;/h5&gt;
&lt;p&gt;分库分表的原因是数据量过大，一帮分库分表之后只靠MySQL是无法满足业务的，高频率的复杂查询和复杂查询+分页需要es的配合，低频率的大量数据可以使用MongoDB，还有一些更大数据量的低频查询数据可以使用HBase，他和MongoDB的区别是他可以对保存的数据进行列扩展，还可以对MySQL的一些数据做降级，需要注意HBase的查询只有根据rowkey才快，所以在rowkey的设计上需要一些技巧。&lt;/p&gt;
&lt;h5 id="数据迁移"&gt;数据迁移&lt;/h5&gt;
&lt;p&gt;分库分表或者多种库异构存储就要涉及到数据迁移，数据迁移方案由两步组成，全量同步和增量同步，两步就有同步执行和串行执行，在执行数据迁移之前要把新版本的服务环境和服务运行起来，此时流量0%打到新系统上，启动数据迁移系统，然后启动canal监听老版本和新版本数据库的binlog，开启数据全量同步。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;全量和增量串行，如果是串行在全量同步的时候收到的增量变更只记录，不执行，等到全量同步完成后，遍历增量变更数据，根据变更时间和全量数据的查询时间，选择性刷新数据，在全量同步完成后，收到的增量变更不记录，直接刷新，然后修改分流方案，让流量全部打到新系统上，这个时候就服务就已经没用了，等到增量的topic全部消费完数据迁移服务也没用了。适合小数据量的数据迁移。&lt;/li&gt;
&lt;li&gt;全量和增量并行，并行和串行类似，但是比串行快，同时迁移代码也更复杂，需要处理好并发问题。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img loading="lazy" src="https://tva1.sinaimg.cn/large/e6c9d24ely1h1f2hoj3bcj21470u0q57.jpg"&gt;&lt;/p&gt;</description></item></channel></rss>